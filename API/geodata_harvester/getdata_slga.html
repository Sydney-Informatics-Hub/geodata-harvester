<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>geodata_harvester.getdata_slga API documentation</title>
<meta name="description" content="Python script to download data from Soil and Landscape Grid of Australia (SLGA) …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>geodata_harvester.getdata_slga</code></h1>
</header>
<section id="section-intro">
<p>Python script to download data from Soil and Landscape Grid of Australia (SLGA).</p>
<p>Core functionality:
- Retrieval of WCS capability
with function get_capabilities()
- automatic download SLGA data for given depth range and layer(s) via Web Coverage Service (WCS)
- clip data to custom bounding box
- save data as multi-band geotiff
- plot data as map</p>
<p>The SLGA layers and metadata are described as dictionary in the module function get_slgadict()
and the respective licensing and attribution are availabe with the module function getdict_license()</p>
<p>More details about the SLGA data and attributions can be found here:
<a href="https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails-SoilAttributes.html">https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails-SoilAttributes.html</a></p>
<p>This package is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).</p>
<p>Copyright 2022 Sydney Informatics Hub (SIH), The University of Sydney</p>
<p>This open-source software is released under the LGPL-3.0 License.</p>
<p>Author: Sebastian Haan</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Python script to download data from Soil and Landscape Grid of Australia (SLGA).

Core functionality:
- Retrieval of WCS capability  with function get_capabilities()
- automatic download SLGA data for given depth range and layer(s) via Web Coverage Service (WCS)
- clip data to custom bounding box
- save data as multi-band geotiff
- plot data as map

The SLGA layers and metadata are described as dictionary in the module function get_slgadict()
and the respective licensing and attribution are availabe with the module function getdict_license()

More details about the SLGA data and attributions can be found here:
https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails-SoilAttributes.html

This package is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).

Copyright 2022 Sydney Informatics Hub (SIH), The University of Sydney

This open-source software is released under the LGPL-3.0 License.

Author: Sebastian Haan
&#34;&#34;&#34;

import os
from owslib.wcs import WebCoverageService
import rasterio
from rasterio.plot import show
from geodata_harvester import utils
from geodata_harvester.utils import spin

# logger setup
from geodata_harvester import write_logs
import logging


def get_slgadict():
    &#34;&#34;&#34;
    Get dictionary of SLGA data.

    The Soil Facility produced a range of digital soil attribute products.
    Each product contains six digital soil attribute maps, and their upper and lower confidence limits,
    representing the soil attribute at six depths: 0-5cm, 5-15cm, 15-30cm, 30-60cm, 60-100cm and 100-200cm.
    These depths are consistent with the specifications of the GlobalSoilMap.net project (http://www.globalsoilmap.net/).
    The digital soil attribute maps are in raster format at a resolution of 3 arc sec (~90 x 90 m pixels).

    Period (temporal coverage; approximately): 1950-2013;
    Spatial resolution: 3 arc seconds (approx 90m);
    Data license : Creative Commons Attribution 3.0 (CC By);
    Target data standard: GlobalSoilMap specifications;
    Format: GeoTIFF.

    Run function get_capabilities(url) to update dictionary

    Returns
    -------
    slgadict : dictionary of National Soil Map data
    &#34;&#34;&#34;
    slgadict = {}
    slgadict[&#34;title&#34;] = &#34;SLGA&#34;
    slgadict[&#34;description&#34;] = &#34;National Soil and Landscape Grid of Australia&#34;
    slgadict[&#34;crs&#34;] = &#34;EPSG:4326&#34;
    slgadict[&#34;bbox&#34;] = [
        112.9995833334,
        -44.0004166670144,
        153.999583334061,
        -10.0004166664663,
    ]
    slgadict[&#34;resolution_arcsec&#34;] = 3
    slgadict[&#34;depth_min&#34;] = 0
    slgadict[&#34;depth_max&#34;] = 200
    slgadict[&#34;layers_url&#34;] = {
        &#34;Bulk_Density&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/BDW_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Organic_Carbon&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/SOC_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Clay&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/CLY_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Silt&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/SLT_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Sand&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/SND_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;pH_CaCl2&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/PHC_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Available_Water_Capacity&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/AWC_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Total_Nitrogen&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/NTO_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Total_Phosphorus&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/PTO_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Effective_Cation_Exchange_Capacity&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/ECE_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Depth_of_Regolith&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/DER_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Depth_of_Soil&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/DES_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
    }
    return slgadict


def getdict_license():
    &#34;&#34;&#34;
    Retrieves the SLGA license and attribution information as dict
    &#34;&#34;&#34;
    dict = {
        &#34;name&#34;: &#34;Soil and Landscape Grid of Australia (SLGA)&#34;,
        &#34;source_url&#34;: &#34;https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails.html&#34;,
        &#34;license&#34;: &#34;CC BY 4.0&#34;,
        &#34;license_title&#34;: &#34;Creative Commons Attribution 4.0 International (CC BY 4.0)&#34;,
        &#34;license_url&#34;: &#34;https://creativecommons.org/licenses/by/4.0/&#34;,
        &#34;copyright&#34;: &#34;(c) 2010-2022 CSIRO Australia, © 2020 TERN (University of Queensland)&#34;,
        &#34;attribution&#34;: &#34;CSIRO Australia, TERN (University of Queensland), and Geoscience Australia&#34;,
    }
    return dict


def plot_raster(infname):
    &#34;&#34;&#34;
    Read in raster tif with rasterio and visualise as map

    Parameters
    ----------
    infname : str
    &#34;&#34;&#34;
    data = rasterio.open(infname)
    # show image
    show(data)

    # show image with matplotlib
    # img = data.read(1)
    # plt.imshow(img, cmap=&#39;viridis&#39;)
    # plt.colorbar()


def get_capabilities(url):
    &#34;&#34;&#34;
    Get capabilities from WCS layer

    Parameters
    ----------
    url : str
        layer url

    Returns
    -------
    keys    : list
        layer identifiers
    titles  : list  of str
        layer titles
    descriptions : list of str
        layer descriptions
    bboxs   : list of floats
        layer bounding boxes
    &#34;&#34;&#34;

    # Create WCS object
    wcs = WebCoverageService(url, version=&#34;1.0.0&#34;)

    # URL address for national bulk density layer
    # url_bd = &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/BDW_ACLEP_AU_NAT_C/MapServer/WCSServer?SERVICE=WCS&amp;REQUEST=GetCapabilities&#34;
    # url_bd = &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/BDW_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;

    # Get coverages and content dict keys
    content = wcs.contents
    keys = content.keys()

    print(&#34;Operations possible: &#34;, [op.name for op in wcs.operations])

    # Get bounding boxes and crs for each coverage
    bbox_list = []
    title_list = []
    description_list = []
    for key in keys:
        print(f&#34;key: {key}&#34;)
        print(f&#34;title: {wcs[key].title}&#34;)
        title_list.append(wcs[key].title)
        print(f&#34;{wcs[key].abstract}&#34;)
        description_list.append(wcs[key].abstract)
        print(f&#34;bounding box: {wcs[key].boundingboxes}&#34;)
        bbox_list.append(wcs[key].boundingboxes)
        print(&#34;&#34;)

    return keys, title_list, description_list, bbox_list


def get_wcsmap(url, identifier, crs, bbox, resolution, outfname):
    &#34;&#34;&#34;
    Download and save geotiff from WCS layer

    Parameters
    ----------
    url : str
    identifier : str
        layer identifier
    crs : str
        layer crs
    bbox : list
        layer bounding box
    resolution : int
        layer resolution
    outfname : str
        output file name

    &#34;&#34;&#34;
    # Create WCS object
    filename = outfname.split(os.sep)[-1]
    if os.path.exists(outfname):
        utils.msg_warn(f&#34;{filename} already exists, skipping download&#34;)
        # logging.warning(f&#34;\u25b2 Download skipped: {filename} already exists&#34;)
        # logging.info(f&#34;  Location: {outfname}&#34;)

        return False
    else:
        with spin(f&#34;Downloading {filename}&#34;) as s:
            wcs = WebCoverageService(url, version=&#34;1.0.0&#34;)
            # Get data
            data = wcs.getCoverage(
                identifier,
                format=&#34;GEOTIFF&#34;,
                bbox=bbox,
                crs=crs,
                resx=resolution,
                resy=resolution,
            )
            # timeout=30)
            s(1)

        # Save data
        with open(outfname, &#34;wb&#34;) as f:
            f.write(data.read())
        return True


def depth2identifier(depth_min, depth_max):
    &#34;&#34;&#34;
    Get identifiers that correspond to depths and their corresponding confidence interval identifiers
    that lie within the depth range depth_min to depth_max.

    Parameters
    ----------
    depth_min : minimum depth [cm]
    depth_max : maximum depth [cm]

    Returns
    -------
    identifiers : layer identifiers
    identifiers_ci_5pc : identifiers for confidence interval 5%
    identifiers_ci_95pc : identifiers for confidence interval 95%
    depth_lower : lower depth of interval
    depth_upper : upper depth of interval
    &#34;&#34;&#34;
    depth_intervals = [0, 5, 15, 30, 60, 100, 200]
    identifiers = []
    identifiers_ci_5pc = []
    identifiers_ci_95pc = []
    depths_lower = []
    depths_upper = []
    # Loop over depth intervals
    for i in range(len(depth_intervals) - 1):
        if (depth_min &lt;= depth_intervals[i]) &amp; (depth_max &gt;= depth_intervals[i + 1]):
            identifiers.append(str(3 * i + 1))
            identifiers_ci_5pc.append(str(3 * i + 3))
            identifiers_ci_95pc.append(str(3 * i + 2))
            depths_lower.append(depth_intervals[i])
            depths_upper.append(depth_intervals[i + 1])
    return (
        identifiers,
        identifiers_ci_5pc,
        identifiers_ci_95pc,
        depths_lower,
        depths_upper,
    )


def identifier2depthbounds(depths):
    &#34;&#34;&#34;
    Get min and max depth of list of depth strings

    Parameters
    ----------
    depth_list: list of depth

    Returns
    -------
    min depth
    max depth
    &#34;&#34;&#34;
    depth_options = [&#34;0-5cm&#34;, &#34;5-15cm&#34;, &#34;15-30cm&#34;,
                     &#34;30-60cm&#34;, &#34;60-100cm&#34;, &#34;100-200cm&#34;]
    depth_intervals = [0, 5, 15, 30, 60, 100, 200]
    # Check first if entries valid
    for depth in depth_options:
        assert (
            depth in depth_options
        ), f&#34;depth should be one of the following options {depth_options}&#34;
    # find min and max depth
    ncount = 0
    for i in range(len(depth_options)):
        if depth_options[i] in depths:
            depth_max = depth_intervals[i + 1]
            if ncount == 0:
                depth_min = depth_intervals[i]
            ncount += 1
    assert ncount == len(depths), f&#34;ncount = {ncount}&#34;
    return depth_min, depth_max


def get_slga_layers(
    layernames,
    bbox,
    outpath,
    resolution=3,
    depth_min=0,
    depth_max=200,
    get_ci=True,
    verbose=False,
):
    &#34;&#34;&#34;
    Download layers from SLGA data server and saves as geotif.

    Parameters
    ----------
    layernames : list of layer names
    bbox : bounding box [min, miny, maxx, maxy] in
    resolution : resolution in arcsec (Default: 3 arcsec ~ 90m, which is native resolution of SLGA data)
    depth_min : minimum depth (Default: 0 cm). If depth_min and depth_max are lists, then must have same length as layernames
    depth_max : maximum depth (Default: 200 cm, maximum depth of SLGA data)
    outpath : output path

    Returns
    -------
    fnames_out : list of output file names

    TBD: check that Request image size does not exceeds allowed limit. Set Timeout?
    &#34;&#34;&#34;

    # Logger setup
    if verbose:
        write_logs.setup(level=&#34;info&#34;)
    else:
        write_logs.setup()

    # Check if layernames is a list
    if not isinstance(layernames, list):
        layernames = [layernames]


    # Check if depth_min and depth_max are lists:
    if not isinstance(depth_min, list):
        depth_min = [depth_min] * len(layernames)
    if not isinstance(depth_max, list):
        depth_max = [depth_max] * len(layernames)

    assert len(depth_min) == len(depth_max), &#34;depth_min and depth_max should be lists of same length&#34;
    assert len(depth_min) == len(layernames), &#34;depth_min and depth_max should be lists with same length as layernames&#34;
    

    # Check if outpath exist, if not create it
    os.makedirs(outpath, exist_ok=True)

    # If the resolution passed is None, set to native resolution of datasource
    if resolution is None:
        resolution = get_slgadict()[&#34;resolution_arcsec&#34;]

    # Get SLGA dictionary
    slgadict = get_slgadict()
    layers_url = slgadict[&#34;layers_url&#34;]

    # Convert resolution from arcsec to degree
    resolution_deg = resolution / 3600.0

    # set crs
    crs = &#34;EPSG:4326&#34;

    fnames_out = []
    # Loop over layers
    for idx, layername in enumerate(layernames):
        # Get layer url
        layer_url = layers_url[layername]
        # logging.print(f&#34;Downloading {layername}...&#34;)
        # Get depth identifiers for layers
        (identifiers,
        identifiers_ci_5pc,
        identifiers_ci_95pc,
        depth_lower,
        depth_upper,
        ) = depth2identifier(depth_min[idx], depth_max[idx])
        for i in range(len(identifiers)):
            identifier = identifiers[i]
            # Get layer name
            layer_depth_name = f&#34;SLGA_{layername}_{depth_lower[i]}-{depth_upper[i]}cm&#34;
            # Layer fname
            fname_out = os.path.join(outpath, layer_depth_name + &#34;.tif&#34;)
            # download data
            dl = get_wcsmap(layer_url, identifier, crs,
                            bbox, resolution_deg, fname_out)
            # if dl is True:
            #     print(f&#34;✔ {layer_depth_name}&#34;)
            # logging.print(f&#34;✔ | {layer_depth_name}&#34;)
            # logging.info(f&#34;  | saved to: {fname_out}&#34;)
            fnames_out.append(fname_out)
        if get_ci:
            # logging.info(f&#34;Downloading confidence intervals for {layername}...&#34;)
            for i in range(len(identifiers)):
                # 5th percentile
                identifier = identifiers_ci_5pc[i]
                # Get layer name
                layer_depth_name = (
                    f&#34;SLGA_{layername}_{depth_lower[i]}-{depth_upper[i]}cm&#34;
                )
                # Layer fname
                fname_out = os.path.join(
                    outpath, layer_depth_name + &#34;_5percentile.tif&#34;)
                # download data
                get_wcsmap(layer_url, identifier, crs,
                           bbox, resolution_deg, fname_out)
                # 95th percentile
                identifier = identifiers_ci_95pc[i]
                # Get layer name
                layer_depth_name = (
                    f&#34;SLGA_{layername}_{depth_lower[i]}-{depth_upper[i]}cm&#34;
                )
                # Layer fname
                fname_out = os.path.join(
                    outpath, layer_depth_name + &#34;_95percentile.tif&#34;
                )
                # download data
                dl = get_wcsmap(
                    layer_url, identifier, crs, bbox, resolution_deg, fname_out
                )
                # if dl is True:
                # print(f&#34;✔ {layer_depth_name} CIs&#34;)
                # logging.print(f&#34;✔ {layer_depth_name} CIs&#34;)
                # logging.info(f&#34;  saved to: {outpath}&#34;)
    # logging.print(&#34;SLGA download(s) complete&#34;)
    return fnames_out


### test functions ###


def test_wcs():

    layername = &#34;Bulk_Density&#34;
    # Get SLGA dictionary
    slgadict = get_slgadict()
    # get layer url
    layers_url = slgadict[&#34;layers_url&#34;]
    url = layers_url[layername]
    # url = &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/BDW_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;

    # Get capabilities
    keys, titles, descriptions, bboxs = get_capabilities(url)

    # define bounding box for retrieval (simple test here for ~ half of Australia)
    bbox = (130, -44, 153.9, -11)
    # define resolution (in arcsec per pixel since crs is in WGS84).
    # Note that there is a request size limit for the WCS service.
    resolution = 50
    # define output file name
    outpath = &#34;result_slga_testfunction&#34;

    # Get data for first layer depth
    fnames_out = get_slga_layers(
        &#34;Bulk_Density&#34;, bbox, outpath, resolution, depth_min=0, depth_max=5
    )

    # crs = &#39;EPSG:4326&#39; # WGS84
    # Get data (here only for first layer)
    # identifier = &#39;1&#39;
    # fname_out = &#39;result_slga_testfunction.tif&#39;
    # get_wcsmap(url, identifier, crs, bbox, resolution / 3600., fname_out)

    # Show data
    plot_raster(fnames_out)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="geodata_harvester.getdata_slga.depth2identifier"><code class="name flex">
<span>def <span class="ident">depth2identifier</span></span>(<span>depth_min, depth_max)</span>
</code></dt>
<dd>
<div class="desc"><p>Get identifiers that correspond to depths and their corresponding confidence interval identifiers
that lie within the depth range depth_min to depth_max.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>depth_min</code></strong> :&ensp;<code>minimum depth [cm]</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>depth_max</code></strong> :&ensp;<code>maximum depth [cm]</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>identifiers</code></strong> :&ensp;<code>layer identifiers</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>identifiers_ci_5pc</code></strong> :&ensp;<code>identifiers for confidence interval 5%</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>identifiers_ci_95pc</code></strong> :&ensp;<code>identifiers for confidence interval 95%</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>depth_lower</code></strong> :&ensp;<code>lower depth</code> of <code>interval</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>depth_upper</code></strong> :&ensp;<code>upper depth</code> of <code>interval</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def depth2identifier(depth_min, depth_max):
    &#34;&#34;&#34;
    Get identifiers that correspond to depths and their corresponding confidence interval identifiers
    that lie within the depth range depth_min to depth_max.

    Parameters
    ----------
    depth_min : minimum depth [cm]
    depth_max : maximum depth [cm]

    Returns
    -------
    identifiers : layer identifiers
    identifiers_ci_5pc : identifiers for confidence interval 5%
    identifiers_ci_95pc : identifiers for confidence interval 95%
    depth_lower : lower depth of interval
    depth_upper : upper depth of interval
    &#34;&#34;&#34;
    depth_intervals = [0, 5, 15, 30, 60, 100, 200]
    identifiers = []
    identifiers_ci_5pc = []
    identifiers_ci_95pc = []
    depths_lower = []
    depths_upper = []
    # Loop over depth intervals
    for i in range(len(depth_intervals) - 1):
        if (depth_min &lt;= depth_intervals[i]) &amp; (depth_max &gt;= depth_intervals[i + 1]):
            identifiers.append(str(3 * i + 1))
            identifiers_ci_5pc.append(str(3 * i + 3))
            identifiers_ci_95pc.append(str(3 * i + 2))
            depths_lower.append(depth_intervals[i])
            depths_upper.append(depth_intervals[i + 1])
    return (
        identifiers,
        identifiers_ci_5pc,
        identifiers_ci_95pc,
        depths_lower,
        depths_upper,
    )</code></pre>
</details>
</dd>
<dt id="geodata_harvester.getdata_slga.get_capabilities"><code class="name flex">
<span>def <span class="ident">get_capabilities</span></span>(<span>url)</span>
</code></dt>
<dd>
<div class="desc"><p>Get capabilities from WCS layer</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>url</code></strong> :&ensp;<code>str</code></dt>
<dd>layer url</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>keys
: list</code></dt>
<dd>layer identifiers</dd>
<dt><code>titles
: list</code>
of <code>str</code></dt>
<dd>layer titles</dd>
<dt><strong><code>descriptions</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>layer descriptions</dd>
<dt><code>bboxs
: list</code> of <code>floats</code></dt>
<dd>layer bounding boxes</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_capabilities(url):
    &#34;&#34;&#34;
    Get capabilities from WCS layer

    Parameters
    ----------
    url : str
        layer url

    Returns
    -------
    keys    : list
        layer identifiers
    titles  : list  of str
        layer titles
    descriptions : list of str
        layer descriptions
    bboxs   : list of floats
        layer bounding boxes
    &#34;&#34;&#34;

    # Create WCS object
    wcs = WebCoverageService(url, version=&#34;1.0.0&#34;)

    # URL address for national bulk density layer
    # url_bd = &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/BDW_ACLEP_AU_NAT_C/MapServer/WCSServer?SERVICE=WCS&amp;REQUEST=GetCapabilities&#34;
    # url_bd = &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/BDW_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;

    # Get coverages and content dict keys
    content = wcs.contents
    keys = content.keys()

    print(&#34;Operations possible: &#34;, [op.name for op in wcs.operations])

    # Get bounding boxes and crs for each coverage
    bbox_list = []
    title_list = []
    description_list = []
    for key in keys:
        print(f&#34;key: {key}&#34;)
        print(f&#34;title: {wcs[key].title}&#34;)
        title_list.append(wcs[key].title)
        print(f&#34;{wcs[key].abstract}&#34;)
        description_list.append(wcs[key].abstract)
        print(f&#34;bounding box: {wcs[key].boundingboxes}&#34;)
        bbox_list.append(wcs[key].boundingboxes)
        print(&#34;&#34;)

    return keys, title_list, description_list, bbox_list</code></pre>
</details>
</dd>
<dt id="geodata_harvester.getdata_slga.get_slga_layers"><code class="name flex">
<span>def <span class="ident">get_slga_layers</span></span>(<span>layernames, bbox, outpath, resolution=3, depth_min=0, depth_max=200, get_ci=True, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Download layers from SLGA data server and saves as geotif.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>layernames</code></strong> :&ensp;<code>list</code> of <code>layer names</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>bbox</code></strong> :&ensp;<code>bounding box [min, miny, maxx, maxy] in</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>resolution</code></strong> :&ensp;<code>resolution in arcsec (Default: 3 arcsec ~ 90m, which is native resolution</code> of <code>SLGA data)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>depth_min</code></strong> :&ensp;<code>minimum depth (Default: 0 cm). If depth_min and depth_max are lists, then must have same length as layernames</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>depth_max</code></strong> :&ensp;<code>maximum depth (Default: 200 cm, maximum depth</code> of <code>SLGA data)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>outpath</code></strong> :&ensp;<code>output path</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fnames_out</code></strong> :&ensp;<code>list</code> of <code>output file names</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>TBD</code></strong> :&ensp;<code>check that Request image size does not exceeds allowed limit. Set Timeout?</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_slga_layers(
    layernames,
    bbox,
    outpath,
    resolution=3,
    depth_min=0,
    depth_max=200,
    get_ci=True,
    verbose=False,
):
    &#34;&#34;&#34;
    Download layers from SLGA data server and saves as geotif.

    Parameters
    ----------
    layernames : list of layer names
    bbox : bounding box [min, miny, maxx, maxy] in
    resolution : resolution in arcsec (Default: 3 arcsec ~ 90m, which is native resolution of SLGA data)
    depth_min : minimum depth (Default: 0 cm). If depth_min and depth_max are lists, then must have same length as layernames
    depth_max : maximum depth (Default: 200 cm, maximum depth of SLGA data)
    outpath : output path

    Returns
    -------
    fnames_out : list of output file names

    TBD: check that Request image size does not exceeds allowed limit. Set Timeout?
    &#34;&#34;&#34;

    # Logger setup
    if verbose:
        write_logs.setup(level=&#34;info&#34;)
    else:
        write_logs.setup()

    # Check if layernames is a list
    if not isinstance(layernames, list):
        layernames = [layernames]


    # Check if depth_min and depth_max are lists:
    if not isinstance(depth_min, list):
        depth_min = [depth_min] * len(layernames)
    if not isinstance(depth_max, list):
        depth_max = [depth_max] * len(layernames)

    assert len(depth_min) == len(depth_max), &#34;depth_min and depth_max should be lists of same length&#34;
    assert len(depth_min) == len(layernames), &#34;depth_min and depth_max should be lists with same length as layernames&#34;
    

    # Check if outpath exist, if not create it
    os.makedirs(outpath, exist_ok=True)

    # If the resolution passed is None, set to native resolution of datasource
    if resolution is None:
        resolution = get_slgadict()[&#34;resolution_arcsec&#34;]

    # Get SLGA dictionary
    slgadict = get_slgadict()
    layers_url = slgadict[&#34;layers_url&#34;]

    # Convert resolution from arcsec to degree
    resolution_deg = resolution / 3600.0

    # set crs
    crs = &#34;EPSG:4326&#34;

    fnames_out = []
    # Loop over layers
    for idx, layername in enumerate(layernames):
        # Get layer url
        layer_url = layers_url[layername]
        # logging.print(f&#34;Downloading {layername}...&#34;)
        # Get depth identifiers for layers
        (identifiers,
        identifiers_ci_5pc,
        identifiers_ci_95pc,
        depth_lower,
        depth_upper,
        ) = depth2identifier(depth_min[idx], depth_max[idx])
        for i in range(len(identifiers)):
            identifier = identifiers[i]
            # Get layer name
            layer_depth_name = f&#34;SLGA_{layername}_{depth_lower[i]}-{depth_upper[i]}cm&#34;
            # Layer fname
            fname_out = os.path.join(outpath, layer_depth_name + &#34;.tif&#34;)
            # download data
            dl = get_wcsmap(layer_url, identifier, crs,
                            bbox, resolution_deg, fname_out)
            # if dl is True:
            #     print(f&#34;✔ {layer_depth_name}&#34;)
            # logging.print(f&#34;✔ | {layer_depth_name}&#34;)
            # logging.info(f&#34;  | saved to: {fname_out}&#34;)
            fnames_out.append(fname_out)
        if get_ci:
            # logging.info(f&#34;Downloading confidence intervals for {layername}...&#34;)
            for i in range(len(identifiers)):
                # 5th percentile
                identifier = identifiers_ci_5pc[i]
                # Get layer name
                layer_depth_name = (
                    f&#34;SLGA_{layername}_{depth_lower[i]}-{depth_upper[i]}cm&#34;
                )
                # Layer fname
                fname_out = os.path.join(
                    outpath, layer_depth_name + &#34;_5percentile.tif&#34;)
                # download data
                get_wcsmap(layer_url, identifier, crs,
                           bbox, resolution_deg, fname_out)
                # 95th percentile
                identifier = identifiers_ci_95pc[i]
                # Get layer name
                layer_depth_name = (
                    f&#34;SLGA_{layername}_{depth_lower[i]}-{depth_upper[i]}cm&#34;
                )
                # Layer fname
                fname_out = os.path.join(
                    outpath, layer_depth_name + &#34;_95percentile.tif&#34;
                )
                # download data
                dl = get_wcsmap(
                    layer_url, identifier, crs, bbox, resolution_deg, fname_out
                )
                # if dl is True:
                # print(f&#34;✔ {layer_depth_name} CIs&#34;)
                # logging.print(f&#34;✔ {layer_depth_name} CIs&#34;)
                # logging.info(f&#34;  saved to: {outpath}&#34;)
    # logging.print(&#34;SLGA download(s) complete&#34;)
    return fnames_out</code></pre>
</details>
</dd>
<dt id="geodata_harvester.getdata_slga.get_slgadict"><code class="name flex">
<span>def <span class="ident">get_slgadict</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Get dictionary of SLGA data.</p>
<p>The Soil Facility produced a range of digital soil attribute products.
Each product contains six digital soil attribute maps, and their upper and lower confidence limits,
representing the soil attribute at six depths: 0-5cm, 5-15cm, 15-30cm, 30-60cm, 60-100cm and 100-200cm.
These depths are consistent with the specifications of the GlobalSoilMap.net project (<a href="http://www.globalsoilmap.net/">http://www.globalsoilmap.net/</a>).
The digital soil attribute maps are in raster format at a resolution of 3 arc sec (~90 x 90 m pixels).</p>
<p>Period (temporal coverage; approximately): 1950-2013;
Spatial resolution: 3 arc seconds (approx 90m);
Data license : Creative Commons Attribution 3.0 (CC By);
Target data standard: GlobalSoilMap specifications;
Format: GeoTIFF.</p>
<p>Run function get_capabilities(url) to update dictionary</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>slgadict</code></strong> :&ensp;<code>dictionary</code> of <code>National Soil Map data</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_slgadict():
    &#34;&#34;&#34;
    Get dictionary of SLGA data.

    The Soil Facility produced a range of digital soil attribute products.
    Each product contains six digital soil attribute maps, and their upper and lower confidence limits,
    representing the soil attribute at six depths: 0-5cm, 5-15cm, 15-30cm, 30-60cm, 60-100cm and 100-200cm.
    These depths are consistent with the specifications of the GlobalSoilMap.net project (http://www.globalsoilmap.net/).
    The digital soil attribute maps are in raster format at a resolution of 3 arc sec (~90 x 90 m pixels).

    Period (temporal coverage; approximately): 1950-2013;
    Spatial resolution: 3 arc seconds (approx 90m);
    Data license : Creative Commons Attribution 3.0 (CC By);
    Target data standard: GlobalSoilMap specifications;
    Format: GeoTIFF.

    Run function get_capabilities(url) to update dictionary

    Returns
    -------
    slgadict : dictionary of National Soil Map data
    &#34;&#34;&#34;
    slgadict = {}
    slgadict[&#34;title&#34;] = &#34;SLGA&#34;
    slgadict[&#34;description&#34;] = &#34;National Soil and Landscape Grid of Australia&#34;
    slgadict[&#34;crs&#34;] = &#34;EPSG:4326&#34;
    slgadict[&#34;bbox&#34;] = [
        112.9995833334,
        -44.0004166670144,
        153.999583334061,
        -10.0004166664663,
    ]
    slgadict[&#34;resolution_arcsec&#34;] = 3
    slgadict[&#34;depth_min&#34;] = 0
    slgadict[&#34;depth_max&#34;] = 200
    slgadict[&#34;layers_url&#34;] = {
        &#34;Bulk_Density&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/BDW_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Organic_Carbon&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/SOC_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Clay&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/CLY_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Silt&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/SLT_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Sand&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/SND_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;pH_CaCl2&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/PHC_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Available_Water_Capacity&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/AWC_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Total_Nitrogen&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/NTO_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Total_Phosphorus&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/PTO_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Effective_Cation_Exchange_Capacity&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/ECE_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Depth_of_Regolith&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/DER_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
        &#34;Depth_of_Soil&#34;: &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/DES_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;,
    }
    return slgadict</code></pre>
</details>
</dd>
<dt id="geodata_harvester.getdata_slga.get_wcsmap"><code class="name flex">
<span>def <span class="ident">get_wcsmap</span></span>(<span>url, identifier, crs, bbox, resolution, outfname)</span>
</code></dt>
<dd>
<div class="desc"><p>Download and save geotiff from WCS layer</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>url</code></strong> :&ensp;<code>str</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>identifier</code></strong> :&ensp;<code>str</code></dt>
<dd>layer identifier</dd>
<dt><strong><code>crs</code></strong> :&ensp;<code>str</code></dt>
<dd>layer crs</dd>
<dt><strong><code>bbox</code></strong> :&ensp;<code>list</code></dt>
<dd>layer bounding box</dd>
<dt><strong><code>resolution</code></strong> :&ensp;<code>int</code></dt>
<dd>layer resolution</dd>
<dt><strong><code>outfname</code></strong> :&ensp;<code>str</code></dt>
<dd>output file name</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_wcsmap(url, identifier, crs, bbox, resolution, outfname):
    &#34;&#34;&#34;
    Download and save geotiff from WCS layer

    Parameters
    ----------
    url : str
    identifier : str
        layer identifier
    crs : str
        layer crs
    bbox : list
        layer bounding box
    resolution : int
        layer resolution
    outfname : str
        output file name

    &#34;&#34;&#34;
    # Create WCS object
    filename = outfname.split(os.sep)[-1]
    if os.path.exists(outfname):
        utils.msg_warn(f&#34;{filename} already exists, skipping download&#34;)
        # logging.warning(f&#34;\u25b2 Download skipped: {filename} already exists&#34;)
        # logging.info(f&#34;  Location: {outfname}&#34;)

        return False
    else:
        with spin(f&#34;Downloading {filename}&#34;) as s:
            wcs = WebCoverageService(url, version=&#34;1.0.0&#34;)
            # Get data
            data = wcs.getCoverage(
                identifier,
                format=&#34;GEOTIFF&#34;,
                bbox=bbox,
                crs=crs,
                resx=resolution,
                resy=resolution,
            )
            # timeout=30)
            s(1)

        # Save data
        with open(outfname, &#34;wb&#34;) as f:
            f.write(data.read())
        return True</code></pre>
</details>
</dd>
<dt id="geodata_harvester.getdata_slga.getdict_license"><code class="name flex">
<span>def <span class="ident">getdict_license</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieves the SLGA license and attribution information as dict</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getdict_license():
    &#34;&#34;&#34;
    Retrieves the SLGA license and attribution information as dict
    &#34;&#34;&#34;
    dict = {
        &#34;name&#34;: &#34;Soil and Landscape Grid of Australia (SLGA)&#34;,
        &#34;source_url&#34;: &#34;https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails.html&#34;,
        &#34;license&#34;: &#34;CC BY 4.0&#34;,
        &#34;license_title&#34;: &#34;Creative Commons Attribution 4.0 International (CC BY 4.0)&#34;,
        &#34;license_url&#34;: &#34;https://creativecommons.org/licenses/by/4.0/&#34;,
        &#34;copyright&#34;: &#34;(c) 2010-2022 CSIRO Australia, © 2020 TERN (University of Queensland)&#34;,
        &#34;attribution&#34;: &#34;CSIRO Australia, TERN (University of Queensland), and Geoscience Australia&#34;,
    }
    return dict</code></pre>
</details>
</dd>
<dt id="geodata_harvester.getdata_slga.identifier2depthbounds"><code class="name flex">
<span>def <span class="ident">identifier2depthbounds</span></span>(<span>depths)</span>
</code></dt>
<dd>
<div class="desc"><p>Get min and max depth of list of depth strings</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>depth_list</code></strong> :&ensp;<code>list</code> of <code>depth</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>min depth</code></dt>
<dd>&nbsp;</dd>
<dt><code>max depth</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identifier2depthbounds(depths):
    &#34;&#34;&#34;
    Get min and max depth of list of depth strings

    Parameters
    ----------
    depth_list: list of depth

    Returns
    -------
    min depth
    max depth
    &#34;&#34;&#34;
    depth_options = [&#34;0-5cm&#34;, &#34;5-15cm&#34;, &#34;15-30cm&#34;,
                     &#34;30-60cm&#34;, &#34;60-100cm&#34;, &#34;100-200cm&#34;]
    depth_intervals = [0, 5, 15, 30, 60, 100, 200]
    # Check first if entries valid
    for depth in depth_options:
        assert (
            depth in depth_options
        ), f&#34;depth should be one of the following options {depth_options}&#34;
    # find min and max depth
    ncount = 0
    for i in range(len(depth_options)):
        if depth_options[i] in depths:
            depth_max = depth_intervals[i + 1]
            if ncount == 0:
                depth_min = depth_intervals[i]
            ncount += 1
    assert ncount == len(depths), f&#34;ncount = {ncount}&#34;
    return depth_min, depth_max</code></pre>
</details>
</dd>
<dt id="geodata_harvester.getdata_slga.plot_raster"><code class="name flex">
<span>def <span class="ident">plot_raster</span></span>(<span>infname)</span>
</code></dt>
<dd>
<div class="desc"><p>Read in raster tif with rasterio and visualise as map</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>infname</code></strong> :&ensp;<code>str</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_raster(infname):
    &#34;&#34;&#34;
    Read in raster tif with rasterio and visualise as map

    Parameters
    ----------
    infname : str
    &#34;&#34;&#34;
    data = rasterio.open(infname)
    # show image
    show(data)

    # show image with matplotlib
    # img = data.read(1)
    # plt.imshow(img, cmap=&#39;viridis&#39;)
    # plt.colorbar()</code></pre>
</details>
</dd>
<dt id="geodata_harvester.getdata_slga.test_wcs"><code class="name flex">
<span>def <span class="ident">test_wcs</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_wcs():

    layername = &#34;Bulk_Density&#34;
    # Get SLGA dictionary
    slgadict = get_slgadict()
    # get layer url
    layers_url = slgadict[&#34;layers_url&#34;]
    url = layers_url[layername]
    # url = &#34;https://www.asris.csiro.au/ArcGIS/services/TERN/BDW_ACLEP_AU_NAT_C/MapServer/WCSServer&#34;

    # Get capabilities
    keys, titles, descriptions, bboxs = get_capabilities(url)

    # define bounding box for retrieval (simple test here for ~ half of Australia)
    bbox = (130, -44, 153.9, -11)
    # define resolution (in arcsec per pixel since crs is in WGS84).
    # Note that there is a request size limit for the WCS service.
    resolution = 50
    # define output file name
    outpath = &#34;result_slga_testfunction&#34;

    # Get data for first layer depth
    fnames_out = get_slga_layers(
        &#34;Bulk_Density&#34;, bbox, outpath, resolution, depth_min=0, depth_max=5
    )

    # crs = &#39;EPSG:4326&#39; # WGS84
    # Get data (here only for first layer)
    # identifier = &#39;1&#39;
    # fname_out = &#39;result_slga_testfunction.tif&#39;
    # get_wcsmap(url, identifier, crs, bbox, resolution / 3600., fname_out)

    # Show data
    plot_raster(fnames_out)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="geodata_harvester" href="index.html">geodata_harvester</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="geodata_harvester.getdata_slga.depth2identifier" href="#geodata_harvester.getdata_slga.depth2identifier">depth2identifier</a></code></li>
<li><code><a title="geodata_harvester.getdata_slga.get_capabilities" href="#geodata_harvester.getdata_slga.get_capabilities">get_capabilities</a></code></li>
<li><code><a title="geodata_harvester.getdata_slga.get_slga_layers" href="#geodata_harvester.getdata_slga.get_slga_layers">get_slga_layers</a></code></li>
<li><code><a title="geodata_harvester.getdata_slga.get_slgadict" href="#geodata_harvester.getdata_slga.get_slgadict">get_slgadict</a></code></li>
<li><code><a title="geodata_harvester.getdata_slga.get_wcsmap" href="#geodata_harvester.getdata_slga.get_wcsmap">get_wcsmap</a></code></li>
<li><code><a title="geodata_harvester.getdata_slga.getdict_license" href="#geodata_harvester.getdata_slga.getdict_license">getdict_license</a></code></li>
<li><code><a title="geodata_harvester.getdata_slga.identifier2depthbounds" href="#geodata_harvester.getdata_slga.identifier2depthbounds">identifier2depthbounds</a></code></li>
<li><code><a title="geodata_harvester.getdata_slga.plot_raster" href="#geodata_harvester.getdata_slga.plot_raster">plot_raster</a></code></li>
<li><code><a title="geodata_harvester.getdata_slga.test_wcs" href="#geodata_harvester.getdata_slga.test_wcs">test_wcs</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>