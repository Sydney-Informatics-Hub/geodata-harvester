[
  {
    "objectID": "docs/Data_Overview.html",
    "href": "docs/Data_Overview.html",
    "title": "Data Overview",
    "section": "",
    "text": "Soil Data 3D SLGA\nSILO Climate Database\nNational Digital Elevation Model 1 Second Hydrologically Enforced\nDigital Earth Australia Geoscience Earth Observations\nGSKY Data Server for DEA Geoscience Earth Observations\nRadiometric Data\nLandscape Data SLGA\n\n\n\n\nDescription: The Soil Facility produced a range of digital soil attribute products as Soil and Landscape Grid of Australia (SLGA). Each product contains six digital soil attribute maps, and their upper and lower confidence limits, representing the soil attribute at six depths: 0-5cm, 5-15cm, 15-30cm, 30-60cm, 60-100cm and 100-200cm.\nModule name: getdata_slga.py\nBounding Box: Long_min: 113.00, Lat_min: -44.00, Long_max: 154.00, Lat_max: -10.00\nPeriod (temporal coverage; approximately): 1950-2013\nResolution: 3 arcsec\nSource: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails-SoilAttributes.html\nLicense: Creative Commons Attribution 3.0 (CC By)\nAttribution: CSIRO Australia, TERN (University of Queensland), and Geoscience Australia\nLayernames:\n\n‘Bulk_Density’ :\n\nTitle: Bulk Density (whole earth)\nDescription: Bulk Density of the whole soil (including coarse fragments) in mass per unit volume by a method equivalent to the core method\nUnit: g/cm3\n\n‘Organic_Carbon’ :\n\nTitle: Organic Carbon\nDescription: Mass fraction of carbon by weight in the &lt; 2 mm soil material as determined by dry combustion at 900 Celcius\nUnit: %\n\n‘Clay’ :\n\nTitle: Clay\nDescription: &lt; 2 um mass fraction of the &lt; 2 mm soil material determined using the pipette method\nUnit: %\n\n‘Silt’ :\n\nTitle: Silt\nDescription: 2-20 um mass fraction of the &lt; 2 mm soil material determined using the pipette method\nUnit: %\n\n‘Sand’ :\n\nTitle: Sand\nDescription: 20 um - 2 mm mass fraction of the &lt; 2 mm soil material determined using the pipette method\nUnit: %\n\n‘pH_CaCl2’ :\n\nTitle: pH (CaCl2)\nDescription: pH of 1:5 soil/0.01M calcium chloride extract\nUnit: none\n\n‘Available_Water_Capacity’ :\n\nTitle: Available Water Capacity\nDescription: Available water capacity computed for each of the specified depth increments\nUnit: %\n\n‘Total_Nitrogen’ :\n\nTitle: Total Nitrogen\nDescription: Mass fraction of total nitrogen in the soil by weight\nUnit: %\n\n‘Total_Phosphorus’ :\n\nTitle: Total Phosphorus\nDescription: Mass fraction of total phosphorus in the soil by weight\nUnit: %\n\n‘Effective_Cation_Exchange_Capacity’ :\n\nTitle: Effective Cation Exchange Capacity\nDescription: Cations extracted using barium chloride (BaCl2) plus exchangeable H + Al\nUnit: meq/100g\n\n‘Depth_of_Regolith’ :\n\nTitle: Depth of Regolith\nDescription: Depth to hard rock. Depth is inclusive of all regolith.\nUnit: m\n\n‘Depth_of_Soil’ :\n\nTitle: Depth of Soil\nDescription: Depth of soil profile (A & B horizons)\nUnit: m\n\n\n\n\n\nDescription: SILO is containing continuous daily climate data for Australia from 1889 to present.\nModule name: getdata_silo.py\nBounding Box = Long_min: 112.00, Lat_min: -44.00, Long_max: 154.00, Lat_max: -10.00\nUpdates: Daily\nResolution: native: 180 arcsec\nSource: https://www.longpaddock.qld.gov.au/silo/gridded-data/\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: State of Queensland (Queensland Department of Environment and Science) 2020.\nLayernames:\n\n‘daily_rain’ (Daily rainfall, mm)\n‘monthly_rain’ (Monthly rainfall, mm)\n‘max_temp’ (Maximum temperature, deg C)\n‘min_temp’ (Minimum temperature. deg C)\n‘vp’ (Vapour pressure, hPa)\n‘vp_deficit’ (Vapour pressure deficit, hPa)\n‘evap_pan’ (Class A pan evaporation, mm)\n‘evap_syn’ (Synthetic estimate, mm)\n‘evap_comb’ (Combination: synthetic estimate pre-1970, class A pan 1970 onwards, mm)\n‘evap_morton_lake’ (Morton’s shallow lake evaporation, mm)\n‘radiation’ (Solar radiation: Solar exposure, consisting of both direct and diffuse components, MJ/m2)\n‘rh_tmax’ (Relative humidity: Relative humidity at the time of maximum temperature, %)\n‘rh_tmin’ (Relative humidity at the time of minimum temperature, %)\n‘et_short_crop’ (Evapotranspiration FAO564 short crop, mm)\n‘et_tall_crop’ (ASCE5 tall crop6, mm)\n‘et_morton_actual’ (Morton’s areal actual evapotranspiration, mm)\n‘et_morton_potential’ (Morton’s point potential evapotranspiration, mm)\n‘et_morton_wet’ (Morton’s wet-environment areal potential evapotranspiration over land, mm)\n‘mslp’ (Mean sea level pressure Mean sea level pressure, hPa)\n\n\n\n\nDescription: Digital Elevation Model (DEM) of Australia derived from STRM with 1 Second Grid - Hydrologically Enforced\nModule name: getdata_dem.py\nBounding Box = Long_min: 112.00, Lat_min: -44.00, Long_max: 154.00, Lat_max: -10.00\nUpdates: None\nResolution: native: 1 arcsec\nSource: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails.html\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: Commonwealth of Australia (Geoscience Australia)\nLayernames:\n\n‘DEM_1s’\n\nTitle: DEM SRTM 1 Second Hydro Enforced\nDescription: The 1 second SRTM derived hydrologically enforced DEM (DEM-H Version 1.0) is a 1 arc second (~30 m) gridded digital elevation model (DEM) that has been hydrologically conditioned and drainage enforced. The DEM-H captures flow paths based on SRTM elevations and mapped stream lines, and supports delineation of catchments and related hydrological attributes.\n\n\n\n\n\nDescription: Digital Earth Australia’s (DEA) Landsat Surface Reflectance products take Landsat 5 Thematic Mapper (TM), Landsat 7 Enhanced Thematic Mapper Plus (ETM+) and Landsat 8 Operational Land Imager (OLI) imagery captured over the Australian continent and corrects for inconsistencies across land and coastal fringes. The result is accurate and standardised surface reflectance data, which is instrumental in identifying and quantifying environmental change. DEA’s Landsat Surface Reflectance products form a single, cohesive Analysis Ready Data (ARD) package, which allows you to analyse surface reflectance data as is without the need to apply additional corrections.\nModule name: getdata_dea.py\nBounding Box: variable (see layernames)\nResolution: variable (depending on layer, typically 25m)\nUpdates: Daily to yearly\nSource: https://docs.dea.ga.gov.au/notebooks/DEA_datasets/DEA_Landsat_Surface_Reflectance.html\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: Digital Earth Australia (DEA)\nLayernames:\n\n‘ga_ls_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat)\ndescription: Geoscience Australia Landsat 5 Thematic Mapper Analysis Ready Data Collection 3\nbounding box: (110.696007613984, -45.6734535062289, 156.154528040633, -8.13764292647926)\ndate limits: [‘1986-08-16’, ‘2022-09-05’]\nNumber of bands: 7\n\n‘s2_nrt_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2 Near Real-Time)\ndescription: Sentinel-2A MSI ARD NRT - NBAR NBART and Pixel Quality\nbounding box: (109.989859933428, -45.2413329418709, 155.307643731418, -9.9300073889701)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 23\n\n‘s2_ard_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2)\ndescription: Sentinel-2A MSI Definitive ARD - NBART and Pixel Quality\nbounding box: (109.968510816964, -45.2234942244028, 156.101505058599, -9.02727104242043)\ndate limits: [‘2015-07-12’, ‘2022-09-13’]\nNumber of bands: 12\n\n‘ga_ls8c_nbart_gm_cyear_3’:\n\ntitle: DEA GeoMAD (Landsat 8 OLI-TIRS)\ndescription: Geoscience Australia Landsat Nadir BRDF Adjusted Reflectance Terrain, Landsat 8 Geomedian Calendar Year Collection 3\nbounding box: (110.413246718272, -46.2302085135865, 157.044900204052, -8.10857383542487)\ndate limits: [‘2013-01-01’, ‘2021-01-01’]\nNumber of bands: 10\n\n‘ga_ls7e_nbart_gm_cyear_3’:\n\ntitle: DEA GeoMAD (Landsat 7 ETM+)\ndescription: Geoscience Australia Landsat Nadir BRDF Adjusted Reflectance Terrain, Landsat 7 Geomedian Calendar Year Collection 3\nbounding box: (110.413246718272, -45.1432282004529, 156.432609321534, -8.21783704144064)\ndate limits: [‘1999-01-01’, ‘2021-01-01’]\nNumber of bands: 10\n\n‘ga_ls5t_nbart_gm_cyear_3’:\n\ntitle: DEA GeoMAD (Landsat 5 TM)\ndescription: Geoscience Australia Landsat Nadir BRDF Adjusted Reflectance Terrain, Landsat 5 Geomedian Calendar Year Collection 3\nbounding box: (110.413246718272, -45.0401572488294, 156.432609321534, -7.21314878610402)\ndate limits: [‘1986-01-01’, ‘2011-01-01’]\nNumber of bands: 10\n\n‘ga_ls8c_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat 8 OLI-TIRS)\ndescription: Geoscience Australia Landsat 8 Operational Land Imager and Thermal Infra-Red Scanner Analysis Ready Data Collection 3\nbounding box: (110.718297795307, -45.6734535062289, 156.154528040633, -9.07553770894522)\ndate limits: [‘2013-03-19’, ‘2022-09-05’]\nNumber of bands: 9\n\n‘ga_ls7e_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat 7 ETM+)\ndescription: Geoscience Australia Landsat 7 Enhanced Thematic Mapper Plus Analysis Ready Data Collection 3\nbounding box: (110.696007613984, -44.1889410289207, 155.711647298981, -9.15270092381057)\ndate limits: [‘1999-05-28’, ‘2022-04-06’]\nNumber of bands: 8\n\n‘ga_ls5t_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat 5 TM)\ndescription: Geoscience Australia Landsat 5 Thematic Mapper Analysis Ready Data Collection 3\nbounding box: (110.757249124468, -44.2624681575318, 155.662004153478, -8.13764292647926)\ndate limits: [‘1986-08-16’, ‘2011-11-17’]\nNumber of bands: 7\n\n‘ga_ls8c_ard_provisional_3’:\n\ntitle: DEA Surface Reflectance (Landsat 8 OLI-TIRS, Provisional)\ndescription: Geoscience Australia Landsat 8 Operational Land Imager and Thermal Infra-Red Scanner Analysis Ready Data Collection 3 (provisional)\nbounding box: (110.746179078976, -44.2480872929322, 156.113923365678, -9.07570747846392)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 9\n\n‘ga_ls7e_ard_provisional_3’:\n\ntitle: DEA Surface Reflectance (Landsat 7 ETM+, Provisional)\ndescription: Geoscience Australia Landsat 7 Enhanced Thematic Mapper Plus Analysis Ready Data Collection 3 (provisional)\nbounding box: (113.36982861436, -42.7522970095266, 155.249275549932, -9.18167640172494)\ndate limits: [‘2022-06-22’, ‘2022-08-24’]\nNumber of bands: 8\n\n‘ga_ls_ard_provisional_3’:\n\ntitle: DEA Surface Reflectance (Landsat, Provisional)\ndescription: Geoscience Australia Landsat 7 Enhanced Thematic Mapper Plus Analysis Ready Data Collection 3 (provisional)\nbounding box: (110.746179078976, -44.2480872929322, 156.113923365678, -9.07570747846392)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 7\n\n‘s2b_nrt_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2B MSI Near Real-Time)\ndescription: Sentinel-2B MSI ARD NRT - NBAR NBART and Pixel Quality\nbounding box: (109.989859933428, -45.2413329418709, 155.307643731418, -9.9300073889701)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 23\n\n‘s2a_nrt_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2A MSI Near Real-Time)\ndescription: Sentinel-2A MSI ARD NRT - NBAR NBART and Pixel Quality\nbounding box: (109.989859933428, -45.2413329418709, 155.307643731418, -9.9300073889701)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 23\n\n‘s2_nrt_provisional_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2, Provisional)\ndescription: Geoscience Australia Sentinel 2a MSI Analysis Ready Data Collection 3 (provisional)\nbounding box: (111.958960179236, -44.3413038768651, 155.219674237016, -9.93000738897011)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 12\n\n‘s2b_nrt_provisional_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2B MSI, Provisional)\ndescription: Geoscience Australia Sentinel 2b MSI Analysis Ready Data Collection 3 (provisional)\nbounding box: (111.959041001616, -44.341297231057, 155.219281688203, -9.93000738897011)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 12\n\n‘s2a_nrt_provisional_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2A MSI, Provisional)\ndescription: Geoscience Australia Sentinel 2a MSI Analysis Ready Data Collection 3 (provisional)\nbounding box: (111.958960179236, -44.3413038768651, 155.219674237016, -9.93000738897011)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 12\n\n‘s2a_ard_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2A MSI)\ndescription: Sentinel-2A MSI Definitive ARD - NBART and Pixel Quality\nbounding box: (109.968510816964, -45.2234942244028, 156.101505058599, -9.02727104242043)\ndate limits: [‘2015-07-12’, ‘2022-09-13’]\nNumber of bands: 12\n\n‘s2b_ard_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2B MSI)\ndescription: Sentinel-2B MSI Definitive ARD - NBART and Pixel Quality\nbounding box: (110.294393028751, -44.7864137985832, 156.101505058599, -9.02727104242043)\ndate limits: [‘2017-06-30’, ‘2022-09-13’]\nNumber of bands: 12\n\n‘ga_ls_landcover’:\n\ntitle: DEA Land Cover Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Land Cover Calendar Year Collection 2.0\nbounding box: (112.731828633068, -44.2342184871416, 154.267421772154, -9.93509678400507)\ndate limits: [‘1988-01-01’, ‘2020-01-01’]\nNumber of bands: 2\n\n‘ga_ls_landcover_descriptors’:\n\ntitle: DEA Land Cover Environmental Descriptors\ndescription: Geoscience Australia Landsat Land Cover Calendar Year Collection 2.0\nbounding box: (112.731828633068, -44.2342184871416, 154.267421772154, -9.93509678400507)\ndate limits: [‘1988-01-01’, ‘2020-01-01’]\nNumber of bands: 5\n\n‘ga_ls_fc_3’:\n\ntitle: DEA Fractional Cover (Landsat)\ndescription: Geoscience Australia Landsat Fractional Cover Collection 3\nbounding box: (110.696007613984, -45.6734535062289, 156.154528040633, -8.13764292647926)\ndate limits: [‘1986-08-16’, ‘2022-09-05’]\nNumber of bands: 4\n\n‘ga_ls_fc_pc_cyear_3’:\n\ntitle: DEA Fractional Cover Percentiles Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Fractional Cover Percentile Calendar Year Collection 3\nbounding box: (112.343354889631, -44.2467683625153, 154.378185360282, -8.51120628432549)\ndate limits: [‘1987-01-01’, ‘2021-01-01’]\nNumber of bands: 10\n\n‘ga_ls_mangrove_cover_cyear_3’:\n\ntitle: DEA Mangroves (Landsat)\ndescription: Geoscience Australia Landsat Mangrove Cover Calendar Year Collection 3\nbounding box: (112.492257439061, -39.1292216144938, 154.264053741666, -9.5698963139854)\ndate limits: [‘1987-01-01’, ‘2021-01-01’]\nNumber of bands: 1\n\n‘s2_barest_earth’:\n\ntitle: GA Barest Earth (Sentinel-2)\ndescription: The Sentinel-2 Barest Earth\nbounding box: (112.324372771065, -43.9381826788341, 154.70510751296, -8.82186564540388)\ndate limits: [‘2017-01-01’, ‘2017-01-01’]\nNumber of bands: 10\n\n‘ls8_barest_earth_mosaic’:\n\ntitle: GA Barest Earth (Landsat 8 OLI/TIRS)\ndescription: Landsat-8 Barest Earth pixel composite albers 25 metre, 100km tile, Australian Albers Equal Area projection (EPSG:3577)\nbounding box: (111.492400120054, -44.3357065215098, 155.066563941708, -8.83515695199939)\ndate limits: [‘2013-01-01’, ‘2013-01-01’]\nNumber of bands: 6\n\n‘landsat_barest_earth’:\n\ntitle: GA Barest Earth (Landsat)\ndescription: Landsat-5/Landsat-7/Landsat-8 combined Barest Earth pixel composite albers 25 metre, 100km tile, Australian Albers Equal Area projection (EPSG:3577)\nbounding box: (111.033686003887, -44.4285210281062, 155.790571411147, -8.49453875182811)\ndate limits: [‘1980-01-01’, ‘1980-01-01’]\nNumber of bands: 6\n\n‘ga_ls_tcw_percentiles_2’:\n\ntitle: DEA Wetness Percentiles (Landsat)\ndescription: Geoscience Australia Landsat Tasseled Cap Wetness Percentiles Collection 2, 25 metre, 100km tile, Australian Albers Equal Area projection (EPSG:3577)\nbounding box: (112.501524524947, -44.315077785668, 154.340852639902, -9.07349125191758)\ndate limits: [‘1987-01-01’, ‘1987-01-01’]\nNumber of bands: 3\n\n‘ga_ls_tc_pc_cyear_3’:\n\ntitle: DEA Tasseled Cap Indices Percentiles Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Tasseled Cap Percentile Calendar Year Collection 3\nbounding box: (112.343354889631, -44.2467683625153, 154.378185360282, -8.51120628432549)\ndate limits: [‘1987-01-01’, ‘2021-01-01’]\nNumber of bands: 9\n\n‘ga_ls_wo_3’:\n\ntitle: DEA Water Observations (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Collection 3\nbounding box: (110.696007613984, -45.6734414490927, 156.154528040633, -9.07557070726103)\ndate limits: [‘1986-08-16’, ‘2022-09-05’]\nNumber of bands: 1\n\n‘ga_ls_wo_fq_myear_3’:\n\ntitle: DEA Water Observations Multi Year (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency Multi Year Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.10857383542487)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 3\n\n‘ga_ls_wo_fq_cyear_3’:\n\ntitle: DEA Water Observations Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency Calendar Year Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.10857383542487)\ndate limits: [‘1986-01-01’, ‘2021-01-01’]\nNumber of bands: 3\n\n‘ga_ls_wo_fq_apr_oct_3’:\n\ntitle: DEA Water Observations April to October (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency April to October Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.10857383542487)\ndate limits: [‘1986-04-01’, ‘2021-04-01’]\nNumber of bands: 3\n\n‘ga_ls_wo_fq_nov_mar_3’:\n\ntitle: DEA Water Observations November to March (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency November to March Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.21783704144064)\ndate limits: [‘1987-11-01’, ‘2021-11-01’]\nNumber of bands: 3\n\n‘wofs_filtered_summary’:\n\ntitle: DEA Multi-Year Water Observation Frequency Filtered Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics confidence filtered\nbounding box: (111.859562290899, -44.9351287319957, 155.169368098324, -9.00692244744483)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 2\n\n‘wofs_summary_clear’:\n\ntitle: DEA Multi-Year Clear Observation Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics\nbounding box: (112.99986111, -44.0008652894921, 153.999861110328, -10.0001388899999)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 3\n\n‘wofs_summary_wet’:\n\ntitle: DEA Multi-Year Wet Observation Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics\nbounding box: (112.99986111, -44.0008652894921, 153.999861110328, -10.0001388899999)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 3\n\n‘Water Observations from Space Statistics’:\n\ntitle: DEA Multi-Year Water Observation Frequency Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics\nbounding box: (112.99986111, -44.0008652894921, 153.999861110328, -10.0001388899999)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 3\n\n‘wofs_filtered_summary_confidence’:\n\ntitle: DEA Multi-Year Water Observation Confidence Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics confidence filtered\nbounding box: (111.859562290899, -44.9351287319957, 155.169368098324, -9.00692244744483)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 2\n\n‘ITEM_V2.0.0’:\n\ntitle: DEA Intertidal Extents (Landsat)\ndescription: Relative Extents Model\nbounding box: (112.459622677896, -43.7203758299765, 153.670408736335, -10.3096529183452)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 1\n\n‘ITEM_V2.0.0_Conf’:\n\ntitle: DEA Intertidal Extents confidence\ndescription: Average ndwi Standard Deviation, the Confidence Layer\nbounding box: (112.459622677896, -43.7203758299765, 153.670408736335, -10.3096529183452)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 1\n\n‘NIDEM’:\n\ntitle: DEA Intertidal Elevation (Landsat)\ndescription: National Intertidal Digital Elevation Model 25m 1.0.0\nbounding box: (112.223058990767, -43.8291965530654, 154.080299801132, -10.2371048142508)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 1\n\n‘high_tide_composite’:\n\ntitle: DEA High Tide Imagery (Landsat)\ndescription: High tide 20 percentage composites 25m v. 2.0.0\nbounding box: (112.223058990767, -43.8291965530654, 154.080299801132, -10.2371048142508)\ndate limits: [‘2000-01-01’, ‘2000-01-01’]\nNumber of bands: 6\n\n‘low_tide_composite’:\n\ntitle: DEA Low Tide Imagery (Landsat)\ndescription: Low tide 20 percentage composites 25m v. 2.0.0\nbounding box: (112.223058990767, -43.8291965530654, 154.080299801132, -10.2371048142508)\ndate limits: [‘2000-01-01’, ‘2000-01-01’]\nNumber of bands: 6\n\n‘ga_s2_ba_provisional_3’:\n\ntitle: DEA Burnt Area Characteristic Layers (Sentinel 2 Near Real-Time, Provisional)\ndescription: Sentinel 2 Burnt Area Collection 3 (Provisional)\nbounding box: (111.966746816605, -44.3414673034495, 155.213824039639, -9.93000738897011)\ndate limits: [‘2021-10-01’, ‘2022-09-19’]\nNumber of bands: None\n\n‘alos_displacement’:\n\ntitle: ALOS Displacement\ndescription: CEMP InSAR ALOS Displacement\nbounding box: (150.330509919584, -34.5250413940276, 151.258021405841, -33.772472435988)\ndate limits: [‘2008-02-11’, ‘2010-10-22’]\nNumber of bands: 4\n\n‘alos_velocity’:\n\ntitle: ALOS Velocity\ndescription: CEMP InSAR ALOS Velocity\nbounding box: (150.331038253243, -34.5250413940276, 151.258021405841, -33.772472435988)\ndate limits: [‘2009-06-15’, ‘2009-06-15’]\nNumber of bands: 4\n\n‘envisat_displacement’:\n\ntitle: ENVISAT Displacement\ndescription: CEMP InSAR Envisat Displacement\nbounding box: (150.416357298779, -34.5283535864513, 151.184355816078, -33.5035077252927)\ndate limits: [‘2006-06-26’, ‘2010-08-28’]\nNumber of bands: 4\n\n‘envisat_velocity’:\n\ntitle: ENVISAT Velocity\ndescription: CEMP InSAR Envisat Velocity\nbounding box: (150.416357298779, -34.5283535864513, 151.184355816078, -33.5035077252927)\ndate limits: [‘2008-06-15’, ‘2008-06-15’]\nNumber of bands: 4\n\n‘radarsat2_displacement’:\n\ntitle: RADARSAT2 Displacement\ndescription: CEMP InSAR Radarsat-2 Displacement\nbounding box: (150.540420399293, -34.3792688432228, 151.151613477574, -33.8798432478719)\ndate limits: [‘2015-07-15’, ‘2019-05-31’]\nNumber of bands: 4\n\n‘radarsat2_velocity’:\n\ntitle: RADARSAT2 Velocity\ndescription: CEMP InSAR Radarsat-2 Velocity\nbounding box: (150.540420399293, -34.3792688432228, 151.151613477574, -33.8798432478719)\ndate limits: [‘2017-06-15’, ‘2017-06-15’]\nNumber of bands: 4\n\n‘aster_false_colour’:\n\ntitle: False Colour Mosaic\ndescription: ASTER\nbounding box: (112.917275536606, -44.013698912363, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 3\n\n‘aster_regolith_ratios’:\n\ntitle: Regolith Ratios\ndescription: ASTER\nbounding box: (112.917275536606, -44.013698912363, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 3\n\n‘aster_aloh_group_composition’:\n\ntitle: AlOH Group Composition\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_aloh_group_content’:\n\ntitle: AlOH Group Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_feoh_group_content’:\n\ntitle: FeOH Group Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferric_oxide_composition’:\n\ntitle: Ferric Oxide Composition\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferric_oxide_content’:\n\ntitle: Ferric Oxide Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferrous_iron_content_in_mgoh’:\n\ntitle: Ferrous Iron Content in MgOH/Carbonate\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferrous_iron_index’:\n\ntitle: Ferrous Iron Index\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_green_vegetation’:\n\ntitle: Green Vegetation Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_gypsum_index’:\n\ntitle: Gypsum Index\ndescription: ASTER\nbounding box: (112.917024138111, -43.7806027057097, 153.640358457438, -10.28257228)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_kaolin_group_index’:\n\ntitle: Kaolin Group Index\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_mgoh_group_composition’:\n\ntitle: MgOH Group Composition\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_mgoh_group_content’:\n\ntitle: MgOH Group Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_opaque_index’:\n\ntitle: Opaque Index\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_silica_index’:\n\ntitle: TIR Silica index\ndescription: ASTER\nbounding box: (112.917024138111, -43.7806027057097, 153.640358457438, -10.28257228)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_quartz_index’:\n\ntitle: TIR Quartz Index\ndescription: ASTER\nbounding box: (112.917024138111, -43.7806027057097, 153.640358457438, -10.28257228)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘multi_scale_topographic_position’:\n\ntitle: Multi-Scale Topographic Position\ndescription: Multi-scale Topographic Position Image\nbounding box: (112.9995833, -44.0004167, 153.9995833, -10.0004167)\ndate limits: [‘2018-01-01’, ‘2018-01-01’]\nNumber of bands: 3\n\n‘weathering_intensity’:\n\ntitle: Weathering Intensity\ndescription: Weathering Intensity Model\nbounding box: (112.9995833, -44.0004167, 153.9995833, -10.0004167)\ndate limits: [‘2018-01-01’, ‘2018-01-01’]\nNumber of bands: 1\n\n\n\n\n\nDescription: Digital Earth Australia’s (DEA) Landsat Surface Reflectance products take Landsat 5 Thematic Mapper (TM), Landsat 7 Enhanced Thematic Mapper Plus (ETM+) and Landsat 8 Operational Land Imager (OLI) imagery captured over the Australian continent and corrects for inconsistencies across land and coastal fringes. This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles. Some of the layers include image composites that are made from images acquired within a 16 day period.\nModule name: getdata_dea_nci.py\nResolution: variable (typically 1 arcsec)\nUpdates: daily to yearly\nSource: https://opus.nci.org.au/display/Help/Datasets\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: The data products are produced using Digital Earth Australia. The WCS service relies on GSKY - A Scalable, Distributed Geospatial Data Service from the National Centre for Environmental Information (NCI).\nLayernames:\n\n‘blend_sentinel2_landsat_nbart_daily’ :\n\ntitle: Multi-sensor (Landsat and Sentinel 2) surface reflectance (Beta)\ndescription: This multi-sensor service has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. This service combines terrain corrected surface reflectance observations from three Landsat sensors (Landsat 5 TM, Landsat 7 ETM+, Landsat 8 OLI) and two Sentinel 2 sensors (Sentinel 2A and 2B). More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. The service for each day is composed from all acquisitions that occurred over the Australian region on that calendar day.\n\n‘hltc_high’ :\n\ntitle: DEA High Tide Composite 25m v2.0\ndescription: The High and Low Tide Composites product is composed of two surface reflectance composite mosaics of Landsat TM and ETM+ (Landsat 5 and Landsat 7 respectively) and OLI (Landsat 8) surface reflectance data Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. These products have been produced using Digital Earth Australia (DEA). The two mosaics allow cloud free and noise reduced visualisation of the shallow water and inter-tidal coastal regions of Australia, as observed at high and low tide respectively. The composites are generated utilising the geomedian approach of Roberts et al. (2017) (https://doi.org/10.1109/TGRS.2017.2723896) to ensure a valid surface reflectance spectra suitable for uses such as habitat mapping. The time range used for composite generation in each polygon of the mosaic is tailored to ensure dynamic coastal features are captured whilst still allowing a clean and cloud free composite to be generated (see Sagar et al. 2018 (https://doi.org/10.3390/rs10030480)). The concepts of the Observed Tidal Range (OTR), and Highest and Lowest Observed Tide (HOT, LOT) are discussed and described fully in Sagar et al. (2017) (https://doi.org/10.1016/j.rse.2017.04.009). This service provides access to the High Tide Composite v2.0 product. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a615705d20f7 .\n\n‘hltc_low’ :\n\ntitle: DEA Low Tide Composite 25m v2.0\ndescription: The High and Low Tide Composites product is composed of two surface reflectance composite mosaics of Landsat TM and ETM+ (Landsat 5 and Landsat 7 respectively) and OLI (Landsat 8) surface reflectance data Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. These products have been produced using Digital Earth Australia (DEA). The two mosaics allow cloud free and noise reduced visualisation of the shallow water and inter-tidal coastal regions of Australia, as observed at high and low tide respectively. The composites are generated utilising the geomedian approach of Roberts et al. (2017) (https://doi.org/10.1109/TGRS.2017.2723896) to ensure a valid surface reflectance spectra suitable for uses such as habitat mapping. The time range used for composite generation in each polygon of the mosaic is tailored to ensure dynamic coastal features are captured whilst still allowing a clean and cloud free composite to be generated (see Sagar et al. 2018 (https://doi.org/10.3390/rs10030480)). The concepts of the Observed Tidal Range (OTR), and Highest and Lowest Observed Tide (HOT, LOT) are discussed and described fully in Sagar et al. (2017) (https://doi.org/10.1016/j.rse.2017.04.009). This service provides access to the Low Tide Composite v2.0 product. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a615705d20f7 .\n\n‘item_relative’ :\n\ntitle: DEA Intertidal Extents Model Relative Layer 25m v2.0\ndescription: The Intertidal Extents Model (ITEM) product is a national dataset characterising the spatial extents of the exposed intertidal zone; the land between the observed highest and lowest tide, at intervals of the observed tidal range. ITEM provides the extent and topography of the intertidal zone of Australia’s coastline (excluding offshore Territories). This information was derived using observations in the Landsat archive since 1986. ITEM v2.0 has implemented an improved tidal modelling framework over that utilised in ITEM v1.0 (Sagar et al. 2017, 2018) (https://doi.org/10.1016/j.rse.2017.04.009, https://doi.org/10.3390/rs10030480). The expanded Landsat archive within the Digital Earth Australia (DEA) has also enabled the model extent to be increased from ITEM v1.0 to cover a number of offshore reefs, including the full Great Barrier Reef and southern sections of the Torres Strait Islands. ITEM can be a valuable complementary dataset to both onshore LiDAR survey data and coarser offshore bathymetry data, enabling a more realistic representation of the land and ocean interface. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a602cc9eb358. This service provides access to the Intertidal Extents Model v2.0 Relative Layer product. The relative layer displays the modelled extents of the exposed intertidal zone, at percentile intervals of the observed tidal range (OTR). For example, the region defined as 0-10% denotes an area that only exposes at the lowest 10% of tides in relation to the OTR.\n\n‘item_stddev’ :\n\ntitle: DEA Intertidal Extents Model Confidence Layer 25m v2.0\ndescription: The Intertidal Extents Model (ITEM) product is a national dataset characterising the spatial extents of the exposed intertidal zone; the land between the observed highest and lowest tide, at intervals of the observed tidal range. ITEM provides the extent and topography of the intertidal zone of Australia’s coastline (excluding offshore Territories). This information was derived using observations in the Landsat archive since 1986. ITEM v2.0 has implemented an improved tidal modelling framework over that utilised in ITEM v1.0 (Sagar et al. 2017, 2018) (https://doi.org/10.1016/j.rse.2017.04.009, https://doi.org/10.3390/rs10030480). The expanded Landsat archive within the Digital Earth Australia (DEA) has also enabled the model extent to be increased from ITEM v1.0 to cover a number of offshore reefs, including the full Great Barrier Reef and southern sections of the Torres Strait Islands. ITEM can be a valuable complementary dataset to both onshore LiDAR survey data and coarser offshore bathymetry data, enabling a more realistic representation of the land and ocean interface. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a602cc9eb358. This service provides access to the Intertidal Extents Model v2.0 Confidence Layer product. The confidence layer displays the standard deviation of the water index values (NDWI) derived across the tidal intervals used in generating the core ITEM relative extents product. High values indicate regions where inundation patterns are not driven by tidal influences. This can be a result of change (shoreline, geomorphic, anthropogenic), or caused by errors in the underlying tidal model.\n\n‘landsat5_nbar_16day’ :\n\ntitle: 16-day DEA Landsat 5 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 5 TM surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat5_nbar_daily’ :\n\ntitle: Daily DEA Landsat 5 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 5 TM surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat5_nbart_16day’ :\n\ntitle: 16-day DEA Landsat 5 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 5 Thematic Mapper (TM) terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat5_nbart_daily’ :\n\ntitle: Daily DEA Landsat 5 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 5 Thematic Mapper (TM) terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat7_nbar_16day’ :\n\ntitle: 16-day DEA Landsat 7 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 onwards are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat7_nbar_daily’ :\n\ntitle: Daily DEA Landsat 7 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 onwards are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat7_nbart_16day’ :\n\ntitle: 16-day DEA Landsat 7 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et. al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat7_nbart_daily’ :\n\ntitle: Daily DEA Landsat 7 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et. al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat8_nbar_16day’ :\n\ntitle: 16-day DEA Landsat 8 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 8 OLI surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat8_nbar_daily’ :\n\ntitle: Daily DEA Landsat 8 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 8 OLI surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat8_nbart_16day’ :\n\ntitle: 16-day DEA Landsat 8 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 8 OLI terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat8_nbart_daily’ :\n\ntitle: Daily DEA Landsat 8 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 8 OLI terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘sentinel2_nbart_daily’ :\n\ntitle: Sentinel 2 Analysis Ready Data\ndescription: The Surface Reflectance product has been corrected to account for variations caused by atmospheric properties, sun position and sensor view angle at time of image capture. These corrections have been applied to all satellite imagery in the Sentinel-2 archive. This is undertaken to allow comparison of imagery acquired at different times, by different sensors, in different seasons and in different geographic locations. These products also indicate where the imagery has been affected by cloud or cloud shadow, contains missing data or has been affected in other ways. The Surface Reflectance products are useful as a fundamental starting point for any further analysis and are the underlying data of all other Digital Earth Australia products.\n\n\n\n\n\nDescription: This radiometric sub-collection of the Geoscience Australia Geophysics Reference Data Collection are compilations of radiometric data from an extensive archive of geophysical surveys dating back to 1947, which are contained in other sub-collections of this collection. The individual survey datasets have been acquired by Geoscience Australia and its State and Territory Government partners. The compilations of radiometric data involved the levelling and merging (mosaicking) of regularly interpolated grid (raster) data, from selected individual geophysical surveys, into near-seamless national scale grids for each datatype and creating derivations thereof. The selected individual surveys are chosen based on the spatial resolution and accuracy of individual surveys within a given area.\nModule name: getdata_radiometric.py\nResolution: 100m (0.001 deg)\nUpdates: None\nSource: https://opus.nci.org.au/display/Help/Datasets,\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: Geoscience Australia. The WCS service relies on GSKY - A Scalable, Distributed Geospatial Data Service from the National Centre for Environmental Information (NCI).\nLayernames:\n\n‘radmap2019_grid_dose_terr_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered terrestrial dose rate\ndescription: The unfiltered terrestrial dose rate grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia, which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The unfiltered terrestrial dose rate grid is derived as a linear combination of the unfiltered K, U and Th grids, and has a cell size of about 100m (0.001 degrees).\n\n‘radmap2019_grid_dose_terr_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered terrestrial dose rate\ndescription: The filtered terrestrial dose rate grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia, made of a combination of over 600 individual survey grids. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The terrestrial dose rate grid is derived as a linear combination of the filtered K, U and Th grids. A low pass filter is applied to the unfiltered grid to generate the filtered terrestrial dose rate grid. The grid cell size is about 100m (0.001 degrees).\n\n‘radmap2019_grid_k_conc_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered pct potassium\ndescription: The unfiltered potassium grid is a derivative of the 2019 radiometric grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector. The 2019 unfiltered potassium grid has a cell size of about 100 m (0.001 degrees) and shows potassium element concentrations of the Australia region. Potassium is the seventh most abundant element in the Earth’s crust. The potassium concentration grid can be used to locate minerals and compounds containing potassium.\n\n‘radmap2019_grid_k_conc_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered pct potassium grid\ndescription: The filtered potassium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium, uranium and thorium. The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 filtered potassium grid has a cell size of about 100m (0.001 degrees) and shows potassium element concentrations of the Australia region. It was obtained by applying a low-pass filter to the original potassium grid. Potassium is the seventh most abundant element in the Earth’s crust. This potassium concentration grid can be used to locate minerals and compounds containing potassium.\n\n‘radmap2019_grid_th_conc_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered ppm thorium\ndescription: The unfiltered thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 unfiltered thorium grid has a cell size of about 100 m (0.001 degrees) and shows thorium element concentrations of the Australia region.\n\n‘radmap2019_grid_th_conc_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered ppm thorium\ndescription: The filtered thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector. The 2019 filtered thorium grid was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and shows thorium element concentrations of the Australia region.\n\n‘radmap2019_grid_thk_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio thorium over potassium\ndescription: The thorium over potassium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 thorium over potassium was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and is derived from the filtered thorium and potassium grids.\n\n‘radmap2019_grid_u2th_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio uranium squared over thorium\ndescription: The uranium squared over thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 uranium squared over thorium was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and is derived from the filtered uranium and thorium grids.\n\n‘radmap2019_grid_u_conc_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered ppm uranium\ndescription: The unfiltered uranium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium, uranium and thorium. The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 unfiltered uranium grid has a cell size of about 100m (0.001 degrees) and shows uranium element concentrations of the Australia region.\n\n‘radmap2019_grid_u_conc_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered ppm uranium\ndescription: The filtered uranium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 filtered uranium grid was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and shows uranium element concentrations of the Australia region.\n\n‘radmap2019_grid_uk_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio uranium over potassium\ndescription: The uranium over potassium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia comprising over 600 airborne gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 uranium over potassium grid has a cell size of about 100 m (0.001 degrees) and is derived from the filtered uranium and potassium grids.\n\n‘radmap2019_grid_uth_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio uranium over thorium\ndescription: The uranium over thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 uranium over thorium grid has a cell size of about 100 m (0.001 degrees) and is derived from the filtered uranium and thorium grids.\n\n\n\n\n\nDescription: The landscape attribute products available from the Soil and Landscape Grid of Australia (SLGA) were derived from DEM-S, the smoothed version of the national 1 second resolution Digital Elevation Model, which was derived from the 1 second resolution Shuttle Radar Topography Mission (SRTM) data acquired by NASA in February 2000.\nModule name: getdata_landscape.py\nResolution: 3 arcsec\nUpdates: None\nSource: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails.html”\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: CSIRO Australia, TERN (University of Queensland)\nBounding Box: (112.99958, -44.00042, 153.99958, -10.0004)\nLayernames:\n\n‘Prescott_index’\n\nkey: ‘1’\ntitle: Prescott Index\ndescription: Prescott Index derived from 1 second DEM-S version 0.1\n\n‘net_radiation_jan’\n\nkey: ‘2’\ntitle: Net Radiation [January]\ndescription: None\n\n‘net_radiation_july’\n\nkey: ‘3’\ntitle: Net Radiation [July]\ndescription: None\n\n‘total_shortwave_sloping_surf_jan’\n\nkey: ‘4’\ntitle: Total Shortwave Sloping Surf [January]\ndescription: None\n\n‘total_shortwave_sloping_surf_july’\n\nkey: ‘5’\ntitle: Total Shortwave Sloping Surf [July]\ndescription: None\n\n‘Slope’\n\nkey: ‘6’\ntitle: Slope [percent]\ndescription: Percent slope (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Slope_median_300m’\n\nkey: ‘7’\ntitle: Slope [percent] Median 300m Radius\ndescription: Median of Percent slope at 300m radius (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Slope_relief_class’\n\nkey: ‘8’\ntitle: Slope Relief Class\ndescription: Slope relief (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Aspect’\n\nkey: ‘9’\ntitle: Aspect\ndescription: Aspect (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Relief_1000m’\n\nkey: ‘10’\ntitle: Relief [1000m radius]\ndescription: 1000 m elevation range (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Relief_300m’\n\nkey: ‘11’\ntitle: Relief [300m radius]\ndescription: 300 m elevation range (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Topographic_wetness_index’\n\nkey: ‘12’\ntitle: Topographic Wetness Index\ndescription: Topographic Wetness Index (3” resolution) derived from 1 second DEM-H version 1.0\n\n‘TPI_mask’\n\nkey: ‘13’\ntitle: TPI Mask\ndescription: None\n\n‘SRTM_TopographicPositionIndex’\n\nkey: ‘14’\ntitle: SRTM_TopographicPositionIndex\ndescription: Topographic position index (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Contributing_area’\n\nkey: ‘15’\ntitle: Contributing Area [partial]\ndescription: Contributing Area - Multiple Flow Direction (Partial), 3” resolution, derived from 1 second DEM-H version 1.0\n\n‘MrVBF’\n\nkey: ‘16’\ntitle: MrVBF\ndescription: Multi-resolution Valley Bottom Flatness (MrVBF) at 3 second resolution derived from 1 second DEM-S version 1.0\n\n‘Plan_curvature’\n\nkey: ‘17’\ntitle: Plan Curvature\ndescription: Plan curvature (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Profile_curvature’\n\nkey: ‘18’\ntitle: Profile Curvature\ndescription: Profile curvature (3”resolution) derived from 1 second DEM-S version 0.1"
  },
  {
    "objectID": "docs/Data_Overview.html#table-of-contents",
    "href": "docs/Data_Overview.html#table-of-contents",
    "title": "Data Overview",
    "section": "",
    "text": "Soil Data 3D SLGA\nSILO Climate Database\nNational Digital Elevation Model 1 Second Hydrologically Enforced\nDigital Earth Australia Geoscience Earth Observations\nGSKY Data Server for DEA Geoscience Earth Observations\nRadiometric Data\nLandscape Data SLGA"
  },
  {
    "objectID": "docs/Data_Overview.html#soil-data-3d-slga",
    "href": "docs/Data_Overview.html#soil-data-3d-slga",
    "title": "Data Overview",
    "section": "",
    "text": "Description: The Soil Facility produced a range of digital soil attribute products as Soil and Landscape Grid of Australia (SLGA). Each product contains six digital soil attribute maps, and their upper and lower confidence limits, representing the soil attribute at six depths: 0-5cm, 5-15cm, 15-30cm, 30-60cm, 60-100cm and 100-200cm.\nModule name: getdata_slga.py\nBounding Box: Long_min: 113.00, Lat_min: -44.00, Long_max: 154.00, Lat_max: -10.00\nPeriod (temporal coverage; approximately): 1950-2013\nResolution: 3 arcsec\nSource: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails-SoilAttributes.html\nLicense: Creative Commons Attribution 3.0 (CC By)\nAttribution: CSIRO Australia, TERN (University of Queensland), and Geoscience Australia\nLayernames:\n\n‘Bulk_Density’ :\n\nTitle: Bulk Density (whole earth)\nDescription: Bulk Density of the whole soil (including coarse fragments) in mass per unit volume by a method equivalent to the core method\nUnit: g/cm3\n\n‘Organic_Carbon’ :\n\nTitle: Organic Carbon\nDescription: Mass fraction of carbon by weight in the &lt; 2 mm soil material as determined by dry combustion at 900 Celcius\nUnit: %\n\n‘Clay’ :\n\nTitle: Clay\nDescription: &lt; 2 um mass fraction of the &lt; 2 mm soil material determined using the pipette method\nUnit: %\n\n‘Silt’ :\n\nTitle: Silt\nDescription: 2-20 um mass fraction of the &lt; 2 mm soil material determined using the pipette method\nUnit: %\n\n‘Sand’ :\n\nTitle: Sand\nDescription: 20 um - 2 mm mass fraction of the &lt; 2 mm soil material determined using the pipette method\nUnit: %\n\n‘pH_CaCl2’ :\n\nTitle: pH (CaCl2)\nDescription: pH of 1:5 soil/0.01M calcium chloride extract\nUnit: none\n\n‘Available_Water_Capacity’ :\n\nTitle: Available Water Capacity\nDescription: Available water capacity computed for each of the specified depth increments\nUnit: %\n\n‘Total_Nitrogen’ :\n\nTitle: Total Nitrogen\nDescription: Mass fraction of total nitrogen in the soil by weight\nUnit: %\n\n‘Total_Phosphorus’ :\n\nTitle: Total Phosphorus\nDescription: Mass fraction of total phosphorus in the soil by weight\nUnit: %\n\n‘Effective_Cation_Exchange_Capacity’ :\n\nTitle: Effective Cation Exchange Capacity\nDescription: Cations extracted using barium chloride (BaCl2) plus exchangeable H + Al\nUnit: meq/100g\n\n‘Depth_of_Regolith’ :\n\nTitle: Depth of Regolith\nDescription: Depth to hard rock. Depth is inclusive of all regolith.\nUnit: m\n\n‘Depth_of_Soil’ :\n\nTitle: Depth of Soil\nDescription: Depth of soil profile (A & B horizons)\nUnit: m"
  },
  {
    "objectID": "docs/Data_Overview.html#silo-climate-database",
    "href": "docs/Data_Overview.html#silo-climate-database",
    "title": "Data Overview",
    "section": "",
    "text": "Description: SILO is containing continuous daily climate data for Australia from 1889 to present.\nModule name: getdata_silo.py\nBounding Box = Long_min: 112.00, Lat_min: -44.00, Long_max: 154.00, Lat_max: -10.00\nUpdates: Daily\nResolution: native: 180 arcsec\nSource: https://www.longpaddock.qld.gov.au/silo/gridded-data/\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: State of Queensland (Queensland Department of Environment and Science) 2020.\nLayernames:\n\n‘daily_rain’ (Daily rainfall, mm)\n‘monthly_rain’ (Monthly rainfall, mm)\n‘max_temp’ (Maximum temperature, deg C)\n‘min_temp’ (Minimum temperature. deg C)\n‘vp’ (Vapour pressure, hPa)\n‘vp_deficit’ (Vapour pressure deficit, hPa)\n‘evap_pan’ (Class A pan evaporation, mm)\n‘evap_syn’ (Synthetic estimate, mm)\n‘evap_comb’ (Combination: synthetic estimate pre-1970, class A pan 1970 onwards, mm)\n‘evap_morton_lake’ (Morton’s shallow lake evaporation, mm)\n‘radiation’ (Solar radiation: Solar exposure, consisting of both direct and diffuse components, MJ/m2)\n‘rh_tmax’ (Relative humidity: Relative humidity at the time of maximum temperature, %)\n‘rh_tmin’ (Relative humidity at the time of minimum temperature, %)\n‘et_short_crop’ (Evapotranspiration FAO564 short crop, mm)\n‘et_tall_crop’ (ASCE5 tall crop6, mm)\n‘et_morton_actual’ (Morton’s areal actual evapotranspiration, mm)\n‘et_morton_potential’ (Morton’s point potential evapotranspiration, mm)\n‘et_morton_wet’ (Morton’s wet-environment areal potential evapotranspiration over land, mm)\n‘mslp’ (Mean sea level pressure Mean sea level pressure, hPa)"
  },
  {
    "objectID": "docs/Data_Overview.html#national-digital-elevation-model-1-second-hydrologically-enforced",
    "href": "docs/Data_Overview.html#national-digital-elevation-model-1-second-hydrologically-enforced",
    "title": "Data Overview",
    "section": "",
    "text": "Description: Digital Elevation Model (DEM) of Australia derived from STRM with 1 Second Grid - Hydrologically Enforced\nModule name: getdata_dem.py\nBounding Box = Long_min: 112.00, Lat_min: -44.00, Long_max: 154.00, Lat_max: -10.00\nUpdates: None\nResolution: native: 1 arcsec\nSource: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails.html\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: Commonwealth of Australia (Geoscience Australia)\nLayernames:\n\n‘DEM_1s’\n\nTitle: DEM SRTM 1 Second Hydro Enforced\nDescription: The 1 second SRTM derived hydrologically enforced DEM (DEM-H Version 1.0) is a 1 arc second (~30 m) gridded digital elevation model (DEM) that has been hydrologically conditioned and drainage enforced. The DEM-H captures flow paths based on SRTM elevations and mapped stream lines, and supports delineation of catchments and related hydrological attributes."
  },
  {
    "objectID": "docs/Data_Overview.html#digital-earth-australia-geoscience-earth-observations",
    "href": "docs/Data_Overview.html#digital-earth-australia-geoscience-earth-observations",
    "title": "Data Overview",
    "section": "",
    "text": "Description: Digital Earth Australia’s (DEA) Landsat Surface Reflectance products take Landsat 5 Thematic Mapper (TM), Landsat 7 Enhanced Thematic Mapper Plus (ETM+) and Landsat 8 Operational Land Imager (OLI) imagery captured over the Australian continent and corrects for inconsistencies across land and coastal fringes. The result is accurate and standardised surface reflectance data, which is instrumental in identifying and quantifying environmental change. DEA’s Landsat Surface Reflectance products form a single, cohesive Analysis Ready Data (ARD) package, which allows you to analyse surface reflectance data as is without the need to apply additional corrections.\nModule name: getdata_dea.py\nBounding Box: variable (see layernames)\nResolution: variable (depending on layer, typically 25m)\nUpdates: Daily to yearly\nSource: https://docs.dea.ga.gov.au/notebooks/DEA_datasets/DEA_Landsat_Surface_Reflectance.html\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: Digital Earth Australia (DEA)\nLayernames:\n\n‘ga_ls_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat)\ndescription: Geoscience Australia Landsat 5 Thematic Mapper Analysis Ready Data Collection 3\nbounding box: (110.696007613984, -45.6734535062289, 156.154528040633, -8.13764292647926)\ndate limits: [‘1986-08-16’, ‘2022-09-05’]\nNumber of bands: 7\n\n‘s2_nrt_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2 Near Real-Time)\ndescription: Sentinel-2A MSI ARD NRT - NBAR NBART and Pixel Quality\nbounding box: (109.989859933428, -45.2413329418709, 155.307643731418, -9.9300073889701)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 23\n\n‘s2_ard_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2)\ndescription: Sentinel-2A MSI Definitive ARD - NBART and Pixel Quality\nbounding box: (109.968510816964, -45.2234942244028, 156.101505058599, -9.02727104242043)\ndate limits: [‘2015-07-12’, ‘2022-09-13’]\nNumber of bands: 12\n\n‘ga_ls8c_nbart_gm_cyear_3’:\n\ntitle: DEA GeoMAD (Landsat 8 OLI-TIRS)\ndescription: Geoscience Australia Landsat Nadir BRDF Adjusted Reflectance Terrain, Landsat 8 Geomedian Calendar Year Collection 3\nbounding box: (110.413246718272, -46.2302085135865, 157.044900204052, -8.10857383542487)\ndate limits: [‘2013-01-01’, ‘2021-01-01’]\nNumber of bands: 10\n\n‘ga_ls7e_nbart_gm_cyear_3’:\n\ntitle: DEA GeoMAD (Landsat 7 ETM+)\ndescription: Geoscience Australia Landsat Nadir BRDF Adjusted Reflectance Terrain, Landsat 7 Geomedian Calendar Year Collection 3\nbounding box: (110.413246718272, -45.1432282004529, 156.432609321534, -8.21783704144064)\ndate limits: [‘1999-01-01’, ‘2021-01-01’]\nNumber of bands: 10\n\n‘ga_ls5t_nbart_gm_cyear_3’:\n\ntitle: DEA GeoMAD (Landsat 5 TM)\ndescription: Geoscience Australia Landsat Nadir BRDF Adjusted Reflectance Terrain, Landsat 5 Geomedian Calendar Year Collection 3\nbounding box: (110.413246718272, -45.0401572488294, 156.432609321534, -7.21314878610402)\ndate limits: [‘1986-01-01’, ‘2011-01-01’]\nNumber of bands: 10\n\n‘ga_ls8c_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat 8 OLI-TIRS)\ndescription: Geoscience Australia Landsat 8 Operational Land Imager and Thermal Infra-Red Scanner Analysis Ready Data Collection 3\nbounding box: (110.718297795307, -45.6734535062289, 156.154528040633, -9.07553770894522)\ndate limits: [‘2013-03-19’, ‘2022-09-05’]\nNumber of bands: 9\n\n‘ga_ls7e_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat 7 ETM+)\ndescription: Geoscience Australia Landsat 7 Enhanced Thematic Mapper Plus Analysis Ready Data Collection 3\nbounding box: (110.696007613984, -44.1889410289207, 155.711647298981, -9.15270092381057)\ndate limits: [‘1999-05-28’, ‘2022-04-06’]\nNumber of bands: 8\n\n‘ga_ls5t_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat 5 TM)\ndescription: Geoscience Australia Landsat 5 Thematic Mapper Analysis Ready Data Collection 3\nbounding box: (110.757249124468, -44.2624681575318, 155.662004153478, -8.13764292647926)\ndate limits: [‘1986-08-16’, ‘2011-11-17’]\nNumber of bands: 7\n\n‘ga_ls8c_ard_provisional_3’:\n\ntitle: DEA Surface Reflectance (Landsat 8 OLI-TIRS, Provisional)\ndescription: Geoscience Australia Landsat 8 Operational Land Imager and Thermal Infra-Red Scanner Analysis Ready Data Collection 3 (provisional)\nbounding box: (110.746179078976, -44.2480872929322, 156.113923365678, -9.07570747846392)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 9\n\n‘ga_ls7e_ard_provisional_3’:\n\ntitle: DEA Surface Reflectance (Landsat 7 ETM+, Provisional)\ndescription: Geoscience Australia Landsat 7 Enhanced Thematic Mapper Plus Analysis Ready Data Collection 3 (provisional)\nbounding box: (113.36982861436, -42.7522970095266, 155.249275549932, -9.18167640172494)\ndate limits: [‘2022-06-22’, ‘2022-08-24’]\nNumber of bands: 8\n\n‘ga_ls_ard_provisional_3’:\n\ntitle: DEA Surface Reflectance (Landsat, Provisional)\ndescription: Geoscience Australia Landsat 7 Enhanced Thematic Mapper Plus Analysis Ready Data Collection 3 (provisional)\nbounding box: (110.746179078976, -44.2480872929322, 156.113923365678, -9.07570747846392)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 7\n\n‘s2b_nrt_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2B MSI Near Real-Time)\ndescription: Sentinel-2B MSI ARD NRT - NBAR NBART and Pixel Quality\nbounding box: (109.989859933428, -45.2413329418709, 155.307643731418, -9.9300073889701)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 23\n\n‘s2a_nrt_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2A MSI Near Real-Time)\ndescription: Sentinel-2A MSI ARD NRT - NBAR NBART and Pixel Quality\nbounding box: (109.989859933428, -45.2413329418709, 155.307643731418, -9.9300073889701)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 23\n\n‘s2_nrt_provisional_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2, Provisional)\ndescription: Geoscience Australia Sentinel 2a MSI Analysis Ready Data Collection 3 (provisional)\nbounding box: (111.958960179236, -44.3413038768651, 155.219674237016, -9.93000738897011)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 12\n\n‘s2b_nrt_provisional_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2B MSI, Provisional)\ndescription: Geoscience Australia Sentinel 2b MSI Analysis Ready Data Collection 3 (provisional)\nbounding box: (111.959041001616, -44.341297231057, 155.219281688203, -9.93000738897011)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 12\n\n‘s2a_nrt_provisional_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2A MSI, Provisional)\ndescription: Geoscience Australia Sentinel 2a MSI Analysis Ready Data Collection 3 (provisional)\nbounding box: (111.958960179236, -44.3413038768651, 155.219674237016, -9.93000738897011)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 12\n\n‘s2a_ard_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2A MSI)\ndescription: Sentinel-2A MSI Definitive ARD - NBART and Pixel Quality\nbounding box: (109.968510816964, -45.2234942244028, 156.101505058599, -9.02727104242043)\ndate limits: [‘2015-07-12’, ‘2022-09-13’]\nNumber of bands: 12\n\n‘s2b_ard_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2B MSI)\ndescription: Sentinel-2B MSI Definitive ARD - NBART and Pixel Quality\nbounding box: (110.294393028751, -44.7864137985832, 156.101505058599, -9.02727104242043)\ndate limits: [‘2017-06-30’, ‘2022-09-13’]\nNumber of bands: 12\n\n‘ga_ls_landcover’:\n\ntitle: DEA Land Cover Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Land Cover Calendar Year Collection 2.0\nbounding box: (112.731828633068, -44.2342184871416, 154.267421772154, -9.93509678400507)\ndate limits: [‘1988-01-01’, ‘2020-01-01’]\nNumber of bands: 2\n\n‘ga_ls_landcover_descriptors’:\n\ntitle: DEA Land Cover Environmental Descriptors\ndescription: Geoscience Australia Landsat Land Cover Calendar Year Collection 2.0\nbounding box: (112.731828633068, -44.2342184871416, 154.267421772154, -9.93509678400507)\ndate limits: [‘1988-01-01’, ‘2020-01-01’]\nNumber of bands: 5\n\n‘ga_ls_fc_3’:\n\ntitle: DEA Fractional Cover (Landsat)\ndescription: Geoscience Australia Landsat Fractional Cover Collection 3\nbounding box: (110.696007613984, -45.6734535062289, 156.154528040633, -8.13764292647926)\ndate limits: [‘1986-08-16’, ‘2022-09-05’]\nNumber of bands: 4\n\n‘ga_ls_fc_pc_cyear_3’:\n\ntitle: DEA Fractional Cover Percentiles Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Fractional Cover Percentile Calendar Year Collection 3\nbounding box: (112.343354889631, -44.2467683625153, 154.378185360282, -8.51120628432549)\ndate limits: [‘1987-01-01’, ‘2021-01-01’]\nNumber of bands: 10\n\n‘ga_ls_mangrove_cover_cyear_3’:\n\ntitle: DEA Mangroves (Landsat)\ndescription: Geoscience Australia Landsat Mangrove Cover Calendar Year Collection 3\nbounding box: (112.492257439061, -39.1292216144938, 154.264053741666, -9.5698963139854)\ndate limits: [‘1987-01-01’, ‘2021-01-01’]\nNumber of bands: 1\n\n‘s2_barest_earth’:\n\ntitle: GA Barest Earth (Sentinel-2)\ndescription: The Sentinel-2 Barest Earth\nbounding box: (112.324372771065, -43.9381826788341, 154.70510751296, -8.82186564540388)\ndate limits: [‘2017-01-01’, ‘2017-01-01’]\nNumber of bands: 10\n\n‘ls8_barest_earth_mosaic’:\n\ntitle: GA Barest Earth (Landsat 8 OLI/TIRS)\ndescription: Landsat-8 Barest Earth pixel composite albers 25 metre, 100km tile, Australian Albers Equal Area projection (EPSG:3577)\nbounding box: (111.492400120054, -44.3357065215098, 155.066563941708, -8.83515695199939)\ndate limits: [‘2013-01-01’, ‘2013-01-01’]\nNumber of bands: 6\n\n‘landsat_barest_earth’:\n\ntitle: GA Barest Earth (Landsat)\ndescription: Landsat-5/Landsat-7/Landsat-8 combined Barest Earth pixel composite albers 25 metre, 100km tile, Australian Albers Equal Area projection (EPSG:3577)\nbounding box: (111.033686003887, -44.4285210281062, 155.790571411147, -8.49453875182811)\ndate limits: [‘1980-01-01’, ‘1980-01-01’]\nNumber of bands: 6\n\n‘ga_ls_tcw_percentiles_2’:\n\ntitle: DEA Wetness Percentiles (Landsat)\ndescription: Geoscience Australia Landsat Tasseled Cap Wetness Percentiles Collection 2, 25 metre, 100km tile, Australian Albers Equal Area projection (EPSG:3577)\nbounding box: (112.501524524947, -44.315077785668, 154.340852639902, -9.07349125191758)\ndate limits: [‘1987-01-01’, ‘1987-01-01’]\nNumber of bands: 3\n\n‘ga_ls_tc_pc_cyear_3’:\n\ntitle: DEA Tasseled Cap Indices Percentiles Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Tasseled Cap Percentile Calendar Year Collection 3\nbounding box: (112.343354889631, -44.2467683625153, 154.378185360282, -8.51120628432549)\ndate limits: [‘1987-01-01’, ‘2021-01-01’]\nNumber of bands: 9\n\n‘ga_ls_wo_3’:\n\ntitle: DEA Water Observations (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Collection 3\nbounding box: (110.696007613984, -45.6734414490927, 156.154528040633, -9.07557070726103)\ndate limits: [‘1986-08-16’, ‘2022-09-05’]\nNumber of bands: 1\n\n‘ga_ls_wo_fq_myear_3’:\n\ntitle: DEA Water Observations Multi Year (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency Multi Year Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.10857383542487)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 3\n\n‘ga_ls_wo_fq_cyear_3’:\n\ntitle: DEA Water Observations Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency Calendar Year Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.10857383542487)\ndate limits: [‘1986-01-01’, ‘2021-01-01’]\nNumber of bands: 3\n\n‘ga_ls_wo_fq_apr_oct_3’:\n\ntitle: DEA Water Observations April to October (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency April to October Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.10857383542487)\ndate limits: [‘1986-04-01’, ‘2021-04-01’]\nNumber of bands: 3\n\n‘ga_ls_wo_fq_nov_mar_3’:\n\ntitle: DEA Water Observations November to March (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency November to March Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.21783704144064)\ndate limits: [‘1987-11-01’, ‘2021-11-01’]\nNumber of bands: 3\n\n‘wofs_filtered_summary’:\n\ntitle: DEA Multi-Year Water Observation Frequency Filtered Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics confidence filtered\nbounding box: (111.859562290899, -44.9351287319957, 155.169368098324, -9.00692244744483)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 2\n\n‘wofs_summary_clear’:\n\ntitle: DEA Multi-Year Clear Observation Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics\nbounding box: (112.99986111, -44.0008652894921, 153.999861110328, -10.0001388899999)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 3\n\n‘wofs_summary_wet’:\n\ntitle: DEA Multi-Year Wet Observation Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics\nbounding box: (112.99986111, -44.0008652894921, 153.999861110328, -10.0001388899999)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 3\n\n‘Water Observations from Space Statistics’:\n\ntitle: DEA Multi-Year Water Observation Frequency Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics\nbounding box: (112.99986111, -44.0008652894921, 153.999861110328, -10.0001388899999)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 3\n\n‘wofs_filtered_summary_confidence’:\n\ntitle: DEA Multi-Year Water Observation Confidence Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics confidence filtered\nbounding box: (111.859562290899, -44.9351287319957, 155.169368098324, -9.00692244744483)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 2\n\n‘ITEM_V2.0.0’:\n\ntitle: DEA Intertidal Extents (Landsat)\ndescription: Relative Extents Model\nbounding box: (112.459622677896, -43.7203758299765, 153.670408736335, -10.3096529183452)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 1\n\n‘ITEM_V2.0.0_Conf’:\n\ntitle: DEA Intertidal Extents confidence\ndescription: Average ndwi Standard Deviation, the Confidence Layer\nbounding box: (112.459622677896, -43.7203758299765, 153.670408736335, -10.3096529183452)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 1\n\n‘NIDEM’:\n\ntitle: DEA Intertidal Elevation (Landsat)\ndescription: National Intertidal Digital Elevation Model 25m 1.0.0\nbounding box: (112.223058990767, -43.8291965530654, 154.080299801132, -10.2371048142508)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 1\n\n‘high_tide_composite’:\n\ntitle: DEA High Tide Imagery (Landsat)\ndescription: High tide 20 percentage composites 25m v. 2.0.0\nbounding box: (112.223058990767, -43.8291965530654, 154.080299801132, -10.2371048142508)\ndate limits: [‘2000-01-01’, ‘2000-01-01’]\nNumber of bands: 6\n\n‘low_tide_composite’:\n\ntitle: DEA Low Tide Imagery (Landsat)\ndescription: Low tide 20 percentage composites 25m v. 2.0.0\nbounding box: (112.223058990767, -43.8291965530654, 154.080299801132, -10.2371048142508)\ndate limits: [‘2000-01-01’, ‘2000-01-01’]\nNumber of bands: 6\n\n‘ga_s2_ba_provisional_3’:\n\ntitle: DEA Burnt Area Characteristic Layers (Sentinel 2 Near Real-Time, Provisional)\ndescription: Sentinel 2 Burnt Area Collection 3 (Provisional)\nbounding box: (111.966746816605, -44.3414673034495, 155.213824039639, -9.93000738897011)\ndate limits: [‘2021-10-01’, ‘2022-09-19’]\nNumber of bands: None\n\n‘alos_displacement’:\n\ntitle: ALOS Displacement\ndescription: CEMP InSAR ALOS Displacement\nbounding box: (150.330509919584, -34.5250413940276, 151.258021405841, -33.772472435988)\ndate limits: [‘2008-02-11’, ‘2010-10-22’]\nNumber of bands: 4\n\n‘alos_velocity’:\n\ntitle: ALOS Velocity\ndescription: CEMP InSAR ALOS Velocity\nbounding box: (150.331038253243, -34.5250413940276, 151.258021405841, -33.772472435988)\ndate limits: [‘2009-06-15’, ‘2009-06-15’]\nNumber of bands: 4\n\n‘envisat_displacement’:\n\ntitle: ENVISAT Displacement\ndescription: CEMP InSAR Envisat Displacement\nbounding box: (150.416357298779, -34.5283535864513, 151.184355816078, -33.5035077252927)\ndate limits: [‘2006-06-26’, ‘2010-08-28’]\nNumber of bands: 4\n\n‘envisat_velocity’:\n\ntitle: ENVISAT Velocity\ndescription: CEMP InSAR Envisat Velocity\nbounding box: (150.416357298779, -34.5283535864513, 151.184355816078, -33.5035077252927)\ndate limits: [‘2008-06-15’, ‘2008-06-15’]\nNumber of bands: 4\n\n‘radarsat2_displacement’:\n\ntitle: RADARSAT2 Displacement\ndescription: CEMP InSAR Radarsat-2 Displacement\nbounding box: (150.540420399293, -34.3792688432228, 151.151613477574, -33.8798432478719)\ndate limits: [‘2015-07-15’, ‘2019-05-31’]\nNumber of bands: 4\n\n‘radarsat2_velocity’:\n\ntitle: RADARSAT2 Velocity\ndescription: CEMP InSAR Radarsat-2 Velocity\nbounding box: (150.540420399293, -34.3792688432228, 151.151613477574, -33.8798432478719)\ndate limits: [‘2017-06-15’, ‘2017-06-15’]\nNumber of bands: 4\n\n‘aster_false_colour’:\n\ntitle: False Colour Mosaic\ndescription: ASTER\nbounding box: (112.917275536606, -44.013698912363, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 3\n\n‘aster_regolith_ratios’:\n\ntitle: Regolith Ratios\ndescription: ASTER\nbounding box: (112.917275536606, -44.013698912363, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 3\n\n‘aster_aloh_group_composition’:\n\ntitle: AlOH Group Composition\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_aloh_group_content’:\n\ntitle: AlOH Group Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_feoh_group_content’:\n\ntitle: FeOH Group Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferric_oxide_composition’:\n\ntitle: Ferric Oxide Composition\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferric_oxide_content’:\n\ntitle: Ferric Oxide Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferrous_iron_content_in_mgoh’:\n\ntitle: Ferrous Iron Content in MgOH/Carbonate\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferrous_iron_index’:\n\ntitle: Ferrous Iron Index\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_green_vegetation’:\n\ntitle: Green Vegetation Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_gypsum_index’:\n\ntitle: Gypsum Index\ndescription: ASTER\nbounding box: (112.917024138111, -43.7806027057097, 153.640358457438, -10.28257228)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_kaolin_group_index’:\n\ntitle: Kaolin Group Index\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_mgoh_group_composition’:\n\ntitle: MgOH Group Composition\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_mgoh_group_content’:\n\ntitle: MgOH Group Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_opaque_index’:\n\ntitle: Opaque Index\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_silica_index’:\n\ntitle: TIR Silica index\ndescription: ASTER\nbounding box: (112.917024138111, -43.7806027057097, 153.640358457438, -10.28257228)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_quartz_index’:\n\ntitle: TIR Quartz Index\ndescription: ASTER\nbounding box: (112.917024138111, -43.7806027057097, 153.640358457438, -10.28257228)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘multi_scale_topographic_position’:\n\ntitle: Multi-Scale Topographic Position\ndescription: Multi-scale Topographic Position Image\nbounding box: (112.9995833, -44.0004167, 153.9995833, -10.0004167)\ndate limits: [‘2018-01-01’, ‘2018-01-01’]\nNumber of bands: 3\n\n‘weathering_intensity’:\n\ntitle: Weathering Intensity\ndescription: Weathering Intensity Model\nbounding box: (112.9995833, -44.0004167, 153.9995833, -10.0004167)\ndate limits: [‘2018-01-01’, ‘2018-01-01’]\nNumber of bands: 1"
  },
  {
    "objectID": "docs/Data_Overview.html#gsky-data-server-for-dea-geoscience-earth-observations",
    "href": "docs/Data_Overview.html#gsky-data-server-for-dea-geoscience-earth-observations",
    "title": "Data Overview",
    "section": "",
    "text": "Description: Digital Earth Australia’s (DEA) Landsat Surface Reflectance products take Landsat 5 Thematic Mapper (TM), Landsat 7 Enhanced Thematic Mapper Plus (ETM+) and Landsat 8 Operational Land Imager (OLI) imagery captured over the Australian continent and corrects for inconsistencies across land and coastal fringes. This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles. Some of the layers include image composites that are made from images acquired within a 16 day period.\nModule name: getdata_dea_nci.py\nResolution: variable (typically 1 arcsec)\nUpdates: daily to yearly\nSource: https://opus.nci.org.au/display/Help/Datasets\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: The data products are produced using Digital Earth Australia. The WCS service relies on GSKY - A Scalable, Distributed Geospatial Data Service from the National Centre for Environmental Information (NCI).\nLayernames:\n\n‘blend_sentinel2_landsat_nbart_daily’ :\n\ntitle: Multi-sensor (Landsat and Sentinel 2) surface reflectance (Beta)\ndescription: This multi-sensor service has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. This service combines terrain corrected surface reflectance observations from three Landsat sensors (Landsat 5 TM, Landsat 7 ETM+, Landsat 8 OLI) and two Sentinel 2 sensors (Sentinel 2A and 2B). More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. The service for each day is composed from all acquisitions that occurred over the Australian region on that calendar day.\n\n‘hltc_high’ :\n\ntitle: DEA High Tide Composite 25m v2.0\ndescription: The High and Low Tide Composites product is composed of two surface reflectance composite mosaics of Landsat TM and ETM+ (Landsat 5 and Landsat 7 respectively) and OLI (Landsat 8) surface reflectance data Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. These products have been produced using Digital Earth Australia (DEA). The two mosaics allow cloud free and noise reduced visualisation of the shallow water and inter-tidal coastal regions of Australia, as observed at high and low tide respectively. The composites are generated utilising the geomedian approach of Roberts et al. (2017) (https://doi.org/10.1109/TGRS.2017.2723896) to ensure a valid surface reflectance spectra suitable for uses such as habitat mapping. The time range used for composite generation in each polygon of the mosaic is tailored to ensure dynamic coastal features are captured whilst still allowing a clean and cloud free composite to be generated (see Sagar et al. 2018 (https://doi.org/10.3390/rs10030480)). The concepts of the Observed Tidal Range (OTR), and Highest and Lowest Observed Tide (HOT, LOT) are discussed and described fully in Sagar et al. (2017) (https://doi.org/10.1016/j.rse.2017.04.009). This service provides access to the High Tide Composite v2.0 product. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a615705d20f7 .\n\n‘hltc_low’ :\n\ntitle: DEA Low Tide Composite 25m v2.0\ndescription: The High and Low Tide Composites product is composed of two surface reflectance composite mosaics of Landsat TM and ETM+ (Landsat 5 and Landsat 7 respectively) and OLI (Landsat 8) surface reflectance data Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. These products have been produced using Digital Earth Australia (DEA). The two mosaics allow cloud free and noise reduced visualisation of the shallow water and inter-tidal coastal regions of Australia, as observed at high and low tide respectively. The composites are generated utilising the geomedian approach of Roberts et al. (2017) (https://doi.org/10.1109/TGRS.2017.2723896) to ensure a valid surface reflectance spectra suitable for uses such as habitat mapping. The time range used for composite generation in each polygon of the mosaic is tailored to ensure dynamic coastal features are captured whilst still allowing a clean and cloud free composite to be generated (see Sagar et al. 2018 (https://doi.org/10.3390/rs10030480)). The concepts of the Observed Tidal Range (OTR), and Highest and Lowest Observed Tide (HOT, LOT) are discussed and described fully in Sagar et al. (2017) (https://doi.org/10.1016/j.rse.2017.04.009). This service provides access to the Low Tide Composite v2.0 product. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a615705d20f7 .\n\n‘item_relative’ :\n\ntitle: DEA Intertidal Extents Model Relative Layer 25m v2.0\ndescription: The Intertidal Extents Model (ITEM) product is a national dataset characterising the spatial extents of the exposed intertidal zone; the land between the observed highest and lowest tide, at intervals of the observed tidal range. ITEM provides the extent and topography of the intertidal zone of Australia’s coastline (excluding offshore Territories). This information was derived using observations in the Landsat archive since 1986. ITEM v2.0 has implemented an improved tidal modelling framework over that utilised in ITEM v1.0 (Sagar et al. 2017, 2018) (https://doi.org/10.1016/j.rse.2017.04.009, https://doi.org/10.3390/rs10030480). The expanded Landsat archive within the Digital Earth Australia (DEA) has also enabled the model extent to be increased from ITEM v1.0 to cover a number of offshore reefs, including the full Great Barrier Reef and southern sections of the Torres Strait Islands. ITEM can be a valuable complementary dataset to both onshore LiDAR survey data and coarser offshore bathymetry data, enabling a more realistic representation of the land and ocean interface. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a602cc9eb358. This service provides access to the Intertidal Extents Model v2.0 Relative Layer product. The relative layer displays the modelled extents of the exposed intertidal zone, at percentile intervals of the observed tidal range (OTR). For example, the region defined as 0-10% denotes an area that only exposes at the lowest 10% of tides in relation to the OTR.\n\n‘item_stddev’ :\n\ntitle: DEA Intertidal Extents Model Confidence Layer 25m v2.0\ndescription: The Intertidal Extents Model (ITEM) product is a national dataset characterising the spatial extents of the exposed intertidal zone; the land between the observed highest and lowest tide, at intervals of the observed tidal range. ITEM provides the extent and topography of the intertidal zone of Australia’s coastline (excluding offshore Territories). This information was derived using observations in the Landsat archive since 1986. ITEM v2.0 has implemented an improved tidal modelling framework over that utilised in ITEM v1.0 (Sagar et al. 2017, 2018) (https://doi.org/10.1016/j.rse.2017.04.009, https://doi.org/10.3390/rs10030480). The expanded Landsat archive within the Digital Earth Australia (DEA) has also enabled the model extent to be increased from ITEM v1.0 to cover a number of offshore reefs, including the full Great Barrier Reef and southern sections of the Torres Strait Islands. ITEM can be a valuable complementary dataset to both onshore LiDAR survey data and coarser offshore bathymetry data, enabling a more realistic representation of the land and ocean interface. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a602cc9eb358. This service provides access to the Intertidal Extents Model v2.0 Confidence Layer product. The confidence layer displays the standard deviation of the water index values (NDWI) derived across the tidal intervals used in generating the core ITEM relative extents product. High values indicate regions where inundation patterns are not driven by tidal influences. This can be a result of change (shoreline, geomorphic, anthropogenic), or caused by errors in the underlying tidal model.\n\n‘landsat5_nbar_16day’ :\n\ntitle: 16-day DEA Landsat 5 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 5 TM surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat5_nbar_daily’ :\n\ntitle: Daily DEA Landsat 5 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 5 TM surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat5_nbart_16day’ :\n\ntitle: 16-day DEA Landsat 5 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 5 Thematic Mapper (TM) terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat5_nbart_daily’ :\n\ntitle: Daily DEA Landsat 5 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 5 Thematic Mapper (TM) terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat7_nbar_16day’ :\n\ntitle: 16-day DEA Landsat 7 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 onwards are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat7_nbar_daily’ :\n\ntitle: Daily DEA Landsat 7 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 onwards are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat7_nbart_16day’ :\n\ntitle: 16-day DEA Landsat 7 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et. al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat7_nbart_daily’ :\n\ntitle: Daily DEA Landsat 7 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et. al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat8_nbar_16day’ :\n\ntitle: 16-day DEA Landsat 8 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 8 OLI surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat8_nbar_daily’ :\n\ntitle: Daily DEA Landsat 8 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 8 OLI surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat8_nbart_16day’ :\n\ntitle: 16-day DEA Landsat 8 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 8 OLI terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat8_nbart_daily’ :\n\ntitle: Daily DEA Landsat 8 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 8 OLI terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘sentinel2_nbart_daily’ :\n\ntitle: Sentinel 2 Analysis Ready Data\ndescription: The Surface Reflectance product has been corrected to account for variations caused by atmospheric properties, sun position and sensor view angle at time of image capture. These corrections have been applied to all satellite imagery in the Sentinel-2 archive. This is undertaken to allow comparison of imagery acquired at different times, by different sensors, in different seasons and in different geographic locations. These products also indicate where the imagery has been affected by cloud or cloud shadow, contains missing data or has been affected in other ways. The Surface Reflectance products are useful as a fundamental starting point for any further analysis and are the underlying data of all other Digital Earth Australia products."
  },
  {
    "objectID": "docs/Data_Overview.html#radiometric-data",
    "href": "docs/Data_Overview.html#radiometric-data",
    "title": "Data Overview",
    "section": "",
    "text": "Description: This radiometric sub-collection of the Geoscience Australia Geophysics Reference Data Collection are compilations of radiometric data from an extensive archive of geophysical surveys dating back to 1947, which are contained in other sub-collections of this collection. The individual survey datasets have been acquired by Geoscience Australia and its State and Territory Government partners. The compilations of radiometric data involved the levelling and merging (mosaicking) of regularly interpolated grid (raster) data, from selected individual geophysical surveys, into near-seamless national scale grids for each datatype and creating derivations thereof. The selected individual surveys are chosen based on the spatial resolution and accuracy of individual surveys within a given area.\nModule name: getdata_radiometric.py\nResolution: 100m (0.001 deg)\nUpdates: None\nSource: https://opus.nci.org.au/display/Help/Datasets,\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: Geoscience Australia. The WCS service relies on GSKY - A Scalable, Distributed Geospatial Data Service from the National Centre for Environmental Information (NCI).\nLayernames:\n\n‘radmap2019_grid_dose_terr_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered terrestrial dose rate\ndescription: The unfiltered terrestrial dose rate grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia, which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The unfiltered terrestrial dose rate grid is derived as a linear combination of the unfiltered K, U and Th grids, and has a cell size of about 100m (0.001 degrees).\n\n‘radmap2019_grid_dose_terr_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered terrestrial dose rate\ndescription: The filtered terrestrial dose rate grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia, made of a combination of over 600 individual survey grids. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The terrestrial dose rate grid is derived as a linear combination of the filtered K, U and Th grids. A low pass filter is applied to the unfiltered grid to generate the filtered terrestrial dose rate grid. The grid cell size is about 100m (0.001 degrees).\n\n‘radmap2019_grid_k_conc_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered pct potassium\ndescription: The unfiltered potassium grid is a derivative of the 2019 radiometric grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector. The 2019 unfiltered potassium grid has a cell size of about 100 m (0.001 degrees) and shows potassium element concentrations of the Australia region. Potassium is the seventh most abundant element in the Earth’s crust. The potassium concentration grid can be used to locate minerals and compounds containing potassium.\n\n‘radmap2019_grid_k_conc_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered pct potassium grid\ndescription: The filtered potassium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium, uranium and thorium. The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 filtered potassium grid has a cell size of about 100m (0.001 degrees) and shows potassium element concentrations of the Australia region. It was obtained by applying a low-pass filter to the original potassium grid. Potassium is the seventh most abundant element in the Earth’s crust. This potassium concentration grid can be used to locate minerals and compounds containing potassium.\n\n‘radmap2019_grid_th_conc_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered ppm thorium\ndescription: The unfiltered thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 unfiltered thorium grid has a cell size of about 100 m (0.001 degrees) and shows thorium element concentrations of the Australia region.\n\n‘radmap2019_grid_th_conc_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered ppm thorium\ndescription: The filtered thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector. The 2019 filtered thorium grid was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and shows thorium element concentrations of the Australia region.\n\n‘radmap2019_grid_thk_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio thorium over potassium\ndescription: The thorium over potassium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 thorium over potassium was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and is derived from the filtered thorium and potassium grids.\n\n‘radmap2019_grid_u2th_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio uranium squared over thorium\ndescription: The uranium squared over thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 uranium squared over thorium was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and is derived from the filtered uranium and thorium grids.\n\n‘radmap2019_grid_u_conc_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered ppm uranium\ndescription: The unfiltered uranium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium, uranium and thorium. The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 unfiltered uranium grid has a cell size of about 100m (0.001 degrees) and shows uranium element concentrations of the Australia region.\n\n‘radmap2019_grid_u_conc_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered ppm uranium\ndescription: The filtered uranium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 filtered uranium grid was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and shows uranium element concentrations of the Australia region.\n\n‘radmap2019_grid_uk_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio uranium over potassium\ndescription: The uranium over potassium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia comprising over 600 airborne gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 uranium over potassium grid has a cell size of about 100 m (0.001 degrees) and is derived from the filtered uranium and potassium grids.\n\n‘radmap2019_grid_uth_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio uranium over thorium\ndescription: The uranium over thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 uranium over thorium grid has a cell size of about 100 m (0.001 degrees) and is derived from the filtered uranium and thorium grids."
  },
  {
    "objectID": "docs/Data_Overview.html#landscape-data-slga",
    "href": "docs/Data_Overview.html#landscape-data-slga",
    "title": "Data Overview",
    "section": "",
    "text": "Description: The landscape attribute products available from the Soil and Landscape Grid of Australia (SLGA) were derived from DEM-S, the smoothed version of the national 1 second resolution Digital Elevation Model, which was derived from the 1 second resolution Shuttle Radar Topography Mission (SRTM) data acquired by NASA in February 2000.\nModule name: getdata_landscape.py\nResolution: 3 arcsec\nUpdates: None\nSource: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails.html”\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: CSIRO Australia, TERN (University of Queensland)\nBounding Box: (112.99958, -44.00042, 153.99958, -10.0004)\nLayernames:\n\n‘Prescott_index’\n\nkey: ‘1’\ntitle: Prescott Index\ndescription: Prescott Index derived from 1 second DEM-S version 0.1\n\n‘net_radiation_jan’\n\nkey: ‘2’\ntitle: Net Radiation [January]\ndescription: None\n\n‘net_radiation_july’\n\nkey: ‘3’\ntitle: Net Radiation [July]\ndescription: None\n\n‘total_shortwave_sloping_surf_jan’\n\nkey: ‘4’\ntitle: Total Shortwave Sloping Surf [January]\ndescription: None\n\n‘total_shortwave_sloping_surf_july’\n\nkey: ‘5’\ntitle: Total Shortwave Sloping Surf [July]\ndescription: None\n\n‘Slope’\n\nkey: ‘6’\ntitle: Slope [percent]\ndescription: Percent slope (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Slope_median_300m’\n\nkey: ‘7’\ntitle: Slope [percent] Median 300m Radius\ndescription: Median of Percent slope at 300m radius (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Slope_relief_class’\n\nkey: ‘8’\ntitle: Slope Relief Class\ndescription: Slope relief (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Aspect’\n\nkey: ‘9’\ntitle: Aspect\ndescription: Aspect (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Relief_1000m’\n\nkey: ‘10’\ntitle: Relief [1000m radius]\ndescription: 1000 m elevation range (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Relief_300m’\n\nkey: ‘11’\ntitle: Relief [300m radius]\ndescription: 300 m elevation range (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Topographic_wetness_index’\n\nkey: ‘12’\ntitle: Topographic Wetness Index\ndescription: Topographic Wetness Index (3” resolution) derived from 1 second DEM-H version 1.0\n\n‘TPI_mask’\n\nkey: ‘13’\ntitle: TPI Mask\ndescription: None\n\n‘SRTM_TopographicPositionIndex’\n\nkey: ‘14’\ntitle: SRTM_TopographicPositionIndex\ndescription: Topographic position index (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Contributing_area’\n\nkey: ‘15’\ntitle: Contributing Area [partial]\ndescription: Contributing Area - Multiple Flow Direction (Partial), 3” resolution, derived from 1 second DEM-H version 1.0\n\n‘MrVBF’\n\nkey: ‘16’\ntitle: MrVBF\ndescription: Multi-resolution Valley Bottom Flatness (MrVBF) at 3 second resolution derived from 1 second DEM-S version 1.0\n\n‘Plan_curvature’\n\nkey: ‘17’\ntitle: Plan Curvature\ndescription: Plan curvature (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Profile_curvature’\n\nkey: ‘18’\ntitle: Profile Curvature\ndescription: Profile curvature (3”resolution) derived from 1 second DEM-S version 0.1"
  },
  {
    "objectID": "docs/Earth_Engine_Data_Overview.html",
    "href": "docs/Earth_Engine_Data_Overview.html",
    "title": "Earth Engine Data Overview",
    "section": "",
    "text": "Version 0.1.0 | 5 Aug 2022\n\n\nThrough the Google Earth Engine API, the AgReFed Data-Harvester provides access to the following satellite products:\n\nUSGS Landsat 9 Level 2, Collection 2, Tier 1\nUSGS Landsat 8 Level 2, Collection 2, Tier 1\nUSGS Landsat 7 Level 2, Collection 2, Tier 1\nUSGS Landsat 5 Level 2, Collection 2, Tier 1\nSentinel-2 MSI: MultiSpectral Instrument, Level-2A\n\nNote that Earth Engine is still under active development. Download and access limits apply, including a maximum download size of 32 MB (but, ~50MB raw). The Data Harvester uses the geedim package to overcome this ceiling but cloud processing limits (e.g. during compositing of images) will continue to limit the amount of data that can be downloaded.\n\n\n\nThe USGS/NASA Landsat Program provides satellite spectral and thermal data of the Earth from 1972. Collection 2, Tier 1 products in the catalog represent data of the highest available quality with inclusions of corrections for improved geometric accuracy, digital elevation modeling and radiometric calibrations. Strips of collected data are packaged into overlapping “scenes” covering approximately 170 km x 183 km using a standardized reference grid.\nCoverage: See coverage here\nResolution: 15/30/100 m\nPeriod (y-m-d):\n\nLandsat 9 : 2021-10-31 – present\nLandsat 8 : 2013-03-18 – present\nLandsat 7 : 1999-05-28 – 2022-04-06\nLandsat 5 : 1984-03-16 – 2012-05-05\n\nUpdates: Daily\nRevisit frequency: 16 days\nAttribution: tbd\n\n\n\nSentinel-2 is part of a constellation of satellites in the Copernicus Program and surface reflectance images have been available from 2017. Level 2A images provide orthorectified and atmospherically corrected surface reflectance data. Each Level 2A product is composed of 100 km2 tiles in cartographic geometry (UTM/WGS84 projection).\nCoverage: See coverage here\nResolution: 10/20/60 m\nPeriod (y-m-d): 2017-03-28 – present\nUpdates: Daily\nRevisit frequency: 5 days\nAttribution: tbd\n\n\n\nThe following functionality are supported:\n\nSelecting image(s) based on date(s)\nAutomatic cloud masking, shadow masking, using eemont and geedim\nAutomatic scale and offsetting, using eemont\nImage compositioning/reduction\nAutomatic calculation of spectral indices (via Awesome Spectral Indices)\nInteractive map previews, with automatic pixel stretching, using geemap and geetools\nDownload image(s) using split-download-assemble method to overcome size limits, using geedim"
  },
  {
    "objectID": "docs/Earth_Engine_Data_Overview.html#introduction",
    "href": "docs/Earth_Engine_Data_Overview.html#introduction",
    "title": "Earth Engine Data Overview",
    "section": "",
    "text": "Through the Google Earth Engine API, the AgReFed Data-Harvester provides access to the following satellite products:\n\nUSGS Landsat 9 Level 2, Collection 2, Tier 1\nUSGS Landsat 8 Level 2, Collection 2, Tier 1\nUSGS Landsat 7 Level 2, Collection 2, Tier 1\nUSGS Landsat 5 Level 2, Collection 2, Tier 1\nSentinel-2 MSI: MultiSpectral Instrument, Level-2A\n\nNote that Earth Engine is still under active development. Download and access limits apply, including a maximum download size of 32 MB (but, ~50MB raw). The Data Harvester uses the geedim package to overcome this ceiling but cloud processing limits (e.g. during compositing of images) will continue to limit the amount of data that can be downloaded."
  },
  {
    "objectID": "docs/Earth_Engine_Data_Overview.html#landsat",
    "href": "docs/Earth_Engine_Data_Overview.html#landsat",
    "title": "Earth Engine Data Overview",
    "section": "",
    "text": "The USGS/NASA Landsat Program provides satellite spectral and thermal data of the Earth from 1972. Collection 2, Tier 1 products in the catalog represent data of the highest available quality with inclusions of corrections for improved geometric accuracy, digital elevation modeling and radiometric calibrations. Strips of collected data are packaged into overlapping “scenes” covering approximately 170 km x 183 km using a standardized reference grid.\nCoverage: See coverage here\nResolution: 15/30/100 m\nPeriod (y-m-d):\n\nLandsat 9 : 2021-10-31 – present\nLandsat 8 : 2013-03-18 – present\nLandsat 7 : 1999-05-28 – 2022-04-06\nLandsat 5 : 1984-03-16 – 2012-05-05\n\nUpdates: Daily\nRevisit frequency: 16 days\nAttribution: tbd"
  },
  {
    "objectID": "docs/Earth_Engine_Data_Overview.html#sentinel-2-level-2a",
    "href": "docs/Earth_Engine_Data_Overview.html#sentinel-2-level-2a",
    "title": "Earth Engine Data Overview",
    "section": "",
    "text": "Sentinel-2 is part of a constellation of satellites in the Copernicus Program and surface reflectance images have been available from 2017. Level 2A images provide orthorectified and atmospherically corrected surface reflectance data. Each Level 2A product is composed of 100 km2 tiles in cartographic geometry (UTM/WGS84 projection).\nCoverage: See coverage here\nResolution: 10/20/60 m\nPeriod (y-m-d): 2017-03-28 – present\nUpdates: Daily\nRevisit frequency: 5 days\nAttribution: tbd"
  },
  {
    "objectID": "docs/Earth_Engine_Data_Overview.html#functionality",
    "href": "docs/Earth_Engine_Data_Overview.html#functionality",
    "title": "Earth Engine Data Overview",
    "section": "",
    "text": "The following functionality are supported:\n\nSelecting image(s) based on date(s)\nAutomatic cloud masking, shadow masking, using eemont and geedim\nAutomatic scale and offsetting, using eemont\nImage compositioning/reduction\nAutomatic calculation of spectral indices (via Awesome Spectral Indices)\nInteractive map previews, with automatic pixel stretching, using geemap and geetools\nDownload image(s) using split-download-assemble method to overcome size limits, using geedim"
  },
  {
    "objectID": "docs/How_to_add_DataSources.html",
    "href": "docs/How_to_add_DataSources.html",
    "title": "How to add new Data Sources",
    "section": "",
    "text": "How to add new Data Sources\nThe Geodata-Harvester is designed to be extendable and new data source modules can be added as Python modules. The naming convention for the data modules are getdata_SOURCENAME.py with SOURCENAME as the data source name. For an example adding a WebMap service request (WMS/WCS) see getdata_radiometric.py, or for requesting raster data from an AWS server, see as example getdata_silo.py.\nEach data source module consists of at least three core functions:\n\nget_layers function with the following main arguments:\n\ndate_start\ndate_end\nbbox\nresolution\noutpath\nverbose (boolean, for logging options) other optional arguments could be crs (typically “EPSG:4326”), output_format (typically “GeoTIFF” or “netCDF”)\n\nget_capabilities() : returns data server capabilities such as available layernames and metadata (helpful for developing get data requests and documentation)\nget_dict(): returns dictionary of data source selected layernames, options, attributions and license (helpful for validation test, widget selections, and automating attributions/ licensing)\n\nTo invoke the new data source module, you need to import the module (e.g., in your Jupyter notebook) and add new source-name to the settings YAML file under the entry target_sources:, with layername and options as sublist or dict (see existing data source settings as example). This will enable to load the settings into the settings Namespace (via load_settings function in harvesterwidgets.py).\nTo integrate a new module into the geodata-harvester package, you may need to modify the following files:\n\nsrc/geodata_harveseter/init.py (for making new module available in package NameSpace)\nsrc/geodata_harveseter/harvest.py (to automate aggregation with all other layers by callinbg one function)\nsrc/geodata_harveseter/widgets/harvesterwidgets.py (to include and select settings for the new data source via Jupyter widgets)\nsrc/geodata_harveseter/validate_settings.py (optional)\nupdate documentation Data_Overview.md\n\nPlease add test functions for the new data module (either in the module file or as sepepare test script in folder tests). Adding an example notebook that demonstrates how to use new data source is encouraged as well.\nFor development of new data source modules, we recommend to fork the geodata-harvester repo and develop new modules in a local environment (see environment.yaml). If you would like to contribute your data source module to the geodata-harvester package, please visit the geodata-harvester contribution guidelines."
  },
  {
    "objectID": "docs/Settings_Overview.html",
    "href": "docs/Settings_Overview.html",
    "title": "Settings Overview",
    "section": "",
    "text": "The following documentation outlines the available settings for the Data Harvester. For a more interactive exploration of settings, please use the harvesterwidget (see, e.g., example widget notebook).\n\n\n\nYAML File Format\nJupyter Settings Widget\nSettings Validation\nInput and Output Settings\nSpatial and Temporal Settings\nData Selection Settings\n\n\n\n\nThe settings are specified by the user in a .yaml settings file (see e.g., settings/settings_v0.3.yaml). A YAML file is a Unicode based language and is designed for human interaction and to work well with modern programming languages, and is typically used for configuration settings and reusable workflows. YAML uses the .yaml extension (alternatively .yml) for its files. Its syntax is independent of a specific programming language.\nTemplates for the .yaml settings file are provided in the folder settings. More information about YAML Syntax can be found here.\n\n\n\nAlternatively, settings can be selected in the interactive widget of the Jupyter Notebook, which also automatically saves all settings for a run in a .yaml file as well. The interactive widgets are powered by ipywidgets and are currently supported for the Jupyter Notebooks. The widget also allows the user to load a saved .yaml file.\nNote for developers: To make changes to the functionality of the widgets (e.g, extending with new settings or options), please see the script harvesterwidgets.py in the folder widgets.\n\n\n\nThe settings file can be validated and checked for correct options (e.g. valid schema, data types, and data ranges) via the function validate in validate_settings.py, e.g.:\nfname_settings = 'settings_harvest.yaml'\nimport validate_settings\nvalidate_settings.validate(fname_settings)\nNote for developers: Please update validate_settings.py and version if new data layers or options are added to the Data-Harvester.\n\n\n\nThe input file name is specified in infile and is a .csv file that and must include at least point coordinates. The Data Harvester will download new data for these coordinates and align with any given data in the input file. Th column names for the latitude and longitude coordinates are selected by the settings colname_lat and colname_lng, respectively.\nAll data results and images will be saved in the output directory as specified in the settings outpath.\nExample:\n#Input File:\ninfile: ../testdata/Pointdata_Llara.csv\n\n#Output Path:\noutpath: ../../dataresults/\n\n#Headername of Latitude in input file:\ncolname_lat: Lat\n\n#Headername of Longitude in input file:\ncolname_lng: Long\n\n\n\nThe spatial extent of the requested images can be given as bounding box list in the settings target_bbox, in the order: lng_min, lat_min, lng_max, lat_max (left, bottom, right, top corner of box). If no bounding box is provided, Geodata-Harvester will automatically infer a padded bounding box based on the extent of the coordinates given in the input file.\nThe spatial resolution of the requested images is specified in target_res and given in arcsec (1 arcsec corresponds to roughly 30m on the Equator, please see arc2meter.pyfor calculating exact conversion of meter to arcsec and vice versa).\nThe time range for the requested data is specified via minimum date date_min and maximum date date_max (format: YYYY-MM-DD). All data available withon this time interval will be extracted.\nFor data extraction, the user can choose a number of times slices for the given period which is given as integer number temp_intervals. The time buffer window can be provided as number of days in temp_buffer, which specifies the number of days for which data is aggregated around each time slice. For example, if date_min to date_max is 24 weeks, temp_intervals = 24, and temp_buffer = 7, the data-table will be populated with the aggregated stats for each week within the specified time period. If temp_buffer is set to 1, the nearest available date will be extracted for each time slice.\nExample:\n#Bounding Box as (lng_min, lat_min, lng_max, lat_max):\ntarget_bbox: ''\n\n#Select start date:\ndate_min: : 2023-01-01\n\n#Select end date:\ndate_max: : 2023-02-01\n\n#Spatial Resolution [in arcsec]:\ntarget_res: 6.0\n\n#Temporal buffer window (in days)\ntemp_buffer: 1\n\n# Number of time interval slices in given date range\ntemp_intervals: 4\n\n\n\nThe requested layers are specified in the settings target_sources. The following data sources are currently supported:\n\n\nThese are pre-processed and national calibrated satellite image layers provided Digital Earth Australia (DEA) Geoscience Earth Observations. Multiple layers can be given as list in the settings. For more details see Data Overview DEA.\n\n\n\nThe DEM data is given by the National Digital Elevation Model 1 Second Hydrologically Enforced. Options are: ‘DEM’, ‘Slope’, and ‘Aspect’. For more info see Data Overview DEM.\n\n\n\nLandscape data can be retrieved from SLGA. For an overview of all available layers see Data Overview Landscape.\n\n\n\nFor an overview of the radiometric layer options see Data Overview Radiometric.\n\n\n\nSILO is containing continuous daily climate data for Australia. An overview of the available data layers is provided in Data Overview SILO.\nFor each requested SILO data layer, at least one temporal aggregation method has to be provided, which will be applied to aggregate climate data over the specified temporal range. The following options are available: ‘mean’, ‘median’, ‘sum’, ‘std’, ‘perc95’, ‘perc5’, ‘max’, ‘min’\n\n\n\nAn overview of the soil attributes is given in in Data Overview SLGA.\nEach soil attribute has six depth layers (plus their upper and lower confidence limits), with the following options:‘0-5cm’, ‘5-15cm’, ‘15-30cm’, ‘30-60cm’, ‘60-100cm’ and ‘100-200cm’.\n\n\n\nAn overview of the available Google Earth Engine (GEE) data and options is provided in Data Overview GEE. Settings for GEE are added in the entry GEE (see example with descriptions below).\nA complete list of the available spectral indices can be found here\nFor more details on GEE settings, please visit the GEE API documentation or eeharvest documentation.\nNote that GEE requires a Google account and a GEE authorization. If this is you first time using GEE, please follow these instructions. In the next step you must authorise Geodata-Harvester to use the Google Earth Engine API. See a preview of the process here.\nExample:\ntarget_sources:\n  #Satellite data from Digital Earth Australia\n  DEA:\n  - landsat_barest_earth\n\n  #National Digital Elevation Model (DEM) 1 Second\n  DEM:\n  - DEM\n  \n  #Landscape Data \n  Landscape:\n  - Slope\n  - Aspect\n  - Relief_300m\n\n  #Radiometric Data\n  Radiometric:\n  - radmap2019_grid_dose_terr_awags_rad_2019\n  - radmap2019_grid_dose_terr_filtered_awags_rad_2019\n\n  # SILO Climate Data\n  # temporal aggregation options: 'mean', 'median', 'sum', 'std', 'perc95', 'perc5', 'max', 'min'\n  SILO:\n    max_temp:\n    - Median\n    min_temp:\n    - Median\n    monthly_rain:\n    - Total\n\n  #Soil data from SLGA\n  SLGA:\n   Bulk_Density:\n    - 0-5cm\n   Clay:\n    - 0-5cm\n\n  #Satellite data layers from Google Earth Engine\n  GEE: \n    preprocess:\n\n      ### collection as defined in the Earth Engine Catalog \n      # NEW: for multiple collections please add list of collection names\n      collection: LANDSAT/LC09/C02/T1_L2\n\n      #### circular buffer in metres (optional)\n      buffer: null\n\n      #### convert buffer into square bounding box instead (optional)\n      bound: null\n\n      #### cloud masking option\n      mask_clouds: True\n\n      #### Set probability for mask cloud (between 0 to 1), optional\n      mask_probability: null\n\n      #### composite image based on summary stat provided\n      # e.g.: min, max, median, mean, stdDev (see GEE API references)\n      reduce: median\n\n      #### spectral indices to calculate via Awesome Spectral Indices site\n      # examples: NDVI, EVI, AVI, BI \n      spectral:\n        - NDVI\n\n    download:\n      # set bands (either band names or spectral index names) If multiple collections are selected, \n      # add for each collection a list of bands, e.g., [[NDVI, SR_B2],[SR_B23, SR_B4]]\n      bands: \n        - NDVI\n        - SR_B2\n        - SR_B3\n        - SR_B4"
  },
  {
    "objectID": "docs/Settings_Overview.html#table-of-contents",
    "href": "docs/Settings_Overview.html#table-of-contents",
    "title": "Settings Overview",
    "section": "",
    "text": "YAML File Format\nJupyter Settings Widget\nSettings Validation\nInput and Output Settings\nSpatial and Temporal Settings\nData Selection Settings"
  },
  {
    "objectID": "docs/Settings_Overview.html#yaml-file-format",
    "href": "docs/Settings_Overview.html#yaml-file-format",
    "title": "Settings Overview",
    "section": "",
    "text": "The settings are specified by the user in a .yaml settings file (see e.g., settings/settings_v0.3.yaml). A YAML file is a Unicode based language and is designed for human interaction and to work well with modern programming languages, and is typically used for configuration settings and reusable workflows. YAML uses the .yaml extension (alternatively .yml) for its files. Its syntax is independent of a specific programming language.\nTemplates for the .yaml settings file are provided in the folder settings. More information about YAML Syntax can be found here."
  },
  {
    "objectID": "docs/Settings_Overview.html#jupyter-settings-widget",
    "href": "docs/Settings_Overview.html#jupyter-settings-widget",
    "title": "Settings Overview",
    "section": "",
    "text": "Alternatively, settings can be selected in the interactive widget of the Jupyter Notebook, which also automatically saves all settings for a run in a .yaml file as well. The interactive widgets are powered by ipywidgets and are currently supported for the Jupyter Notebooks. The widget also allows the user to load a saved .yaml file.\nNote for developers: To make changes to the functionality of the widgets (e.g, extending with new settings or options), please see the script harvesterwidgets.py in the folder widgets."
  },
  {
    "objectID": "docs/Settings_Overview.html#settings-validation",
    "href": "docs/Settings_Overview.html#settings-validation",
    "title": "Settings Overview",
    "section": "",
    "text": "The settings file can be validated and checked for correct options (e.g. valid schema, data types, and data ranges) via the function validate in validate_settings.py, e.g.:\nfname_settings = 'settings_harvest.yaml'\nimport validate_settings\nvalidate_settings.validate(fname_settings)\nNote for developers: Please update validate_settings.py and version if new data layers or options are added to the Data-Harvester."
  },
  {
    "objectID": "docs/Settings_Overview.html#input-and-output-settings",
    "href": "docs/Settings_Overview.html#input-and-output-settings",
    "title": "Settings Overview",
    "section": "",
    "text": "The input file name is specified in infile and is a .csv file that and must include at least point coordinates. The Data Harvester will download new data for these coordinates and align with any given data in the input file. Th column names for the latitude and longitude coordinates are selected by the settings colname_lat and colname_lng, respectively.\nAll data results and images will be saved in the output directory as specified in the settings outpath.\nExample:\n#Input File:\ninfile: ../testdata/Pointdata_Llara.csv\n\n#Output Path:\noutpath: ../../dataresults/\n\n#Headername of Latitude in input file:\ncolname_lat: Lat\n\n#Headername of Longitude in input file:\ncolname_lng: Long"
  },
  {
    "objectID": "docs/Settings_Overview.html#spatial-and-temporal-settings",
    "href": "docs/Settings_Overview.html#spatial-and-temporal-settings",
    "title": "Settings Overview",
    "section": "",
    "text": "The spatial extent of the requested images can be given as bounding box list in the settings target_bbox, in the order: lng_min, lat_min, lng_max, lat_max (left, bottom, right, top corner of box). If no bounding box is provided, Geodata-Harvester will automatically infer a padded bounding box based on the extent of the coordinates given in the input file.\nThe spatial resolution of the requested images is specified in target_res and given in arcsec (1 arcsec corresponds to roughly 30m on the Equator, please see arc2meter.pyfor calculating exact conversion of meter to arcsec and vice versa).\nThe time range for the requested data is specified via minimum date date_min and maximum date date_max (format: YYYY-MM-DD). All data available withon this time interval will be extracted.\nFor data extraction, the user can choose a number of times slices for the given period which is given as integer number temp_intervals. The time buffer window can be provided as number of days in temp_buffer, which specifies the number of days for which data is aggregated around each time slice. For example, if date_min to date_max is 24 weeks, temp_intervals = 24, and temp_buffer = 7, the data-table will be populated with the aggregated stats for each week within the specified time period. If temp_buffer is set to 1, the nearest available date will be extracted for each time slice.\nExample:\n#Bounding Box as (lng_min, lat_min, lng_max, lat_max):\ntarget_bbox: ''\n\n#Select start date:\ndate_min: : 2023-01-01\n\n#Select end date:\ndate_max: : 2023-02-01\n\n#Spatial Resolution [in arcsec]:\ntarget_res: 6.0\n\n#Temporal buffer window (in days)\ntemp_buffer: 1\n\n# Number of time interval slices in given date range\ntemp_intervals: 4"
  },
  {
    "objectID": "docs/Settings_Overview.html#data-selection-settings",
    "href": "docs/Settings_Overview.html#data-selection-settings",
    "title": "Settings Overview",
    "section": "",
    "text": "The requested layers are specified in the settings target_sources. The following data sources are currently supported:\n\n\nThese are pre-processed and national calibrated satellite image layers provided Digital Earth Australia (DEA) Geoscience Earth Observations. Multiple layers can be given as list in the settings. For more details see Data Overview DEA.\n\n\n\nThe DEM data is given by the National Digital Elevation Model 1 Second Hydrologically Enforced. Options are: ‘DEM’, ‘Slope’, and ‘Aspect’. For more info see Data Overview DEM.\n\n\n\nLandscape data can be retrieved from SLGA. For an overview of all available layers see Data Overview Landscape.\n\n\n\nFor an overview of the radiometric layer options see Data Overview Radiometric.\n\n\n\nSILO is containing continuous daily climate data for Australia. An overview of the available data layers is provided in Data Overview SILO.\nFor each requested SILO data layer, at least one temporal aggregation method has to be provided, which will be applied to aggregate climate data over the specified temporal range. The following options are available: ‘mean’, ‘median’, ‘sum’, ‘std’, ‘perc95’, ‘perc5’, ‘max’, ‘min’\n\n\n\nAn overview of the soil attributes is given in in Data Overview SLGA.\nEach soil attribute has six depth layers (plus their upper and lower confidence limits), with the following options:‘0-5cm’, ‘5-15cm’, ‘15-30cm’, ‘30-60cm’, ‘60-100cm’ and ‘100-200cm’.\n\n\n\nAn overview of the available Google Earth Engine (GEE) data and options is provided in Data Overview GEE. Settings for GEE are added in the entry GEE (see example with descriptions below).\nA complete list of the available spectral indices can be found here\nFor more details on GEE settings, please visit the GEE API documentation or eeharvest documentation.\nNote that GEE requires a Google account and a GEE authorization. If this is you first time using GEE, please follow these instructions. In the next step you must authorise Geodata-Harvester to use the Google Earth Engine API. See a preview of the process here.\nExample:\ntarget_sources:\n  #Satellite data from Digital Earth Australia\n  DEA:\n  - landsat_barest_earth\n\n  #National Digital Elevation Model (DEM) 1 Second\n  DEM:\n  - DEM\n  \n  #Landscape Data \n  Landscape:\n  - Slope\n  - Aspect\n  - Relief_300m\n\n  #Radiometric Data\n  Radiometric:\n  - radmap2019_grid_dose_terr_awags_rad_2019\n  - radmap2019_grid_dose_terr_filtered_awags_rad_2019\n\n  # SILO Climate Data\n  # temporal aggregation options: 'mean', 'median', 'sum', 'std', 'perc95', 'perc5', 'max', 'min'\n  SILO:\n    max_temp:\n    - Median\n    min_temp:\n    - Median\n    monthly_rain:\n    - Total\n\n  #Soil data from SLGA\n  SLGA:\n   Bulk_Density:\n    - 0-5cm\n   Clay:\n    - 0-5cm\n\n  #Satellite data layers from Google Earth Engine\n  GEE: \n    preprocess:\n\n      ### collection as defined in the Earth Engine Catalog \n      # NEW: for multiple collections please add list of collection names\n      collection: LANDSAT/LC09/C02/T1_L2\n\n      #### circular buffer in metres (optional)\n      buffer: null\n\n      #### convert buffer into square bounding box instead (optional)\n      bound: null\n\n      #### cloud masking option\n      mask_clouds: True\n\n      #### Set probability for mask cloud (between 0 to 1), optional\n      mask_probability: null\n\n      #### composite image based on summary stat provided\n      # e.g.: min, max, median, mean, stdDev (see GEE API references)\n      reduce: median\n\n      #### spectral indices to calculate via Awesome Spectral Indices site\n      # examples: NDVI, EVI, AVI, BI \n      spectral:\n        - NDVI\n\n    download:\n      # set bands (either band names or spectral index names) If multiple collections are selected, \n      # add for each collection a list of bands, e.g., [[NDVI, SR_B2],[SR_B23, SR_B4]]\n      bands: \n        - NDVI\n        - SR_B2\n        - SR_B3\n        - SR_B4"
  },
  {
    "objectID": "docs/Contributing.html",
    "href": "docs/Contributing.html",
    "title": "Welcome to Geodata-Harvester Contributing Guide",
    "section": "",
    "text": "Thank you for investing your time in contributing to our project! We appreciate your interest in contributing to Geodata-Harvesterproject. Your contributions can help improve the software and make it more useful for others.\nIn this guideline, we’ll explain how you can contribute to the project. Contributions to the geodata-harvester can be made in many ways, such as:\n\nFeedback and bug reports via Github Issue\nUse-case examples via notebook contributions\nSource-code contributions\nData-source contributions\nUpdating existing data source modules\nImproving documentation\n\n\n\nTo report bugs or provide feedback, you can use the Github Issues feature. If you spot a problem or have a suggestion for improvement, search if an issue already exists. If a related issue doesn’t exist, please open a new issue. The issue should address what is the current problem, where it occurs, and, if possible, one suggestion how this problem can potentially be solved.\nIf this is a bug report, please provide a clear and concise description of the issue and any relevant information such as error messages including file name and code line, installation details, and all steps to reproduce the problem.\n\n\n\nScan through our existing issues to find one that interests you. As a general rule, we don’t assign issues to anyone. If you find an issue to work on, you are welcome to open a pull request with a fix.\n\n\n\nIf you have an interesting use-case for the geodata-harvester, we would love to hear about it! A great way to demonstrate use-cases is via Jupyter notebooks, which provide helpful workflows to the community. Currently we maintain a few example notebooks that demonstrate some use-cases of the GeoData-Harvester. If you make use of this package, you are welcome to contribute by improving existing notebooks or creating a Jupyter Notebook with your example and sharing it with us.\nTo contribute, please fork the geodata-harvester repo and add your notebook and settings file to the folder notebooks. For reproducible research we encourage the use of settings YAML files (see notebooks/settings). Please give the settings file a name that corresponds to the notebook name. Then commit your changes and create a pull request to share with us.\n\n\n\nFor small documentation changes and suggestion to improve existing documentation, please open a new Issue. If you would like to add/edit some more documentation, please fork the repo, edit the corresponding .md file, commit the change, and submit a pull request for a review.\n\n\n\nWe welcome contributions to improve the Python code and to keep the data-source handlers up-to-date. If you have experience with Python programming and would like to contribute to the source code, we suggest the following guidelines:\n\nFork the repository and clone it to your local machine.\nCreate a new branch for your changes.\nWrite clear, concise, and well-documented code.\nTest your changes thoroughly.\nSubmit a pull request with a description of your changes and any relevant information.\n\n\n\n\nIf you would like to add a new data source module or update an existing one, please visit the adding new data source guidelines. Please also check if there are any open Issue requests about the data source that you would like to add. To contribute a new data source module, follow these guidelines:\n\nCheck the existing data source modules for inspiration.\nWrite clear, concise, and well-documented code.\nTest your changes thoroughly (test scripts and example notebook demonstrating the new data source are welcome!)\nSubmit a pull request with a description of your changes and any relevant information.\n\n\n\n\nPlease keep in mind that the geodata-harvester project follows the GitHub Community Code of Conduct, which requires respectful and professional behavior.\nWe appreciate your contributions to the geodata-harvester project and look forward to working with you! If you have any questions or need help, don’t hesitate to reach out."
  },
  {
    "objectID": "docs/Contributing.html#feedback-and-bug-reports-create-a-new-issue",
    "href": "docs/Contributing.html#feedback-and-bug-reports-create-a-new-issue",
    "title": "Welcome to Geodata-Harvester Contributing Guide",
    "section": "",
    "text": "To report bugs or provide feedback, you can use the Github Issues feature. If you spot a problem or have a suggestion for improvement, search if an issue already exists. If a related issue doesn’t exist, please open a new issue. The issue should address what is the current problem, where it occurs, and, if possible, one suggestion how this problem can potentially be solved.\nIf this is a bug report, please provide a clear and concise description of the issue and any relevant information such as error messages including file name and code line, installation details, and all steps to reproduce the problem."
  },
  {
    "objectID": "docs/Contributing.html#solve-an-open-issue",
    "href": "docs/Contributing.html#solve-an-open-issue",
    "title": "Welcome to Geodata-Harvester Contributing Guide",
    "section": "",
    "text": "Scan through our existing issues to find one that interests you. As a general rule, we don’t assign issues to anyone. If you find an issue to work on, you are welcome to open a pull request with a fix."
  },
  {
    "objectID": "docs/Contributing.html#use-case-example-notebooks",
    "href": "docs/Contributing.html#use-case-example-notebooks",
    "title": "Welcome to Geodata-Harvester Contributing Guide",
    "section": "",
    "text": "If you have an interesting use-case for the geodata-harvester, we would love to hear about it! A great way to demonstrate use-cases is via Jupyter notebooks, which provide helpful workflows to the community. Currently we maintain a few example notebooks that demonstrate some use-cases of the GeoData-Harvester. If you make use of this package, you are welcome to contribute by improving existing notebooks or creating a Jupyter Notebook with your example and sharing it with us.\nTo contribute, please fork the geodata-harvester repo and add your notebook and settings file to the folder notebooks. For reproducible research we encourage the use of settings YAML files (see notebooks/settings). Please give the settings file a name that corresponds to the notebook name. Then commit your changes and create a pull request to share with us."
  },
  {
    "objectID": "docs/Contributing.html#documentation-contributions",
    "href": "docs/Contributing.html#documentation-contributions",
    "title": "Welcome to Geodata-Harvester Contributing Guide",
    "section": "",
    "text": "For small documentation changes and suggestion to improve existing documentation, please open a new Issue. If you would like to add/edit some more documentation, please fork the repo, edit the corresponding .md file, commit the change, and submit a pull request for a review."
  },
  {
    "objectID": "docs/Contributing.html#source-code-contributions",
    "href": "docs/Contributing.html#source-code-contributions",
    "title": "Welcome to Geodata-Harvester Contributing Guide",
    "section": "",
    "text": "We welcome contributions to improve the Python code and to keep the data-source handlers up-to-date. If you have experience with Python programming and would like to contribute to the source code, we suggest the following guidelines:\n\nFork the repository and clone it to your local machine.\nCreate a new branch for your changes.\nWrite clear, concise, and well-documented code.\nTest your changes thoroughly.\nSubmit a pull request with a description of your changes and any relevant information."
  },
  {
    "objectID": "docs/Contributing.html#data-source-module-contributions",
    "href": "docs/Contributing.html#data-source-module-contributions",
    "title": "Welcome to Geodata-Harvester Contributing Guide",
    "section": "",
    "text": "If you would like to add a new data source module or update an existing one, please visit the adding new data source guidelines. Please also check if there are any open Issue requests about the data source that you would like to add. To contribute a new data source module, follow these guidelines:\n\nCheck the existing data source modules for inspiration.\nWrite clear, concise, and well-documented code.\nTest your changes thoroughly (test scripts and example notebook demonstrating the new data source are welcome!)\nSubmit a pull request with a description of your changes and any relevant information."
  },
  {
    "objectID": "docs/Contributing.html#code-of-conduct",
    "href": "docs/Contributing.html#code-of-conduct",
    "title": "Welcome to Geodata-Harvester Contributing Guide",
    "section": "",
    "text": "Please keep in mind that the geodata-harvester project follows the GitHub Community Code of Conduct, which requires respectful and professional behavior.\nWe appreciate your contributions to the geodata-harvester project and look forward to working with you! If you have any questions or need help, don’t hesitate to reach out."
  },
  {
    "objectID": "index.html#what-is-it",
    "href": "index.html#what-is-it",
    "title": "Geodata-Harvester",
    "section": "What is it?",
    "text": "What is it?\nThe Geodata-Harvester project enables researchers with reusable workflows and provides open-source software for automatic data extraction from a wide range of data sources including spatial-temporal processing. User provided data is auto-completed with a suitable set of spatial- and temporal-aligned covariates as a ready-made dataset for machine learning models. All data layer maps are automatically extracted and aligned for a specific region and time period."
  },
  {
    "objectID": "index.html#data-sources",
    "href": "index.html#data-sources",
    "title": "Geodata-Harvester",
    "section": "Data Sources",
    "text": "Data Sources\nThe following data sources are currently integrated:\n\nSoil and Landscape Grid of Australia (SLGA)\nSILO Climate Database (Australia)\nNational Digital Elevation Model (DEM)\nDigital Earth Australia (DEA) Geoscience Earth Observations\nRadiometric Data (Australia)\nGoogle Earth Engine Data (account needed)"
  },
  {
    "objectID": "index.html#functionality",
    "href": "index.html#functionality",
    "title": "Geodata-Harvester",
    "section": "Functionality",
    "text": "Functionality\nThe main goal of the Data Harvester is to enable researchers with reusable workflows for automatic data extraction and processing:\n\nRetrieve: automatically access geospatial and soil data sources, minimal handling of individual APIs\nProcess: Spatial and temporal processing, filter, mask, reduce and convert data\nOutput: download data as GeoTIFF and ready-made data frames for use in additional modelling and machine learning workflows\n\nData-Harvester is designed as a modular and maintainable project in the form of a multi-stage pipeline by providing explicit boundaries among tasks. To encourage interaction and experimentation with the pipeline, we provide multiple frontend notebooks and use case scenarios as Jupyter and R notebooks, as well as standalone Python and R packages. The core features are:\n\nautomatic data retrieval from geospatial APIs for given locations and dates\ndata experimentation frontends via Jupyter and R notebooks\nenables reusable workflows via interactive widgets and YAML files to save/load settings.\nautomatic geospatial-temporal processing\nsupport for multiple temporal aggregation options\nautomatic extraction of retrieved data into ready-made dataframes for ML training\nautomatic generation of ready-made aligned maps and dataframes for ML prediction models\npreview of data map layers\n\nIf you would like to learn more about the Geodata-Harvester, please visit our Workshop webpage."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "There is an enormous amount of national/global space-time data that is free and accessible. Examples are the numerous satellite platforms, weather, soil landscape grid of Australia. Many have a temporal dimension so for any point in Australia you can extract a time series of remote sensing and weather data and soil and terrain site variables. In the case of time series covariates there are a number of post-processing steps that a user can undertake to extract meaning, e.g. temporal means, aggregating in time. All of the above is a non-trivial task and a workflow where a user could enter a point (s) and get a tidy data frame of data cube variables would be a step towards people understanding its value and being able to jumpstart their analysis. This project will contribute processing tools for finding, extracting and converting these key data layers.\nDeveloped as part of the Agricultural Research Federation (AgReFed), Data-Harvester is an open-source software that allows users to jumpstart their analysis with a suitable set of spatial-temporal aligned raster maps and dataframes.\nFor more information about AgReFed and our shared mission, please see agrefed.org.au/"
  },
  {
    "objectID": "about.html#attribution-and-acknowledgments",
    "href": "about.html#attribution-and-acknowledgments",
    "title": "About",
    "section": "Attribution and Acknowledgments",
    "text": "Attribution and Acknowledgments\nThis software was developed by the Sydney Informatics Hub, a core research facility of the University of Sydney, as part of the Data Harvesting project for the Agricultural Research Federation (AgReFed).\nAcknowledgments are an important way for us to demonstrate the value we bring to your research. Your research outcomes are vital for ongoing funding of the Sydney Informatics Hub.\nIf you make use of this software for your research project, please include the following acknowledgment:\n“This research was supported by the Sydney Informatics Hub, a Core Research Facility of the University of Sydney, and the Agricultural Research Federation (AgReFed).”\nAgReFed is supported by the Australian Research Data Commons (ARDC) and the Australian Government through the National Collaborative Research Infrastructure Strategy (NCRIS)."
  },
  {
    "objectID": "API_md/geodata_harvester/harvest.html",
    "href": "API_md/geodata_harvester/harvest.html",
    "title": "Module geodata_harvester.harvest",
    "section": "",
    "text": "This script is running the headless version of the geodata-harvester.\nThe following main steps are automatically executed within the run() function: - loading settings from config file - creating bounding box from input file points if not provided - downloading data layers as specified in config file - processing data layers as specified in config file - save downloaded image files to disk as GeoTiffs - save summary table of downloaded files as CSV - extract data for point locations provided in input file (name specified in settings) - save extracted point results to disk as CSV and as geopackage\nExample call within Python: from geodata_harvester import harvest harvest.run(path_to_config))\n\n\n\nrun(path_to_config, log_name='download_summary', preview=False, return_df=False)\n\nA headless version of the Data-Harvester (with some limitations). Results are saved to disk.\n\npath_to_config : str Path to YAML config file log_name: name of log file (default: “download_log”) preview : bool, optional Plots a matrix of downloaded images if set to True, by default False return_df : bool, optional (Default: False) if True, returns dataframe with results\n\nNone (if return_df is False) dataframe (if return_df is True)"
  },
  {
    "objectID": "API_md/geodata_harvester/harvest.html#functions",
    "href": "API_md/geodata_harvester/harvest.html#functions",
    "title": "Module geodata_harvester.harvest",
    "section": "",
    "text": "run(path_to_config, log_name='download_summary', preview=False, return_df=False)\n\nA headless version of the Data-Harvester (with some limitations). Results are saved to disk.\n\npath_to_config : str Path to YAML config file log_name: name of log file (default: “download_log”) preview : bool, optional Plots a matrix of downloaded images if set to True, by default False return_df : bool, optional (Default: False) if True, returns dataframe with results\n\nNone (if return_df is False) dataframe (if return_df is True)"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_silo.html",
    "href": "API_md/geodata_harvester/getdata_silo.html",
    "title": "Module geodata_harvester.getdata_silo",
    "section": "",
    "text": "Python script to automatically download and crop climate data layers from SILO.\nFunctionalities: - download SILO data for custom time period and layer(s) as defined in dictionary - clip data to custom bounding box - save data as multi-band geotiff or netCDF\nThe SILO climate layers are described as dictionary in the module function get_silodict() and the SILO licensing and attribution are availabe with the module function getdict_license()\nMore details on the SILO climate variables can be found here: https://www.longpaddock.qld.gov.au/silo/about/climate-variables/ and more details about the gridded data structure here: https://www.longpaddock.qld.gov.au/silo/gridded-data/ and a data index: https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/index.html\nThis package is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2022 Sydney Informatics Hub (SIH), The University of Sydney\nThis open-source software is released under the LGPL-3.0 License.\nAuthor: Sebastian Haan\n\n\n\ndownload_file(url, layername, year, outpath='.')\n\ndownload file from url\nINPUT: url : str outpath : str\nOUTPUT: file : str\n\nget_SILO_layers(layernames, date_start, date_end, outpath, bbox=None, format_out='tif', delete_tempfiles=False, verbose=False)\n\nGet raster data from SILO for certain climate variable and save data as geotif. If multiple times are requested, then each time will be saved in on band of multi-band geotif. All layers are available with daily resolution (except ‘monthly_rain’)\nThis function includes validation of years and automatically download of data from SILO in temporary folder.\nInput: layernames : list climate variable names (see below) date_start : str, start date of time series in format ‘YYYY-MM-DD’ date_end : str, end date of time series in format ‘YYYY-MM-DD’ outpath : str, path to save output data bbox : list of bounding box coordinates (optional) format_out : str, format of output data: either ‘NetCDF’ (nc) or ‘GeoTIFF’ (tif) delete_tempfiles : bool, delete temporary files after processing\nReturns: fnames_out : list of output filenames\nlayer names: - ‘daily_rain’ (Daily rainfall, mm) - ‘monthly_rain’ (Monthly rainfall, mm) - ‘max_temp’ (Maximum temperature, deg C) - ‘min_temp’ (Minimum temperature. deg C) - ‘vp’ (Vapour pressure, hPa) - ‘vp_deficit’ (Vapour pressure deficit, hPa) - ‘evap_pan’ (Class A pan evaporation, mm) - ‘evap_syn’ (Synthetic estimate, mm) - ‘evap_comb’ (Combination: synthetic estimate pre-1970, class A pan 1970 onwards, mm) - ‘evap_morton_lake’ (Morton’s shallow lake evaporation, mm) - ‘radiation’ (Solar radiation: Solar exposure, consisting of both direct and diffuse components, MJ/m2) - ‘rh_tmax’ (Relative humidity: Relative humidity at the time of maximum temperature, %) - ‘rh_tmin’ (Relative humidity at the time of minimum temperature, %) - ‘et_short_crop’ (Evapotranspiration FAO564 short crop, mm) - ‘et_tall_crop’ (ASCE5 tall crop6, mm) - ‘et_morton_actual’ (Morton’s areal actual evapotranspiration, mm) - ‘et_morton_potential’ (Morton’s point potential evapotranspiration, mm) - ‘et_morton_wet’ (Morton’s wet-environment areal potential evapotranspiration over land, mm) - ‘mslp’ (Mean sea level pressure Mean sea level pressure, hPa)\nFor more details see: SILO data structure doc for gridded data: https://www.longpaddock.qld.gov.au/silo/gridded-data/\nNotes: Here we use the SILO annual raster API to download the data and then trim to date range. For data ranges much smaller than a year, one could also use the SILO daily raster API and combine dates.\n\nget_SILO_raster(layername, years, outpath, bbox=None, format_out='nc', delete_temp=False, verbose=False)\n\nGet raster data from SILO for certain climate variable and save data as geotif. If multiple times are requested, then each time will be saved in on band of multi-band geotif. All layers are available with daily resolution (except ‘monthly_rain’)\nThis function includes validation of years and automatically download of data from SILO in temporary folder.\nInput: layername : str, climate variable name (see below) years : list of years outpath : str, path to save output data bbox : list of bounding box coordinates (optional) format_out : str, format of output data: either ‘nc’ (netCDF) or ‘tif’ (geotiff) delete_temp : bool, delete temporary folder after download\nReturns: fnames_out : list of output filenames\nlayer names: - ‘daily_rain’ (Daily rainfall, mm) - ‘monthly_rain’ (Monthly rainfall, mm) - ‘max_temp’ (Maximum temperature, deg C) - ‘min_temp’ (Minimum temperature. deg C) - ‘vp’ (Vapour pressure, hPa) - ‘vp_deficit’ (Vapour pressure deficit, hPa) - ‘evap_pan’ (Class A pan evaporation, mm) - ‘evap_syn’ (Synthetic estimate, mm) - ‘evap_comb’ (Combination: synthetic estimate pre-1970, class A pan 1970 onwards, mm) - ‘evap_morton_lake’ (Morton’s shallow lake evaporation, mm) - ‘radiation’ (Solar radiation: Solar exposure, consisting of both direct and diffuse components, MJ/m2) - ‘rh_tmax’ (Relative humidity: Relative humidity at the time of maximum temperature, %) - ‘rh_tmin’ (Relative humidity at the time of minimum temperature, %) - ‘et_short_crop’ (Evapotranspiration FAO564 short crop, mm) - ‘et_tall_crop’ (ASCE5 tall crop6, mm) - ‘et_morton_actual’ (Morton’s areal actual evapotranspiration, mm) - ‘et_morton_potential’ (Morton’s point potential evapotranspiration, mm) - ‘et_morton_wet’ (Morton’s wet-environment areal potential evapotranspiration over land, mm) - ‘mslp’ (Mean sea level pressure Mean sea level pressure, hPa)\nFor more details see: SILO data structure doc for gridded data: https://www.longpaddock.qld.gov.au/silo/gridded-data/\nSILO url structure: url = “https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual//..nc e.g. url =”https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/monthly_rain/2005.monthly_rain.nc”\n\nget_silodict()\n\nGet dictionary of available layers and meta data\nOUTPUT: layerdict : dict dictionary of meta data and available layer names\n\ngetdict_license()\n\nRetrieves the SILO license and attribution information as dict\n\nprocess_raster_daterange(infnames, date_start, date_end, outfname, layername)\n\nCombines all the raster data into one xarray dataset, trimming to the date range, and saves it as a multiband tif file.\nInput: infnames : list of input filenames date_start : str, start date of time series in format ‘YYYY-MM-DD’ date_end : str, end date of time series in format ‘YYYY-MM-DD’ outfname : str, path+name of output file\n\ntest_get_SILO_layers()\n\ntest script\n\ntest_get_SILO_raster()\n\ntest script\n\nxarray2tif(ds, outfname, layername)\n\nConvert rio xarray dataset to multi-band geotiff with each time as separate band.\nTBD: optional: save separate tif each time slice\nINPUT: ds : xarray dataset outfname : str path+name of output file (“.tif”)\nOUTPUT: tif : str, name of multi-band geotiff"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_silo.html#functions",
    "href": "API_md/geodata_harvester/getdata_silo.html#functions",
    "title": "Module geodata_harvester.getdata_silo",
    "section": "",
    "text": "download_file(url, layername, year, outpath='.')\n\ndownload file from url\nINPUT: url : str outpath : str\nOUTPUT: file : str\n\nget_SILO_layers(layernames, date_start, date_end, outpath, bbox=None, format_out='tif', delete_tempfiles=False, verbose=False)\n\nGet raster data from SILO for certain climate variable and save data as geotif. If multiple times are requested, then each time will be saved in on band of multi-band geotif. All layers are available with daily resolution (except ‘monthly_rain’)\nThis function includes validation of years and automatically download of data from SILO in temporary folder.\nInput: layernames : list climate variable names (see below) date_start : str, start date of time series in format ‘YYYY-MM-DD’ date_end : str, end date of time series in format ‘YYYY-MM-DD’ outpath : str, path to save output data bbox : list of bounding box coordinates (optional) format_out : str, format of output data: either ‘NetCDF’ (nc) or ‘GeoTIFF’ (tif) delete_tempfiles : bool, delete temporary files after processing\nReturns: fnames_out : list of output filenames\nlayer names: - ‘daily_rain’ (Daily rainfall, mm) - ‘monthly_rain’ (Monthly rainfall, mm) - ‘max_temp’ (Maximum temperature, deg C) - ‘min_temp’ (Minimum temperature. deg C) - ‘vp’ (Vapour pressure, hPa) - ‘vp_deficit’ (Vapour pressure deficit, hPa) - ‘evap_pan’ (Class A pan evaporation, mm) - ‘evap_syn’ (Synthetic estimate, mm) - ‘evap_comb’ (Combination: synthetic estimate pre-1970, class A pan 1970 onwards, mm) - ‘evap_morton_lake’ (Morton’s shallow lake evaporation, mm) - ‘radiation’ (Solar radiation: Solar exposure, consisting of both direct and diffuse components, MJ/m2) - ‘rh_tmax’ (Relative humidity: Relative humidity at the time of maximum temperature, %) - ‘rh_tmin’ (Relative humidity at the time of minimum temperature, %) - ‘et_short_crop’ (Evapotranspiration FAO564 short crop, mm) - ‘et_tall_crop’ (ASCE5 tall crop6, mm) - ‘et_morton_actual’ (Morton’s areal actual evapotranspiration, mm) - ‘et_morton_potential’ (Morton’s point potential evapotranspiration, mm) - ‘et_morton_wet’ (Morton’s wet-environment areal potential evapotranspiration over land, mm) - ‘mslp’ (Mean sea level pressure Mean sea level pressure, hPa)\nFor more details see: SILO data structure doc for gridded data: https://www.longpaddock.qld.gov.au/silo/gridded-data/\nNotes: Here we use the SILO annual raster API to download the data and then trim to date range. For data ranges much smaller than a year, one could also use the SILO daily raster API and combine dates.\n\nget_SILO_raster(layername, years, outpath, bbox=None, format_out='nc', delete_temp=False, verbose=False)\n\nGet raster data from SILO for certain climate variable and save data as geotif. If multiple times are requested, then each time will be saved in on band of multi-band geotif. All layers are available with daily resolution (except ‘monthly_rain’)\nThis function includes validation of years and automatically download of data from SILO in temporary folder.\nInput: layername : str, climate variable name (see below) years : list of years outpath : str, path to save output data bbox : list of bounding box coordinates (optional) format_out : str, format of output data: either ‘nc’ (netCDF) or ‘tif’ (geotiff) delete_temp : bool, delete temporary folder after download\nReturns: fnames_out : list of output filenames\nlayer names: - ‘daily_rain’ (Daily rainfall, mm) - ‘monthly_rain’ (Monthly rainfall, mm) - ‘max_temp’ (Maximum temperature, deg C) - ‘min_temp’ (Minimum temperature. deg C) - ‘vp’ (Vapour pressure, hPa) - ‘vp_deficit’ (Vapour pressure deficit, hPa) - ‘evap_pan’ (Class A pan evaporation, mm) - ‘evap_syn’ (Synthetic estimate, mm) - ‘evap_comb’ (Combination: synthetic estimate pre-1970, class A pan 1970 onwards, mm) - ‘evap_morton_lake’ (Morton’s shallow lake evaporation, mm) - ‘radiation’ (Solar radiation: Solar exposure, consisting of both direct and diffuse components, MJ/m2) - ‘rh_tmax’ (Relative humidity: Relative humidity at the time of maximum temperature, %) - ‘rh_tmin’ (Relative humidity at the time of minimum temperature, %) - ‘et_short_crop’ (Evapotranspiration FAO564 short crop, mm) - ‘et_tall_crop’ (ASCE5 tall crop6, mm) - ‘et_morton_actual’ (Morton’s areal actual evapotranspiration, mm) - ‘et_morton_potential’ (Morton’s point potential evapotranspiration, mm) - ‘et_morton_wet’ (Morton’s wet-environment areal potential evapotranspiration over land, mm) - ‘mslp’ (Mean sea level pressure Mean sea level pressure, hPa)\nFor more details see: SILO data structure doc for gridded data: https://www.longpaddock.qld.gov.au/silo/gridded-data/\nSILO url structure: url = “https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual//..nc e.g. url =”https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/monthly_rain/2005.monthly_rain.nc”\n\nget_silodict()\n\nGet dictionary of available layers and meta data\nOUTPUT: layerdict : dict dictionary of meta data and available layer names\n\ngetdict_license()\n\nRetrieves the SILO license and attribution information as dict\n\nprocess_raster_daterange(infnames, date_start, date_end, outfname, layername)\n\nCombines all the raster data into one xarray dataset, trimming to the date range, and saves it as a multiband tif file.\nInput: infnames : list of input filenames date_start : str, start date of time series in format ‘YYYY-MM-DD’ date_end : str, end date of time series in format ‘YYYY-MM-DD’ outfname : str, path+name of output file\n\ntest_get_SILO_layers()\n\ntest script\n\ntest_get_SILO_raster()\n\ntest script\n\nxarray2tif(ds, outfname, layername)\n\nConvert rio xarray dataset to multi-band geotiff with each time as separate band.\nTBD: optional: save separate tif each time slice\nINPUT: ds : xarray dataset outfname : str path+name of output file (“.tif”)\nOUTPUT: tif : str, name of multi-band geotiff"
  },
  {
    "objectID": "API_md/geodata_harvester/index.html",
    "href": "API_md/geodata_harvester/index.html",
    "title": "Module geodata_harvester",
    "section": "",
    "text": "This Python package provides automation tools for harvesting and processing geodata from the web. https://github.com/Sydney-Informatics-Hub/geodata-harvester\n\n\n\ngeodata_harvester.arc2meter\ngeodata_harvester.getdata_dea\ngeodata_harvester.getdata_dem\ngeodata_harvester.getdata_landscape\ngeodata_harvester.getdata_radiometric\ngeodata_harvester.getdata_silo\ngeodata_harvester.getdata_slga\ngeodata_harvester.harvest\ngeodata_harvester.settingshandler\ngeodata_harvester.spatial\ngeodata_harvester.temporal\ngeodata_harvester.utils\ngeodata_harvester.validate_settings\ngeodata_harvester.widgets\ngeodata_harvester.write_logs"
  },
  {
    "objectID": "API_md/geodata_harvester/index.html#sub-modules",
    "href": "API_md/geodata_harvester/index.html#sub-modules",
    "title": "Module geodata_harvester",
    "section": "",
    "text": "geodata_harvester.arc2meter\ngeodata_harvester.getdata_dea\ngeodata_harvester.getdata_dem\ngeodata_harvester.getdata_landscape\ngeodata_harvester.getdata_radiometric\ngeodata_harvester.getdata_silo\ngeodata_harvester.getdata_slga\ngeodata_harvester.harvest\ngeodata_harvester.settingshandler\ngeodata_harvester.spatial\ngeodata_harvester.temporal\ngeodata_harvester.utils\ngeodata_harvester.validate_settings\ngeodata_harvester.widgets\ngeodata_harvester.write_logs"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_slga.html",
    "href": "API_md/geodata_harvester/getdata_slga.html",
    "title": "Module geodata_harvester.getdata_slga",
    "section": "",
    "text": "Python script to download data from Soil and Landscape Grid of Australia (SLGA).\nCore functionality: - Retrieval of WCS capability with function get_capabilities() - automatic download SLGA data for given depth range and layer(s) via Web Coverage Service (WCS) - clip data to custom bounding box - save data as multi-band geotiff - plot data as map\nThe SLGA layers and metadata are described as dictionary in the module function get_slgadict() and the respective licensing and attribution are availabe with the module function getdict_license()\nMore details about the SLGA data and attributions can be found here: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails-SoilAttributes.html\nThis package is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2022 Sydney Informatics Hub (SIH), The University of Sydney\nThis open-source software is released under the LGPL-3.0 License.\nAuthor: Sebastian Haan\n\n\n\ndepth2identifier(depth_min, depth_max)\n\nGet identifiers that correspond to depths and their corresponding confidence interval identifiers that lie within the depth range depth_min to depth_max.\n\ndepth_min : minimum depth [cm] depth_max : maximum depth [cm]\n\nidentifiers : layer identifiers identifiers_ci_5pc : identifiers for confidence interval 5% identifiers_ci_95pc : identifiers for confidence interval 95% depth_lower : lower depth of interval depth_upper : upper depth of interval\n\nget_capabilities(url)\n\nGet capabilities from WCS layer\n\nurl : str layer url\n\nkeys : list layer identifiers titles : list of str layer titles descriptions : list of str layer descriptions bboxs : list of floats layer bounding boxes\n\nget_slga_layers(layernames, bbox, outpath, resolution=3, depth_min=0, depth_max=200, get_ci=True, verbose=False)\n\nDownload layers from SLGA data server and saves as geotif.\n\nlayernames : list of layer names bbox : bounding box [min, miny, maxx, maxy] in resolution : resolution in arcsec (Default: 3 arcsec ~ 90m, which is native resolution of SLGA data) depth_min : minimum depth (Default: 0 cm). If depth_min and depth_max are lists, then must have same length as layernames depth_max : maximum depth (Default: 200 cm, maximum depth of SLGA data) outpath : output path\n\nfnames_out : list of output file names\nTBD: check that Request image size does not exceeds allowed limit. Set Timeout?\n\nget_slgadict()\n\nGet dictionary of SLGA data.\nThe Soil Facility produced a range of digital soil attribute products. Each product contains six digital soil attribute maps, and their upper and lower confidence limits, representing the soil attribute at six depths: 0-5cm, 5-15cm, 15-30cm, 30-60cm, 60-100cm and 100-200cm. These depths are consistent with the specifications of the GlobalSoilMap.net project (http://www.globalsoilmap.net/). The digital soil attribute maps are in raster format at a resolution of 3 arc sec (~90 x 90 m pixels).\nPeriod (temporal coverage; approximately): 1950-2013; Spatial resolution: 3 arc seconds (approx 90m); Data license : Creative Commons Attribution 3.0 (CC By); Target data standard: GlobalSoilMap specifications; Format: GeoTIFF.\nRun function get_capabilities(url) to update dictionary\n\nslgadict : dictionary of National Soil Map data\n\nget_wcsmap(url, identifier, crs, bbox, resolution, outfname)\n\nDownload and save geotiff from WCS layer\n\nurl : str identifier : str layer identifier crs : str layer crs bbox : list layer bounding box resolution : int layer resolution outfname : str output file name\n\ngetdict_license()\n\nRetrieves the SLGA license and attribution information as dict\n\nidentifier2depthbounds(depths)\n\nGet min and max depth of list of depth strings\n\ndepth_list: list of depth\n\nmin depth max depth\n\nplot_raster(infname)\n\nRead in raster tif with rasterio and visualise as map\n\ninfname : str\n\n\ntest_wcs() :"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_slga.html#functions",
    "href": "API_md/geodata_harvester/getdata_slga.html#functions",
    "title": "Module geodata_harvester.getdata_slga",
    "section": "",
    "text": "depth2identifier(depth_min, depth_max)\n\nGet identifiers that correspond to depths and their corresponding confidence interval identifiers that lie within the depth range depth_min to depth_max.\n\ndepth_min : minimum depth [cm] depth_max : maximum depth [cm]\n\nidentifiers : layer identifiers identifiers_ci_5pc : identifiers for confidence interval 5% identifiers_ci_95pc : identifiers for confidence interval 95% depth_lower : lower depth of interval depth_upper : upper depth of interval\n\nget_capabilities(url)\n\nGet capabilities from WCS layer\n\nurl : str layer url\n\nkeys : list layer identifiers titles : list of str layer titles descriptions : list of str layer descriptions bboxs : list of floats layer bounding boxes\n\nget_slga_layers(layernames, bbox, outpath, resolution=3, depth_min=0, depth_max=200, get_ci=True, verbose=False)\n\nDownload layers from SLGA data server and saves as geotif.\n\nlayernames : list of layer names bbox : bounding box [min, miny, maxx, maxy] in resolution : resolution in arcsec (Default: 3 arcsec ~ 90m, which is native resolution of SLGA data) depth_min : minimum depth (Default: 0 cm). If depth_min and depth_max are lists, then must have same length as layernames depth_max : maximum depth (Default: 200 cm, maximum depth of SLGA data) outpath : output path\n\nfnames_out : list of output file names\nTBD: check that Request image size does not exceeds allowed limit. Set Timeout?\n\nget_slgadict()\n\nGet dictionary of SLGA data.\nThe Soil Facility produced a range of digital soil attribute products. Each product contains six digital soil attribute maps, and their upper and lower confidence limits, representing the soil attribute at six depths: 0-5cm, 5-15cm, 15-30cm, 30-60cm, 60-100cm and 100-200cm. These depths are consistent with the specifications of the GlobalSoilMap.net project (http://www.globalsoilmap.net/). The digital soil attribute maps are in raster format at a resolution of 3 arc sec (~90 x 90 m pixels).\nPeriod (temporal coverage; approximately): 1950-2013; Spatial resolution: 3 arc seconds (approx 90m); Data license : Creative Commons Attribution 3.0 (CC By); Target data standard: GlobalSoilMap specifications; Format: GeoTIFF.\nRun function get_capabilities(url) to update dictionary\n\nslgadict : dictionary of National Soil Map data\n\nget_wcsmap(url, identifier, crs, bbox, resolution, outfname)\n\nDownload and save geotiff from WCS layer\n\nurl : str identifier : str layer identifier crs : str layer crs bbox : list layer bounding box resolution : int layer resolution outfname : str output file name\n\ngetdict_license()\n\nRetrieves the SLGA license and attribution information as dict\n\nidentifier2depthbounds(depths)\n\nGet min and max depth of list of depth strings\n\ndepth_list: list of depth\n\nmin depth max depth\n\nplot_raster(infname)\n\nRead in raster tif with rasterio and visualise as map\n\ninfname : str\n\n\ntest_wcs() :"
  },
  {
    "objectID": "API_md/geodata_harvester/spatial.html",
    "href": "API_md/geodata_harvester/spatial.html",
    "title": "Module geodata_harvester.spatial",
    "section": "",
    "text": "Utility functions for for spatial processing.\n–Function List, in order of appearence–\n_points_in_circle(internal): Return all points whose indices are within a given circle. _coreg_buffer(internal): Queries values of a raster around a point buffer region. raster_buffer: Given a longitude,latitude point, a raster file, and a buffer region, find the values of all points in circular buffer. _get_features(internal): Parse features from GeoDataFrame format to Rasterio format _coreg_polygon(internal): Crops a raster to a polygon shape. raster_polygon_buffer: Given list of longitudes and latitudes defining a polygon, crop raster file, return the values of all points in the polygon.\n\n\n\nraster_buffer(long, lat, raster, buffer)\n\ngiven a longitude,latitude point, a raster file, and a buffer region, return the value values of all points in circular buffer.\nINPUTS: long: longitude point of interest lat: latitude point of interest raster: file path/name (as string) buffer: integer, raster array pixel units to return values for\nRETURNS values: list of raster array values around point of interest.\n\nraster_polygon_buffer(lngs, lats, raster)\n\nGiven a list of longitudes and latitudes that define a polygone, crop a raster file, and return the values of all points in the polygon.\nINPUTS: lngs: list of longitudes lats: list of latitudes raster: file path/name (as string) of raster\nRETURNS values: list of raster array values inside polygon."
  },
  {
    "objectID": "API_md/geodata_harvester/spatial.html#functions",
    "href": "API_md/geodata_harvester/spatial.html#functions",
    "title": "Module geodata_harvester.spatial",
    "section": "",
    "text": "raster_buffer(long, lat, raster, buffer)\n\ngiven a longitude,latitude point, a raster file, and a buffer region, return the value values of all points in circular buffer.\nINPUTS: long: longitude point of interest lat: latitude point of interest raster: file path/name (as string) buffer: integer, raster array pixel units to return values for\nRETURNS values: list of raster array values around point of interest.\n\nraster_polygon_buffer(lngs, lats, raster)\n\nGiven a list of longitudes and latitudes that define a polygone, crop a raster file, and return the values of all points in the polygon.\nINPUTS: lngs: list of longitudes lats: list of latitudes raster: file path/name (as string) of raster\nRETURNS values: list of raster array values inside polygon."
  },
  {
    "objectID": "API_md/geodata_harvester/validate_settings.html#functions",
    "href": "API_md/geodata_harvester/validate_settings.html#functions",
    "title": "Module geodata_harvester.validate_settings",
    "section": "Functions",
    "text": "Functions\n\ncheck_schema(settings)\n\nValidate Schema\n\ncheck_schema2(settings)\n\nValidate Schema with package schema\nRequirements: schema\n\ncheck_target_dates(dates)\n\nValidate date range\n\ncheck_target_size(bbox, target_res, nmax_pixels=100000000.0)\n\nValidate bounding box and check number of raster pixels\nINPUT\nbbox: list, target bounding box target_res: float or int, target resolution nmax_pixels: maximum number of raster pixels for target image (nmax = nx * ny)\n\ncheck_target_sources(target_sources)\n\nValidate selected data layers and options\nTBD: GEE validations\n\nvalidate(fname_settings, verbose=False)\n\nValidates all settings with regard - schema - date range - data size and bounding box - data layers and options\nINPUT: fname_settings: str, path + filename of settings"
  },
  {
    "objectID": "API_md/geodata_harvester/arc2meter.html",
    "href": "API_md/geodata_harvester/arc2meter.html",
    "title": "Module geodata_harvester.arc2meter",
    "section": "",
    "text": "Converter arc seconds to meter and vice versa.\nEarth circumference around Equator is 40,075,017 meter 1 arc second at equatorial sea level = 1855.325m/60 = 30.922m\nEarth circumference around Poles is 40,007,863 meter 1 arc second latitude = 1852.216m/60 = 30.87m\nFormula for longitude: meters = arcsec * cos(degree latitude) * 30.922m (conversion for latitude stays constant: arcsec * 30.87m)\n\n\n\ncalc_arc2meter(arcsec, latitude)\n\nCalculate arc seconds to meter\n\narcsec: float, arcsec latitude: float, latitude\n\n(meters Long, meters Lat)\n\ncalc_meter2arc(meter, latitude)\n\nCalculate meter to arc seconds\n\nmeter: float, meter latitude: float, latitude\n\n(arcsec Long, arcsec Lat)"
  },
  {
    "objectID": "API_md/geodata_harvester/arc2meter.html#functions",
    "href": "API_md/geodata_harvester/arc2meter.html#functions",
    "title": "Module geodata_harvester.arc2meter",
    "section": "",
    "text": "calc_arc2meter(arcsec, latitude)\n\nCalculate arc seconds to meter\n\narcsec: float, arcsec latitude: float, latitude\n\n(meters Long, meters Lat)\n\ncalc_meter2arc(meter, latitude)\n\nCalculate meter to arc seconds\n\nmeter: float, meter latitude: float, latitude\n\n(arcsec Long, arcsec Lat)"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_dea.html",
    "href": "API_md/geodata_harvester/getdata_dea.html",
    "title": "Module geodata_harvester.getdata_dea",
    "section": "",
    "text": "Script to download satellite data from Digital Earth Australia (DEA)for a given time, resolution, and bounding box. Final data is saved as geotiff or NetCDF.\nSatellite data sources are calibrated by DEA for Australia and include datasets for Landsat and Sentinel2.\nAn overview of DEA data is available here https://docs.dea.ga.gov.au/notebooks/DEA_datasets/README.html and explanation of datasets here: https://docs.dea.ga.gov.au/notebooks/Beginners_guide/02_DEA.html\nA full ist of data layer names can be retrieved with get_deadict() or get_capabilities() for a given url The DEA WCS service capabilities are also available online at: https://docs.dea.ga.gov.au/setup/gis/web_services.html#Web-Coverage-Service-(WCS)\nFor more complex data processing use DEA’s excellent Jupyter notebooks within their Sandbox (authentication needed) that leverage the Open Data Cube software package (datacube-core) https://docs.dea.ga.gov.au/setup/Sandbox/sandbox.html\nOther resources: - NCI (authentication needed) https://docs.dea.ga.gov.au/setup/NCI/README.html\n\nSpatioTemporal Asset Catalog (STAC) endpoint (authentication needed): https://docs.dea.ga.gov.au/notebooks/Frequently_used_code/Downloading_data_with_STAC.html\n\nLIMITATIONS: for large bbox the server can exceeds limits and the data is not returned.\nThis package is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2022 Sydney Informatics Hub (SIH), The University of Sydney\nThis open-source software is released under the LGPL-3.0 License.\nAuthor: Sebastian Haan\nTBF: - apply cloud mask to downloaded images automatically (accept “valid”, “water”, “snow”) - include some DEA tools https://github.com/GeoscienceAustralia/dea-notebooks/blob/stable/Tools/dea_tools/\n\n\n\nget_capabilities(url)\n\nGet capabilities from WCS layer.\n\nurl : str layer url\n\nkeys : list layer identifiers titles : list of str layer titles descriptions : list of str layer descriptions bboxs : list of floats layer bounding boxes\n\nget_dea_images(layername, year, bbox, resolution, outpath, crs='EPSG:4326', format_out='GeoTIFF', verbose=False)\n\nGet all satellite images from DEA for a given layer and year. Downloaded images are saved either as GeoTIFF or NetCDF.\n\nlayername : str layer identifier year : str selected year for images bbox : list layer bounding box resolution : int layer resolution in arcsec outpath : str output directory crs: str crs, default ‘EPSG:4326’ format: str output format, either “GeoTIFF” or “NetCDF”\n\nExited ok: boolean\n\nget_dea_images_daterange(layername, date_min, date_max, bbox, resolution, outpath, crs='EPSG:4326', format_out='GeoTIFF', verbose=False)\n\nGet all satellite images from DEA for a given layer and year. Downloaded images are saved either as GeoTIFF or NetCDF.\n\nlayername : str layer identifier date_min : str start datetime string for images (format: YYYY-MM-DD) date_max : str end datetime string for images (format: YYYY-MM-DD) bbox : list layer bounding box resolution : int layer resolution in arcsec outpath : str output directory crs: str crs, default ‘EPSG:4326’ format: str output format, either “GeoTIFF” or “NetCDF”\n\nExited ok: boolean\n\nget_dea_layers(layernames, years, bbox, resolution, outpath, crs='EPSG:4326', format_out='GeoTIFF', verbose=False)\n\nGet all images for all layers and all years. Downloaded images are saved in outpath.\n\nlayernames : list of strings layer identifiers years : list years, e.g. [2019, 2020] bbox : list layer bounding box resolution : int layer resolution in arcsec outpath : str output directory crs: str crs, default ‘EPSG:4326’ format: str output format, either “GeoTIFF” or “NetCDF”\n\nlist of output filenames for each layer\n\nget_dea_layers_daterange(layernames, date_start, date_end, bbox, resolution, outpath, crs='EPSG:4326', format_out='GeoTIFF', verbose=False)\n\nGet all images for all layers and all dates between start_date and end_date. Downloaded images are saved in outpath.\n\nlayernames : list of strings layer identifiers date_start : str start date in dateformat YYYY-MM-DD date_end : str end date in dateformat YYYY-MM-DD bbox : list layer bounding box resolution : int layer resolution in arcsec outpath : str output directory crs: str crs, default ‘EPSG:4326’ format: str output format, either “GeoTIFF” or “NetCDF”\n\nlist of output filenames for each layer\n\nget_deadict()\n\nReturns dictionary of keys and layer titles\nTo update manually please run get_capabilities() to retrieve all current layer details\n\nget_times(url, layername, year=None)\n\nReturn available dates for layer.\n\nurl: str, layer url layername: str, name of layer id year: int or str, year of interest (if None, times for all available years are returned)\n\nlist of dates\n\nget_times_startend(url, layername, dt_start, dt_end)\n\nReturn all available images datetimes for layer in range between start and end date.\n\nurl: str, layer url layername: str, name of layer id dt_start: str, start date in dateformat YYYY-MM-DD dt_end: str, end date in dateformat YYYY-MM-DD\n\nlist of dates\n\nget_wcsmap(outfname, layername, bbox, date, resolution, url, crs='EPSG:4326', format_out='GeoTIFF')\n\nDownload and save geotiff from WCS layer.\n\noutfname : str output file name layername : str layer identifier bbox : list layer bounding box date : str datetime resolution : int layer resolution in arcsec url : str url of wcs server crs: str crsm default ‘EPSG:4326’ format: str output format, either “GeoTIFF” or “NetCDF”\n\nExited ok: boolean\n\ngetdict_cloudmask()\n\nreturn dict of cloud mask\n\ngetdict_license()\n\nRetrieves the DEA data license and NCI attribution information as dict\n\nplot_raster(infname)\n\nRead in raster tif with rasterio and visualise as map.\n\ninfname : str\n\nwrite_deadict()\n\nGenerates new DEA dictionary from crawling WCS url"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_dea.html#functions",
    "href": "API_md/geodata_harvester/getdata_dea.html#functions",
    "title": "Module geodata_harvester.getdata_dea",
    "section": "",
    "text": "get_capabilities(url)\n\nGet capabilities from WCS layer.\n\nurl : str layer url\n\nkeys : list layer identifiers titles : list of str layer titles descriptions : list of str layer descriptions bboxs : list of floats layer bounding boxes\n\nget_dea_images(layername, year, bbox, resolution, outpath, crs='EPSG:4326', format_out='GeoTIFF', verbose=False)\n\nGet all satellite images from DEA for a given layer and year. Downloaded images are saved either as GeoTIFF or NetCDF.\n\nlayername : str layer identifier year : str selected year for images bbox : list layer bounding box resolution : int layer resolution in arcsec outpath : str output directory crs: str crs, default ‘EPSG:4326’ format: str output format, either “GeoTIFF” or “NetCDF”\n\nExited ok: boolean\n\nget_dea_images_daterange(layername, date_min, date_max, bbox, resolution, outpath, crs='EPSG:4326', format_out='GeoTIFF', verbose=False)\n\nGet all satellite images from DEA for a given layer and year. Downloaded images are saved either as GeoTIFF or NetCDF.\n\nlayername : str layer identifier date_min : str start datetime string for images (format: YYYY-MM-DD) date_max : str end datetime string for images (format: YYYY-MM-DD) bbox : list layer bounding box resolution : int layer resolution in arcsec outpath : str output directory crs: str crs, default ‘EPSG:4326’ format: str output format, either “GeoTIFF” or “NetCDF”\n\nExited ok: boolean\n\nget_dea_layers(layernames, years, bbox, resolution, outpath, crs='EPSG:4326', format_out='GeoTIFF', verbose=False)\n\nGet all images for all layers and all years. Downloaded images are saved in outpath.\n\nlayernames : list of strings layer identifiers years : list years, e.g. [2019, 2020] bbox : list layer bounding box resolution : int layer resolution in arcsec outpath : str output directory crs: str crs, default ‘EPSG:4326’ format: str output format, either “GeoTIFF” or “NetCDF”\n\nlist of output filenames for each layer\n\nget_dea_layers_daterange(layernames, date_start, date_end, bbox, resolution, outpath, crs='EPSG:4326', format_out='GeoTIFF', verbose=False)\n\nGet all images for all layers and all dates between start_date and end_date. Downloaded images are saved in outpath.\n\nlayernames : list of strings layer identifiers date_start : str start date in dateformat YYYY-MM-DD date_end : str end date in dateformat YYYY-MM-DD bbox : list layer bounding box resolution : int layer resolution in arcsec outpath : str output directory crs: str crs, default ‘EPSG:4326’ format: str output format, either “GeoTIFF” or “NetCDF”\n\nlist of output filenames for each layer\n\nget_deadict()\n\nReturns dictionary of keys and layer titles\nTo update manually please run get_capabilities() to retrieve all current layer details\n\nget_times(url, layername, year=None)\n\nReturn available dates for layer.\n\nurl: str, layer url layername: str, name of layer id year: int or str, year of interest (if None, times for all available years are returned)\n\nlist of dates\n\nget_times_startend(url, layername, dt_start, dt_end)\n\nReturn all available images datetimes for layer in range between start and end date.\n\nurl: str, layer url layername: str, name of layer id dt_start: str, start date in dateformat YYYY-MM-DD dt_end: str, end date in dateformat YYYY-MM-DD\n\nlist of dates\n\nget_wcsmap(outfname, layername, bbox, date, resolution, url, crs='EPSG:4326', format_out='GeoTIFF')\n\nDownload and save geotiff from WCS layer.\n\noutfname : str output file name layername : str layer identifier bbox : list layer bounding box date : str datetime resolution : int layer resolution in arcsec url : str url of wcs server crs: str crsm default ‘EPSG:4326’ format: str output format, either “GeoTIFF” or “NetCDF”\n\nExited ok: boolean\n\ngetdict_cloudmask()\n\nreturn dict of cloud mask\n\ngetdict_license()\n\nRetrieves the DEA data license and NCI attribution information as dict\n\nplot_raster(infname)\n\nRead in raster tif with rasterio and visualise as map.\n\ninfname : str\n\nwrite_deadict()\n\nGenerates new DEA dictionary from crawling WCS url"
  },
  {
    "objectID": "API_md/geodata_harvester/utils.html",
    "href": "API_md/geodata_harvester/utils.html",
    "title": "Module geodata_harvester.utils",
    "section": "",
    "text": "Utility functions for use in the Agrefed data harvesting pipeline.\n–Function List, in order of appearence–\nplot_rasters: Plots a list of rasters. _getFeatures (internal): Extracts rasterio compatible test from geodataframe. reproj_mask: Masks a raster to the area of a shape, and reprojects. reproj_rastermatch: Reproject a file to match the shape and projection of existing raster. reproj_raster: Reproject and clip for a given output resolution, crs and bbox. _read_file (internal): Reads raster with rasterio returns numpy array aggregate_rasters: Averages (or similar) over multiple files and multiple channels. aggregate_multiband: Averages (or similar) over multiple files but keeps multi-channels independent. _get_coords_at_point (internal): Finds closest index of a point-location in an array (raster). raster_query: Given a longitude,latitude value, return the value at that point of a raster/tif. extract_values_from_rasters: Given a list of rasters, extract the values at coords. init_logtable: Stores metdata for each step of raster download and processing. update_logtable: Updates each the logtable with new information.\n\n\n\naggregate_multiband(file_list=None, data_dir=None, agg=['mean'], outfile='aggregation')\n\nAggregates over multiple files but keeps channels independently. Results are written to new tif files.\n\nfile_list : list of strings List of files to aggregate data_dir : string Path to directory containing files agg : list of strings List of aggregation methods to apply outfile : string Name of output file\n\noutfname_list : list of strings of output file names channel_list : list of strings of channel names agg_list : list of strings of aggregation methods\n\naggregate_rasters(file_list=None, data_dir=None, agg=['mean'], outfile='aggregation')\n\nAggregrates over multiple files and over all channels and writes results to new tif file(s).\n\nfile_list : list of strings List of files to aggregate data_dir : string Path to directory containing files agg : list of strings List of aggregation methods to apply (mean, median, sum, perc95, perc5) outfile : string Name of output file\n\nlist_outfnames : list of strings of output file names\n\ncoreg_raster(i0, j0, data, region)\n\nCoregisters a point with a buffer region of a raster.\nINPUTS i0: column-index of point of interest j0: row-index of point of interest data: two-dimensional numpy array (raster) region: integer, same units as data resolution\nRETURNS pts: all values from array within region\n\nextract_values_from_rasters(coords, raster_files, method='nearest')\n\nExtract values from a list of raster files at given coordinates using rioxarray. Values will be extracted for all bands in each raster file. Return geopandas DataFrame with extracted values and geometry.\nInput: coords: A list of tuples containing longitude and latitude coordinates. Format: [(lng1, lat1), (lng2, lat2), …]\nraster_files: A list of raster file paths.\n              Format: [\"path/to/raster1.tif\", \"path/to/raster2.tif\", ...]\n\nmethod: The method to select values from raster files for \n        inexact matches between input coords and raster coords:\n         {\"nearest\", \"pad\", \"ffill\", \"backfill\", \"bfill\"}, optional\n    - nearest (Default): use nearest valid index value. \n    - pad / ffill: propagate last valid index value forward\n    - backfill / bfill: propagate next valid index value backward\n    - None: only exact matches\nOutput: A geopandas DataFrame containing the extracted values and geometry, where each row represents a coordinate point and the columns represent the bands for each raster file. Output column names are the raster file name plus the band name.\n\ninit_logtable()\n\nCreate a log table to store information from the raster download or processing.\nRETURNS: df_log: dataframe to update\n\nmsg_dl(message, log=False)\n\nPrints a downloading message\n\nmsg_err(message, log=False)\n\nPrints an error message\n\nmsg_info(message, icon=True, log=False)\n\nPrints an info message\n\nmsg_success(message, log=False)\n\nPrints a success message\n\nmsg_warn(message, log=False)\n\nPrints a warning message\n\nplot_rasters(rasters, longs=None, lats=None, titles=None)\n\nPlots multiple raster files (.tif) on a grid of nicely arranged figures.\nParameters: raster: list of filenames (.tif). Will only read the first band/channel if multiband. longs: optional x values in list like object for plotting as points over raster images. lats: optional x values in list like object for plotting as points over raster images. titles: title of plot default is raster file name.\nReturns:\nNone\n\npoints_in_circle(circle, arr)\n\nA generator to return all points whose indices are within a given circle. http://stackoverflow.com/a/2774284 Warning: If a point is near the the edges of the raster it will not loop around to the other side of the raster!\nINPUTS circle: a tuple of (i0, j0, r) where i0, j0 are the indices of the center of the circle and r is the radius\narr: a two-dimensional numpy array\nRETURNS A generator that yields all points within the circle\n\nraster_query(longs, lats, rasters, titles=None)\n\nDEPRECATED: Use extract_values_from_rasters instead.\ngiven a longitude,latitude value, return the value at that point of the first channel/band in the raster/tif.\nINPUTS longs:list of longitudes lats:list of latitudes rasters:list of raster filenames (as strings) titles:list of column titles (as strings) that correspond to rasters (if none provided, rasternames will be used)\nRETURNS gdf: geopandas dataframe where each row is long/lat point, and columns are rasterfiles\n\nreproj_mask(filepath, bbox, crscode=4326, filepath_out=None)\n\nClips a raster to the area of a shape, and reprojects.\nINPUTS filepath: input filename (tif) bbox: shapely geometry(polygon) defining mask boundary crscode: optional, coordinate reference system as defined by EPSG filepath_out: optional, the optional output filename of the raster. If False, does not save a new file\nRETURNS out_img: numpy array of the clipped and reprojected raster\n\nreproj_raster(infile, outfile, bbox_out, resolution_out=None, crs_out='EPSG:4326', nodata=0)\n\nReproject and clip for a given output resolution, crs and bbox. Output file is written to disk.\n\ninfile : (string) path to input file to reproject outfile : (string) path to output file tif bbox_out : (left, bottom, right, top) resolution_out : (float) resolution of output raster crs_out : default “EPSG:4326” nodata : (float) nodata value for output raster\n\nreproj_rastermatch(infile, matchfile, outfile, nodata)\n\nReproject a file to match the shape and projection of existing raster. Output file is written to disk.\n\ninfile : (string) path to input file to reproject matchfile : (string) path to raster with desired shape and projection outfile : (string) path to output file tif nodata : (float) nodata value for output raster\n\nspin(message=None, colour='magenta', events=1, log=False)\n\nSpin animation as a progress inidicator\n\nupdate_logtable(df_log, filenames, layernames, datasource, settings, layertitles=[], agfunctions=[], loginfos=[], force=False)\n\nUpdate the dataframe table with the information from the raster download or processing. The dataframe is simultaneoulsy saved to a csv file in default output directory.\nINPUTS df_log: dataframe to update filenames: list of filenames to add to the dataframe (captured in output of getdata_* functions) layernames: list of layernames to add to the dataframe (must be same length as filenames) datasource: datasource of the rasters (e.g. ‘SLGA’, ‘SILO’, ‘DEA’, see settings) settings: settings Namespace object layertitles: list of layer titles to add to the dataframe; if empty or none provided, it will be inferred from settings agfunctions: list of aggregation functions to add to the dataframe; if empty or none provided, it will be inferred from settings loginfos: string or list of log information strings to add to the dataframe;\nRETURNS df_log: updated dataframe"
  },
  {
    "objectID": "API_md/geodata_harvester/utils.html#functions",
    "href": "API_md/geodata_harvester/utils.html#functions",
    "title": "Module geodata_harvester.utils",
    "section": "",
    "text": "aggregate_multiband(file_list=None, data_dir=None, agg=['mean'], outfile='aggregation')\n\nAggregates over multiple files but keeps channels independently. Results are written to new tif files.\n\nfile_list : list of strings List of files to aggregate data_dir : string Path to directory containing files agg : list of strings List of aggregation methods to apply outfile : string Name of output file\n\noutfname_list : list of strings of output file names channel_list : list of strings of channel names agg_list : list of strings of aggregation methods\n\naggregate_rasters(file_list=None, data_dir=None, agg=['mean'], outfile='aggregation')\n\nAggregrates over multiple files and over all channels and writes results to new tif file(s).\n\nfile_list : list of strings List of files to aggregate data_dir : string Path to directory containing files agg : list of strings List of aggregation methods to apply (mean, median, sum, perc95, perc5) outfile : string Name of output file\n\nlist_outfnames : list of strings of output file names\n\ncoreg_raster(i0, j0, data, region)\n\nCoregisters a point with a buffer region of a raster.\nINPUTS i0: column-index of point of interest j0: row-index of point of interest data: two-dimensional numpy array (raster) region: integer, same units as data resolution\nRETURNS pts: all values from array within region\n\nextract_values_from_rasters(coords, raster_files, method='nearest')\n\nExtract values from a list of raster files at given coordinates using rioxarray. Values will be extracted for all bands in each raster file. Return geopandas DataFrame with extracted values and geometry.\nInput: coords: A list of tuples containing longitude and latitude coordinates. Format: [(lng1, lat1), (lng2, lat2), …]\nraster_files: A list of raster file paths.\n              Format: [\"path/to/raster1.tif\", \"path/to/raster2.tif\", ...]\n\nmethod: The method to select values from raster files for \n        inexact matches between input coords and raster coords:\n         {\"nearest\", \"pad\", \"ffill\", \"backfill\", \"bfill\"}, optional\n    - nearest (Default): use nearest valid index value. \n    - pad / ffill: propagate last valid index value forward\n    - backfill / bfill: propagate next valid index value backward\n    - None: only exact matches\nOutput: A geopandas DataFrame containing the extracted values and geometry, where each row represents a coordinate point and the columns represent the bands for each raster file. Output column names are the raster file name plus the band name.\n\ninit_logtable()\n\nCreate a log table to store information from the raster download or processing.\nRETURNS: df_log: dataframe to update\n\nmsg_dl(message, log=False)\n\nPrints a downloading message\n\nmsg_err(message, log=False)\n\nPrints an error message\n\nmsg_info(message, icon=True, log=False)\n\nPrints an info message\n\nmsg_success(message, log=False)\n\nPrints a success message\n\nmsg_warn(message, log=False)\n\nPrints a warning message\n\nplot_rasters(rasters, longs=None, lats=None, titles=None)\n\nPlots multiple raster files (.tif) on a grid of nicely arranged figures.\nParameters: raster: list of filenames (.tif). Will only read the first band/channel if multiband. longs: optional x values in list like object for plotting as points over raster images. lats: optional x values in list like object for plotting as points over raster images. titles: title of plot default is raster file name.\nReturns:\nNone\n\npoints_in_circle(circle, arr)\n\nA generator to return all points whose indices are within a given circle. http://stackoverflow.com/a/2774284 Warning: If a point is near the the edges of the raster it will not loop around to the other side of the raster!\nINPUTS circle: a tuple of (i0, j0, r) where i0, j0 are the indices of the center of the circle and r is the radius\narr: a two-dimensional numpy array\nRETURNS A generator that yields all points within the circle\n\nraster_query(longs, lats, rasters, titles=None)\n\nDEPRECATED: Use extract_values_from_rasters instead.\ngiven a longitude,latitude value, return the value at that point of the first channel/band in the raster/tif.\nINPUTS longs:list of longitudes lats:list of latitudes rasters:list of raster filenames (as strings) titles:list of column titles (as strings) that correspond to rasters (if none provided, rasternames will be used)\nRETURNS gdf: geopandas dataframe where each row is long/lat point, and columns are rasterfiles\n\nreproj_mask(filepath, bbox, crscode=4326, filepath_out=None)\n\nClips a raster to the area of a shape, and reprojects.\nINPUTS filepath: input filename (tif) bbox: shapely geometry(polygon) defining mask boundary crscode: optional, coordinate reference system as defined by EPSG filepath_out: optional, the optional output filename of the raster. If False, does not save a new file\nRETURNS out_img: numpy array of the clipped and reprojected raster\n\nreproj_raster(infile, outfile, bbox_out, resolution_out=None, crs_out='EPSG:4326', nodata=0)\n\nReproject and clip for a given output resolution, crs and bbox. Output file is written to disk.\n\ninfile : (string) path to input file to reproject outfile : (string) path to output file tif bbox_out : (left, bottom, right, top) resolution_out : (float) resolution of output raster crs_out : default “EPSG:4326” nodata : (float) nodata value for output raster\n\nreproj_rastermatch(infile, matchfile, outfile, nodata)\n\nReproject a file to match the shape and projection of existing raster. Output file is written to disk.\n\ninfile : (string) path to input file to reproject matchfile : (string) path to raster with desired shape and projection outfile : (string) path to output file tif nodata : (float) nodata value for output raster\n\nspin(message=None, colour='magenta', events=1, log=False)\n\nSpin animation as a progress inidicator\n\nupdate_logtable(df_log, filenames, layernames, datasource, settings, layertitles=[], agfunctions=[], loginfos=[], force=False)\n\nUpdate the dataframe table with the information from the raster download or processing. The dataframe is simultaneoulsy saved to a csv file in default output directory.\nINPUTS df_log: dataframe to update filenames: list of filenames to add to the dataframe (captured in output of getdata_* functions) layernames: list of layernames to add to the dataframe (must be same length as filenames) datasource: datasource of the rasters (e.g. ‘SLGA’, ‘SILO’, ‘DEA’, see settings) settings: settings Namespace object layertitles: list of layer titles to add to the dataframe; if empty or none provided, it will be inferred from settings agfunctions: list of aggregation functions to add to the dataframe; if empty or none provided, it will be inferred from settings loginfos: string or list of log information strings to add to the dataframe;\nRETURNS df_log: updated dataframe"
  },
  {
    "objectID": "API_md/geodata_harvester/write_logs.html",
    "href": "API_md/geodata_harvester/write_logs.html",
    "title": "Module geodata_harvester.write_logs",
    "section": "",
    "text": "logging_addLevel(levelName, levelNum, methodName=None)\n\nAdd new logging level to logger\nCredit to https://stackoverflow.com/a/35804945\nArgs: levelName (type): Name of the logging level. levelNum (type): Numeric value of the logging level. methodName (type, optional): Name of the method to call. Defaults to None.\nExample: &gt;&gt;&gt; addLoggingLevel(‘TRACE’, logging.DEBUG - 5) &gt;&gt;&gt; logging.getLogger(name).setLevel(“TRACE”) &gt;&gt;&gt; logging.getLogger(name).trace(‘that worked’) &gt;&gt;&gt; logging.trace(‘so did this’) &gt;&gt;&gt; logging.TRACE 5\n\nsetup(path='data/debug', level='print')\n\nSet up the logging system for the AgReFed Data Harvester.\nNote that because this function is custom, 3 levels can be selected: “info”, “print”, “warning”. Obviously, other levels are accessible, just not used (we assume that any level higher than WARNING should be in the log file, and not printed).\nArgs: path (str, optional): path to log file. Defaults to “data/log”. level (bool, optional): debug level. Defaults to “print”. Valid options are “info”, “print”, and “warning”."
  },
  {
    "objectID": "API_md/geodata_harvester/write_logs.html#functions",
    "href": "API_md/geodata_harvester/write_logs.html#functions",
    "title": "Module geodata_harvester.write_logs",
    "section": "",
    "text": "logging_addLevel(levelName, levelNum, methodName=None)\n\nAdd new logging level to logger\nCredit to https://stackoverflow.com/a/35804945\nArgs: levelName (type): Name of the logging level. levelNum (type): Numeric value of the logging level. methodName (type, optional): Name of the method to call. Defaults to None.\nExample: &gt;&gt;&gt; addLoggingLevel(‘TRACE’, logging.DEBUG - 5) &gt;&gt;&gt; logging.getLogger(name).setLevel(“TRACE”) &gt;&gt;&gt; logging.getLogger(name).trace(‘that worked’) &gt;&gt;&gt; logging.trace(‘so did this’) &gt;&gt;&gt; logging.TRACE 5\n\nsetup(path='data/debug', level='print')\n\nSet up the logging system for the AgReFed Data Harvester.\nNote that because this function is custom, 3 levels can be selected: “info”, “print”, “warning”. Obviously, other levels are accessible, just not used (we assume that any level higher than WARNING should be in the log file, and not printed).\nArgs: path (str, optional): path to log file. Defaults to “data/log”. level (bool, optional): debug level. Defaults to “print”. Valid options are “info”, “print”, and “warning”."
  },
  {
    "objectID": "API_md/geodata_harvester/temporal.html",
    "href": "API_md/geodata_harvester/temporal.html",
    "title": "Module geodata_harvester.temporal",
    "section": "",
    "text": "Utility functions for temporal processing.\n–Main function list–\ncombine_rasters_temporal: Concatenates files by time returns xarray. aggregate_temporal: Aggregates xarrays by specified function and time period. temporal_crop: Cuts an xarray object by start and end times. aggregate_temporal: Make a data aggregation (mean, median, sum, etc) through time on an xarray.\n–Helper function list–\nget_date_after_last_underscore: Extract the date from the file name after the last underscore. get_mask_array: Return mask of the data, e.g. for cloud-cover.\n\n\n\naggregate_temporal(xdr, period='yearly', agg=['mean'], outfile='temporal_agg', buffer=None, fill_nan=True)\n\nMake a data aggregation (mean, median, sum, etc) through time on an xarray. Expects xarray coordinates to be x, y, time. Saves every aggregation for every time period as its own tif file.\nExample: file_list = [‘../data/mvp_daily_rain_silo/daily_rain_2017_cropped.tif’, ‘../data/mvp_daily_rain_silo/daily_rain_2018_cropped.tif’]\nxdr = combine_rasters_temporal(file_list, channel_name=‘band’,attribute_name=‘long_name’)\noutfname_list, agg_list = aggregate_temporal( xdr,period=100,agg=[‘mean’,‘sum’],outfile=‘temporal_agg’)\n\nxdr : xarray object of x,y,time period : string or int. Time period to perform aggregation, ‘yearly’, ‘monthly’, or number of periods to aggregate over. agg: list of strings. Choice of aggregation methods to apply of [‘mean’,‘median’,‘sum’,‘perc95’,‘perc5’] outfile : string. Prefix of output file name. buffer: integer time period in same units as period to buffer into the future. fill_nan: boolean. If True (Default), will automatically try to find the value for missing data from header and fills with nan before aggregating. If False, will not fill nan.\n\noutfname_list : list of strings of output file names agg_list : list of strings of aggregation methods\n\ncombine_rasters_temporal(file_list, channel_name='band', attribute_name='long_name')\n\nCombines multiple tif files into single xarray object. Assumes additional channels contain sequential time step data. If multiple files in file_list, files must be in temporal order and same data type. Also assumes files are of the same shape (x,y,t).\nExample: file_list = [‘../data/mvp_daily_rain_silo/daily_rain_2017_cropped.tif’, ‘../data/mvp_daily_rain_silo/daily_rain_2018_cropped.tif’]\nxdr = combine_rasters_temporal(file_list, channel_name=‘band’,attribute_name=‘long_name’)\n\nfile_list : str or list of filename strings in date order to concatenate. Expected to be of the form “x,y” or “x,y,z1” channel_name : string of coordinate dimension to concatentate (band, time, etc). Check options with rioxarray.open_rasterio(‘filename’).coords attribute_name : string name of rioxarray attribute holding a time/date label. Check with rioxarray.open_rasterio(‘filename’).attrs\n\nxdr : xarray object of x,y,time, with approriate metadata.\n\nget_date_after_last_underscore(file_list)\n\nExtract the date from the file name after the last underscore.\n\nfile_list : list of filename strings in date order to concatenate.\n\nresult : list of dates in date order to concatenate.\n\nget_mask_array(xdr, mask_band=None, verbose=True)\n\nReturn mask of the data, e.g. for cloud-cover. The mask values will be set to True if the mask band is not 0, and False otherwise. If no mask band is provided, a mask band will be searched for in the xarray attribute metadata.\n\nxdr : xarray xarray dataset to mask mask_band : str or int, optional\nName or index of the band to use as a mask. If not provided, a mask abd will be searched for in the xarray attribute metadata.\n\nmask: array, bool\n\nmultiband_raster_to_xarray(file_list, date_list=None, mask_bandname=None)\n\nConverts a stack of multiband raster with different dates to an xarray object.\n\nfile_list : list of filename strings in date order to concatenate. date_list : list of dates in date order to concatenate. If None provided, the dates will be extracted from the file names. This assumes that the date is given at the end of the file name after an underscore.\n\ntemporal_crop(xdr, start_time, end_time)\n\nCuts an xarray object by start and end times.\n\nxdr : xarray object of x,y,time start_time : string time in ‘yyyy-mm-dd’ format. end_time : string time in ‘yyyy-mm-dd’ format.\n\nxdr_crop : xarray object of x,y,time, with approriate metadata."
  },
  {
    "objectID": "API_md/geodata_harvester/temporal.html#functions",
    "href": "API_md/geodata_harvester/temporal.html#functions",
    "title": "Module geodata_harvester.temporal",
    "section": "",
    "text": "aggregate_temporal(xdr, period='yearly', agg=['mean'], outfile='temporal_agg', buffer=None, fill_nan=True)\n\nMake a data aggregation (mean, median, sum, etc) through time on an xarray. Expects xarray coordinates to be x, y, time. Saves every aggregation for every time period as its own tif file.\nExample: file_list = [‘../data/mvp_daily_rain_silo/daily_rain_2017_cropped.tif’, ‘../data/mvp_daily_rain_silo/daily_rain_2018_cropped.tif’]\nxdr = combine_rasters_temporal(file_list, channel_name=‘band’,attribute_name=‘long_name’)\noutfname_list, agg_list = aggregate_temporal( xdr,period=100,agg=[‘mean’,‘sum’],outfile=‘temporal_agg’)\n\nxdr : xarray object of x,y,time period : string or int. Time period to perform aggregation, ‘yearly’, ‘monthly’, or number of periods to aggregate over. agg: list of strings. Choice of aggregation methods to apply of [‘mean’,‘median’,‘sum’,‘perc95’,‘perc5’] outfile : string. Prefix of output file name. buffer: integer time period in same units as period to buffer into the future. fill_nan: boolean. If True (Default), will automatically try to find the value for missing data from header and fills with nan before aggregating. If False, will not fill nan.\n\noutfname_list : list of strings of output file names agg_list : list of strings of aggregation methods\n\ncombine_rasters_temporal(file_list, channel_name='band', attribute_name='long_name')\n\nCombines multiple tif files into single xarray object. Assumes additional channels contain sequential time step data. If multiple files in file_list, files must be in temporal order and same data type. Also assumes files are of the same shape (x,y,t).\nExample: file_list = [‘../data/mvp_daily_rain_silo/daily_rain_2017_cropped.tif’, ‘../data/mvp_daily_rain_silo/daily_rain_2018_cropped.tif’]\nxdr = combine_rasters_temporal(file_list, channel_name=‘band’,attribute_name=‘long_name’)\n\nfile_list : str or list of filename strings in date order to concatenate. Expected to be of the form “x,y” or “x,y,z1” channel_name : string of coordinate dimension to concatentate (band, time, etc). Check options with rioxarray.open_rasterio(‘filename’).coords attribute_name : string name of rioxarray attribute holding a time/date label. Check with rioxarray.open_rasterio(‘filename’).attrs\n\nxdr : xarray object of x,y,time, with approriate metadata.\n\nget_date_after_last_underscore(file_list)\n\nExtract the date from the file name after the last underscore.\n\nfile_list : list of filename strings in date order to concatenate.\n\nresult : list of dates in date order to concatenate.\n\nget_mask_array(xdr, mask_band=None, verbose=True)\n\nReturn mask of the data, e.g. for cloud-cover. The mask values will be set to True if the mask band is not 0, and False otherwise. If no mask band is provided, a mask band will be searched for in the xarray attribute metadata.\n\nxdr : xarray xarray dataset to mask mask_band : str or int, optional\nName or index of the band to use as a mask. If not provided, a mask abd will be searched for in the xarray attribute metadata.\n\nmask: array, bool\n\nmultiband_raster_to_xarray(file_list, date_list=None, mask_bandname=None)\n\nConverts a stack of multiband raster with different dates to an xarray object.\n\nfile_list : list of filename strings in date order to concatenate. date_list : list of dates in date order to concatenate. If None provided, the dates will be extracted from the file names. This assumes that the date is given at the end of the file name after an underscore.\n\ntemporal_crop(xdr, start_time, end_time)\n\nCuts an xarray object by start and end times.\n\nxdr : xarray object of x,y,time start_time : string time in ‘yyyy-mm-dd’ format. end_time : string time in ‘yyyy-mm-dd’ format.\n\nxdr_crop : xarray object of x,y,time, with approriate metadata."
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_landscape.html",
    "href": "API_md/geodata_harvester/getdata_landscape.html",
    "title": "Module geodata_harvester.getdata_landscape",
    "section": "",
    "text": "Download landscape data from Soil and Landscape Grid of Australia (SLGA).\nCore functionality: - Retrieval of WCS capability with function get_capabilities() - automatic download landscape data via Web Coverage Service (WCS) - clip data to custom bounding box - save data as multi-band geotif - plot data as map\nThe landscape layers and metadata are described as dictionary in the module function get_landscapedict() and the respective licensing and attribution are available with the module function getdict_license()\nMore details about the data and attributions can be found here: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails-LandscapeAttributes.html\nThis package is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2022 Sydney Informatics Hub (SIH), The University of Sydney\nThis open-source software is released under the LGPL-3.0 License.\nAuthor: Sebastian Haan\n\n\n\nget_capabilities()\n\nGet capabilities from WCS layer\n\nurl : str layer url\n\nkeys : list layer identifiers titles : list of str layer titles descriptions : list of str layer descriptions bboxs : list of floats layer bounding boxes\n\nget_landscape_layers(layernames, bbox, outpath, resolution=3)\n\nDownload landscape layers from SLGA data server and saves as geotif.\n\nlayernames : list of layer names bbox : bounding box [min, miny, maxx, maxy] in resolution : resolution in arcsec (Default: 3 arcsec ~ 90m, which is native resolution of SLGA data) outpath : output path\n\nfnames_out : list of output file names\nTBD: check that Request image size does not exceeds allowed limit. Set Timeout?\n\nget_landscapedict()\n\nGet dictionary of landscape SLGA data. The landscape attribute products available from the Soil and Landscape Grid of Australia (SLGA) were derived from DEM-S, the smoothed version of the national 1 second resolution Digital Elevation Model, which was derived from the 1 second resolution Shuttle Radar Topography Mission (SRTM) data acquired by NASA in February 2000.\nSpatial resolution: 3 arc seconds (approx 90m); Data license : Creative Commons Attribution 3.0 (CC By); Format: GeoTIFF.\nRun function get_capabilities(url) to update dictionary\n\nldict : dictionary of National Soil Map data\n\nget_wcsmap(url, identifier, crs, bbox, resolution, outfname, layername)\n\nDownload and save geotiff from WCS layer\n\nurl : str identifier : str layer identifier crs : str layer crs bbox : list layer bounding box resolution : int layer resolution outfname : str output file name\n\ngetdict_license()\n\nRetrieves the SLGA license and attribution information as dict\n\nplot_raster(infname)\n\nRead in raster tif with rasterio and visualise as map\n\ninfname : str\n\n\ntest_wcs() :"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_landscape.html#functions",
    "href": "API_md/geodata_harvester/getdata_landscape.html#functions",
    "title": "Module geodata_harvester.getdata_landscape",
    "section": "",
    "text": "get_capabilities()\n\nGet capabilities from WCS layer\n\nurl : str layer url\n\nkeys : list layer identifiers titles : list of str layer titles descriptions : list of str layer descriptions bboxs : list of floats layer bounding boxes\n\nget_landscape_layers(layernames, bbox, outpath, resolution=3)\n\nDownload landscape layers from SLGA data server and saves as geotif.\n\nlayernames : list of layer names bbox : bounding box [min, miny, maxx, maxy] in resolution : resolution in arcsec (Default: 3 arcsec ~ 90m, which is native resolution of SLGA data) outpath : output path\n\nfnames_out : list of output file names\nTBD: check that Request image size does not exceeds allowed limit. Set Timeout?\n\nget_landscapedict()\n\nGet dictionary of landscape SLGA data. The landscape attribute products available from the Soil and Landscape Grid of Australia (SLGA) were derived from DEM-S, the smoothed version of the national 1 second resolution Digital Elevation Model, which was derived from the 1 second resolution Shuttle Radar Topography Mission (SRTM) data acquired by NASA in February 2000.\nSpatial resolution: 3 arc seconds (approx 90m); Data license : Creative Commons Attribution 3.0 (CC By); Format: GeoTIFF.\nRun function get_capabilities(url) to update dictionary\n\nldict : dictionary of National Soil Map data\n\nget_wcsmap(url, identifier, crs, bbox, resolution, outfname, layername)\n\nDownload and save geotiff from WCS layer\n\nurl : str identifier : str layer identifier crs : str layer crs bbox : list layer bounding box resolution : int layer resolution outfname : str output file name\n\ngetdict_license()\n\nRetrieves the SLGA license and attribution information as dict\n\nplot_raster(infname)\n\nRead in raster tif with rasterio and visualise as map\n\ninfname : str\n\n\ntest_wcs() :"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_dem copy.html",
    "href": "API_md/geodata_harvester/getdata_dem copy.html",
    "title": "Module geodata_harvester.getdata_dem copy",
    "section": "",
    "text": "This script downloads the National Digital Elevation Model (DEM) 1 Second Hydrologically Enforced product, derived from the National DEM SRTM 1 Second and National Watercourses, lakes and Reservoirs. The output image is a geotiff file with a user defined resolution and bbox. This script also includes the capabilities to generate slope and aspect from the extracted DEM.\nCore functions: get_capabilities(): get the available layers and their metadata getwcs_dem(): download the data as geotiff file for given bbox and resolution dem2slope(): convert geotiff to slope raster dem2aspect(): convert geotiff to aspect raster getdict_license(): get the license and attributes for the DEM 1 arc second grid\nThe DEM layer metadata can be retrieved with the function get_capabilities(). and the respective licensing and attribution are availabe with the module function getdict_license()\nTo download the DEM data, the function getwcs_dem() is used.\nFor more details about the data, see: https://ecat.ga.gov.au/geonetwork/srv/eng/catalog.search#/metadata/72759\nWCS url: https://services.ga.gov.au/site_9/services/DEM_SRTM_1Second_Hydro_Enforced/MapServer/WCSServer?request=GetCapabilities&service=WCS\nThis package is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2022 Sydney Informatics Hub (SIH), The University of Sydney\nThis open-source software is released under the LGPL-3.0 License.\nAuthor: Sebastian Haan\n\n\n\ncalc_gradiant(raster_dem)\n\nCalculate the gradiant from a DEM raster with rioxarray\n\ndem2aspect(fname_dem)\n\nCalculate aspect from DEM and save as geotiff\n\nfname_dem : str DEM file name\n\ndem2slope(fname_dem)\n\nCalculate slope from DEM and save as geotiff\n\nfname_dem : str DEM path + file name\n\nget_capabilities(url)\n\nGet capabilities from WCS layer.\n\nurl : str layer url\n\nkeys : list layer identifiers titles : list of str layer titles descriptions : list of str layer descriptions bboxs : list of floats layer bounding boxes\n\nget_dem_layers(layernames, outpath, bbox, resolution=1, crs='EPSG:4326')\n\nWrapper funtion to get the layers from the Geoscience Australia DEM 1 arc second grid and to calculate slope and aspect layers\n\nlayernames : list list of layer names to download [‘DEM’, ‘Slope’, ‘Aspect’] outpath : str output directory for the downloaded file bbox : list layer bounding box resolution : int layer resolution in arcsec (default 1) crs: str crs default ‘EPSG:4326’\n\nOutput outnames: lits of output filenames\n\nget_demdict()\n\nGet dictionary of meta data\nOUTPUT: layerdict : dict dictionary of meta data\n\ngetdict_license()\n\nRetrieves the Geoscience Australia data license for the DEM Web Map Service as dict\n\ngetwcs_dem(outpath, bbox, resolution=1, url='https://services.ga.gov.au/site_9/services/DEM_SRTM_1Second_Hydro_Enforced/MapServer/WCSServer?request=GetCapabilities&service=WCS', crs='EPSG:4326', verbose=False)\n\nFunction to download and save geotiff from WCS layer. Default downloads the DEM 1 arc second grid from Geoscience Australia using the folllwing WCS url: Url = https://services.ga.gov.au/site_9/services/DEM_SRTM_1Second_Hydro_Enforced/MapServer/WCSServer?request=GetCapabilities&service=WCS\n\noutpath : str output directory for the downloaded file bbox : list layer bounding box resolution : int layer resolution in arcsec (default 1) url : str url of wcs server, default is the Geoscience Australia DEM 1 arc second grid crs: str crs default ‘EPSG:4326’\n\nOutput filename\n\nplot_raster(infname)\n\nRead in raster tif with rasterio and visualise as map\n\ninfname : str\n\ntest_getwcs_dem(outpath='./test_DEM/')\n\nTest script"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_dem copy.html#functions",
    "href": "API_md/geodata_harvester/getdata_dem copy.html#functions",
    "title": "Module geodata_harvester.getdata_dem copy",
    "section": "",
    "text": "calc_gradiant(raster_dem)\n\nCalculate the gradiant from a DEM raster with rioxarray\n\ndem2aspect(fname_dem)\n\nCalculate aspect from DEM and save as geotiff\n\nfname_dem : str DEM file name\n\ndem2slope(fname_dem)\n\nCalculate slope from DEM and save as geotiff\n\nfname_dem : str DEM path + file name\n\nget_capabilities(url)\n\nGet capabilities from WCS layer.\n\nurl : str layer url\n\nkeys : list layer identifiers titles : list of str layer titles descriptions : list of str layer descriptions bboxs : list of floats layer bounding boxes\n\nget_dem_layers(layernames, outpath, bbox, resolution=1, crs='EPSG:4326')\n\nWrapper funtion to get the layers from the Geoscience Australia DEM 1 arc second grid and to calculate slope and aspect layers\n\nlayernames : list list of layer names to download [‘DEM’, ‘Slope’, ‘Aspect’] outpath : str output directory for the downloaded file bbox : list layer bounding box resolution : int layer resolution in arcsec (default 1) crs: str crs default ‘EPSG:4326’\n\nOutput outnames: lits of output filenames\n\nget_demdict()\n\nGet dictionary of meta data\nOUTPUT: layerdict : dict dictionary of meta data\n\ngetdict_license()\n\nRetrieves the Geoscience Australia data license for the DEM Web Map Service as dict\n\ngetwcs_dem(outpath, bbox, resolution=1, url='https://services.ga.gov.au/site_9/services/DEM_SRTM_1Second_Hydro_Enforced/MapServer/WCSServer?request=GetCapabilities&service=WCS', crs='EPSG:4326', verbose=False)\n\nFunction to download and save geotiff from WCS layer. Default downloads the DEM 1 arc second grid from Geoscience Australia using the folllwing WCS url: Url = https://services.ga.gov.au/site_9/services/DEM_SRTM_1Second_Hydro_Enforced/MapServer/WCSServer?request=GetCapabilities&service=WCS\n\noutpath : str output directory for the downloaded file bbox : list layer bounding box resolution : int layer resolution in arcsec (default 1) url : str url of wcs server, default is the Geoscience Australia DEM 1 arc second grid crs: str crs default ‘EPSG:4326’\n\nOutput filename\n\nplot_raster(infname)\n\nRead in raster tif with rasterio and visualise as map\n\ninfname : str\n\ntest_getwcs_dem(outpath='./test_DEM/')\n\nTest script"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_dem.html",
    "href": "API_md/geodata_harvester/getdata_dem.html",
    "title": "Module geodata_harvester.getdata_dem",
    "section": "",
    "text": "This script downloads the National Digital Elevation Model (DEM) 1 Second Hydrologically Enforced product, derived from the National DEM SRTM 1 Second and National Watercourses, lakes and Reservoirs. The output image is a geotiff file with a user defined resolution and bbox. This script also includes the capabilities to generate slope and aspect from the extracted DEM.\nCore functions: get_capabilities(): get the available layers and their metadata getwcs_dem(): download the data as geotiff file for given bbox and resolution dem2slope(): convert geotiff to slope raster dem2aspect(): convert geotiff to aspect raster getdict_license(): get the license and attributes for the DEM 1 arc second grid\nThe DEM layer metadata can be retrieved with the function get_capabilities(). and the respective licensing and attribution are availabe with the module function getdict_license()\nTo download the DEM data, the function getwcs_dem() is used.\nFor more details about the data, see: https://ecat.ga.gov.au/geonetwork/srv/eng/catalog.search#/metadata/72759\nWCS url: https://services.ga.gov.au/site_9/services/DEM_SRTM_1Second_Hydro_Enforced/MapServer/WCSServer?request=GetCapabilities&service=WCS\nThis package is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2023 Sydney Informatics Hub (SIH), The University of Sydney\nThis open-source software is released under the LGPL-3.0 License.\nAuthor: Sebastian Haan\n\n\n\ncalculate_slope_aspect(fname_dem, fname_out, type='slope')\n\nCalculate slope or aspect from DEM and save as geotiff.\n\nfname_dem : str DEM file name fname_out : str output filename type : str ‘slope’ or ‘aspect’\n\ndem2aspect(fname_dem)\n\nCalculate aspect from DEM and save as geotiff\n\nfname_dem : str DEM file name\n\ndem2slope(fname_dem)\n\nCalculate slope from DEM and save as geotiff\n\nfname_dem : str DEM path + file name\n\nget_capabilities(url)\n\nGet capabilities from WCS layer.\n\nurl : str layer url\n\nkeys : list layer identifiers titles : list of str layer titles descriptions : list of str layer descriptions bboxs : list of floats layer bounding boxes\n\nget_dem_layers(layernames, outpath, bbox, resolution=1, crs='EPSG:4326')\n\nWrapper funtion to get the layers from the Geoscience Australia DEM 1 arc second grid and to calculate slope and aspect layers\n\nlayernames : list list of layer names to download [‘DEM’, ‘Slope’, ‘Aspect’] outpath : str output directory for the downloaded file bbox : list layer bounding box resolution : int layer resolution in arcsec (default 1) crs: str crs default ‘EPSG:4326’\n\nOutput outnames: lits of output filenames\n\nget_demdict()\n\nGet dictionary of meta data\nOUTPUT: layerdict : dict dictionary of meta data\n\ngetdict_license()\n\nRetrieves the Geoscience Australia data license for the DEM Web Map Service as dict\n\ngetwcs_dem(outpath, bbox, resolution=1, url='https://services.ga.gov.au/site_9/services/DEM_SRTM_1Second_Hydro_Enforced/MapServer/WCSServer?request=GetCapabilities&service=WCS', crs='EPSG:4326', verbose=False)\n\nFunction to download and save geotiff from WCS layer. Default downloads the DEM 1 arc second grid from Geoscience Australia using the folllwing WCS url: Url = https://services.ga.gov.au/site_9/services/DEM_SRTM_1Second_Hydro_Enforced/MapServer/WCSServer?request=GetCapabilities&service=WCS\n\noutpath : str output directory for the downloaded file bbox : list layer bounding box resolution : int layer resolution in arcsec (default 1) url : str url of wcs server, default is the Geoscience Australia DEM 1 arc second grid crs: str crs default ‘EPSG:4326’\n\nOutput filename\n\nplot_raster(infname)\n\nRead in raster tif with rasterio and visualise as map\n\ninfname : str\n\ntest_getwcs_dem(outpath='./test_DEM/')\n\nTest script"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_dem.html#functions",
    "href": "API_md/geodata_harvester/getdata_dem.html#functions",
    "title": "Module geodata_harvester.getdata_dem",
    "section": "",
    "text": "calculate_slope_aspect(fname_dem, fname_out, type='slope')\n\nCalculate slope or aspect from DEM and save as geotiff.\n\nfname_dem : str DEM file name fname_out : str output filename type : str ‘slope’ or ‘aspect’\n\ndem2aspect(fname_dem)\n\nCalculate aspect from DEM and save as geotiff\n\nfname_dem : str DEM file name\n\ndem2slope(fname_dem)\n\nCalculate slope from DEM and save as geotiff\n\nfname_dem : str DEM path + file name\n\nget_capabilities(url)\n\nGet capabilities from WCS layer.\n\nurl : str layer url\n\nkeys : list layer identifiers titles : list of str layer titles descriptions : list of str layer descriptions bboxs : list of floats layer bounding boxes\n\nget_dem_layers(layernames, outpath, bbox, resolution=1, crs='EPSG:4326')\n\nWrapper funtion to get the layers from the Geoscience Australia DEM 1 arc second grid and to calculate slope and aspect layers\n\nlayernames : list list of layer names to download [‘DEM’, ‘Slope’, ‘Aspect’] outpath : str output directory for the downloaded file bbox : list layer bounding box resolution : int layer resolution in arcsec (default 1) crs: str crs default ‘EPSG:4326’\n\nOutput outnames: lits of output filenames\n\nget_demdict()\n\nGet dictionary of meta data\nOUTPUT: layerdict : dict dictionary of meta data\n\ngetdict_license()\n\nRetrieves the Geoscience Australia data license for the DEM Web Map Service as dict\n\ngetwcs_dem(outpath, bbox, resolution=1, url='https://services.ga.gov.au/site_9/services/DEM_SRTM_1Second_Hydro_Enforced/MapServer/WCSServer?request=GetCapabilities&service=WCS', crs='EPSG:4326', verbose=False)\n\nFunction to download and save geotiff from WCS layer. Default downloads the DEM 1 arc second grid from Geoscience Australia using the folllwing WCS url: Url = https://services.ga.gov.au/site_9/services/DEM_SRTM_1Second_Hydro_Enforced/MapServer/WCSServer?request=GetCapabilities&service=WCS\n\noutpath : str output directory for the downloaded file bbox : list layer bounding box resolution : int layer resolution in arcsec (default 1) url : str url of wcs server, default is the Geoscience Australia DEM 1 arc second grid crs: str crs default ‘EPSG:4326’\n\nOutput filename\n\nplot_raster(infname)\n\nRead in raster tif with rasterio and visualise as map\n\ninfname : str\n\ntest_getwcs_dem(outpath='./test_DEM/')\n\nTest script"
  },
  {
    "objectID": "API_md/geodata_harvester/settingshandler.html",
    "href": "API_md/geodata_harvester/settingshandler.html",
    "title": "Module geodata_harvester.settingshandler",
    "section": "",
    "text": "DateEncoder(obj)\n\nJSON encoder for datetime objects.\n\ncheck_bbox(settings)\n\nCheck if bbox is valid. If no bbox is given, the bbox is calculated from the input points.\nInput: settings: settings namespace\nOutput: settings: updated settings with bbox\n\ndisplay_settings(fname_settings, print_option='json')\n\nDisplay settings from yaml file.\nInput: fname_settings: path and filename to settings file print_option: “display” or “json” (default)\n\nmain(fname_settings='settings/settings_v0.1_default.yaml', to_namespace=True)\n\nMain function for running the script.\nInput: fname_settings: path and filename to settings file"
  },
  {
    "objectID": "API_md/geodata_harvester/settingshandler.html#functions",
    "href": "API_md/geodata_harvester/settingshandler.html#functions",
    "title": "Module geodata_harvester.settingshandler",
    "section": "",
    "text": "DateEncoder(obj)\n\nJSON encoder for datetime objects.\n\ncheck_bbox(settings)\n\nCheck if bbox is valid. If no bbox is given, the bbox is calculated from the input points.\nInput: settings: settings namespace\nOutput: settings: updated settings with bbox\n\ndisplay_settings(fname_settings, print_option='json')\n\nDisplay settings from yaml file.\nInput: fname_settings: path and filename to settings file print_option: “display” or “json” (default)\n\nmain(fname_settings='settings/settings_v0.1_default.yaml', to_namespace=True)\n\nMain function for running the script.\nInput: fname_settings: path and filename to settings file"
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/index.html",
    "href": "API_md/geodata_harvester/widgets/index.html",
    "title": "Module geodata_harvester.widgets",
    "section": "",
    "text": "geodata_harvester.widgets.harvesterwidgets\ngeodata_harvester.widgets.ipyfilechooser\ngeodata_harvester.widgets.ipywidgets_file_selector"
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/index.html#sub-modules",
    "href": "API_md/geodata_harvester/widgets/index.html#sub-modules",
    "title": "Module geodata_harvester.widgets",
    "section": "",
    "text": "geodata_harvester.widgets.harvesterwidgets\ngeodata_harvester.widgets.ipyfilechooser\ngeodata_harvester.widgets.ipywidgets_file_selector"
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/ipywidgets_file_selector.html",
    "href": "API_md/geodata_harvester/widgets/ipywidgets_file_selector.html",
    "title": "Module geodata_harvester.widgets.ipywidgets_file_selector",
    "section": "",
    "text": "IPFileSelector(*args, **kwargs)\n\nWidget that can be inserted into the DOM\n\ntooltip: str tooltip caption layout: InstanceDict(Layout) widget layout\nPublic constructor\n\n\nipywidgets.widgets.domwidget.DOMWidget\nipywidgets.widgets.widget.Widget\nipywidgets.widgets.widget.LoggingHasTraits\ntraitlets.traitlets.HasTraits\ntraitlets.traitlets.HasDescriptors\n\n\n\ncurrent_path\n\nA trait for unicode strings.\n\nhome_path\n\nA trait for unicode strings.\n\nselected\n\nAn instance of a Python dict.\nOne or more traits can be passed to the constructor to validate the keys and/or values of the dict. If you need more detailed validation, you may use a custom validator method.\n.. versionchanged:: 5.0 Added key_trait for validating dict keys.\n.. versionchanged:: 5.0 Deprecated ambiguous trait, traits args in favor of value_trait, per_key_traits.\n\nsubdirs\n\nAn instance of a Python list.\n\nsubfiles\n\nAn instance of a Python list."
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/ipywidgets_file_selector.html#classes",
    "href": "API_md/geodata_harvester/widgets/ipywidgets_file_selector.html#classes",
    "title": "Module geodata_harvester.widgets.ipywidgets_file_selector",
    "section": "",
    "text": "IPFileSelector(*args, **kwargs)\n\nWidget that can be inserted into the DOM\n\ntooltip: str tooltip caption layout: InstanceDict(Layout) widget layout\nPublic constructor\n\n\nipywidgets.widgets.domwidget.DOMWidget\nipywidgets.widgets.widget.Widget\nipywidgets.widgets.widget.LoggingHasTraits\ntraitlets.traitlets.HasTraits\ntraitlets.traitlets.HasDescriptors\n\n\n\ncurrent_path\n\nA trait for unicode strings.\n\nhome_path\n\nA trait for unicode strings.\n\nselected\n\nAn instance of a Python dict.\nOne or more traits can be passed to the constructor to validate the keys and/or values of the dict. If you need more detailed validation, you may use a custom validator method.\n.. versionchanged:: 5.0 Added key_trait for validating dict keys.\n.. versionchanged:: 5.0 Deprecated ambiguous trait, traits args in favor of value_trait, per_key_traits.\n\nsubdirs\n\nAn instance of a Python list.\n\nsubfiles\n\nAn instance of a Python list."
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/ipyfilechooser/filechooser.html",
    "href": "API_md/geodata_harvester/widgets/ipyfilechooser/filechooser.html",
    "title": "Module geodata_harvester.widgets.ipyfilechooser.filechooser",
    "section": "",
    "text": "FileChooser(path: str = '/Users/seb/CTDS/Projects/AgReFed/Harvester/geodata-harvester', filename: str = '', title: str = '', select_desc: str = 'Select', change_desc: str = 'Change', show_hidden: bool = False, select_default: bool = False, dir_icon: Optional[str] = '📁 ', dir_icon_append: bool = False, show_only_dirs: bool = False, filter_pattern: Optional[Sequence[str]] = None, sandbox_path: Optional[str] = None, layout: ipywidgets.widgets.widget_layout.Layout = Layout(width='500px'), **kwargs)\n\nFileChooser class.\nInitialize FileChooser object.\n\n\nipywidgets.widgets.widget_box.VBox\nipywidgets.widgets.widget_box.Box\nipywidgets.widgets.domwidget.DOMWidget\nipywidgets.widgets.widget_core.CoreWidget\nipywidgets.widgets.valuewidget.ValueWidget\nipywidgets.widgets.widget.Widget\nipywidgets.widgets.widget.LoggingHasTraits\ntraitlets.traitlets.HasTraits\ntraitlets.traitlets.HasDescriptors\n\n\n\ndefault: str\n\nGet the default value.\n\ndefault_filename: str\n\nGet the default_filename value.\n\ndefault_path: str\n\nGet the default_path value.\n\ndir_icon: Optional[str]\n\nGet dir icon value.\n\ndir_icon_append: bool\n\nGet dir icon value.\n\nfilter_pattern: Optional[Sequence[str]]\n\nGet file name filter pattern.\n\nrows: int\n\nGet current number of rows.\n\nsandbox_path: Optional[str]\n\nGet the sandbox_path.\n\nselected: Optional[str]\n\nGet selected value.\n\nselected_filename: Optional[str]\n\nGet the selected_filename.\n\nselected_path: Optional[str]\n\nGet selected_path value.\n\nshow_hidden: bool\n\nGet _show_hidden value.\n\nshow_only_dirs: bool\n\nGet show_only_dirs property value.\n\ntitle: str\n\nGet the title.\n\nvalue: Optional[str]\n\nGet selected value.\n\n\n\n\nget_interact_value(self) ‑&gt; Optional[str]\n\nReturn the value which should be passed to interactive functions.\n\nrefresh(self) ‑&gt; None\n\nRe-render the form.\n\nregister_callback(self, callback: Callable[[Optional[ForwardRef('FileChooser')]], None]) ‑&gt; None\n\nRegister a callback function.\n\nreset(self, path: Optional[str] = None, filename: Optional[str] = None) ‑&gt; None\n\nReset the form to the default path and filename."
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/ipyfilechooser/filechooser.html#classes",
    "href": "API_md/geodata_harvester/widgets/ipyfilechooser/filechooser.html#classes",
    "title": "Module geodata_harvester.widgets.ipyfilechooser.filechooser",
    "section": "",
    "text": "FileChooser(path: str = '/Users/seb/CTDS/Projects/AgReFed/Harvester/geodata-harvester', filename: str = '', title: str = '', select_desc: str = 'Select', change_desc: str = 'Change', show_hidden: bool = False, select_default: bool = False, dir_icon: Optional[str] = '📁 ', dir_icon_append: bool = False, show_only_dirs: bool = False, filter_pattern: Optional[Sequence[str]] = None, sandbox_path: Optional[str] = None, layout: ipywidgets.widgets.widget_layout.Layout = Layout(width='500px'), **kwargs)\n\nFileChooser class.\nInitialize FileChooser object.\n\n\nipywidgets.widgets.widget_box.VBox\nipywidgets.widgets.widget_box.Box\nipywidgets.widgets.domwidget.DOMWidget\nipywidgets.widgets.widget_core.CoreWidget\nipywidgets.widgets.valuewidget.ValueWidget\nipywidgets.widgets.widget.Widget\nipywidgets.widgets.widget.LoggingHasTraits\ntraitlets.traitlets.HasTraits\ntraitlets.traitlets.HasDescriptors\n\n\n\ndefault: str\n\nGet the default value.\n\ndefault_filename: str\n\nGet the default_filename value.\n\ndefault_path: str\n\nGet the default_path value.\n\ndir_icon: Optional[str]\n\nGet dir icon value.\n\ndir_icon_append: bool\n\nGet dir icon value.\n\nfilter_pattern: Optional[Sequence[str]]\n\nGet file name filter pattern.\n\nrows: int\n\nGet current number of rows.\n\nsandbox_path: Optional[str]\n\nGet the sandbox_path.\n\nselected: Optional[str]\n\nGet selected value.\n\nselected_filename: Optional[str]\n\nGet the selected_filename.\n\nselected_path: Optional[str]\n\nGet selected_path value.\n\nshow_hidden: bool\n\nGet _show_hidden value.\n\nshow_only_dirs: bool\n\nGet show_only_dirs property value.\n\ntitle: str\n\nGet the title.\n\nvalue: Optional[str]\n\nGet selected value.\n\n\n\n\nget_interact_value(self) ‑&gt; Optional[str]\n\nReturn the value which should be passed to interactive functions.\n\nrefresh(self) ‑&gt; None\n\nRe-render the form.\n\nregister_callback(self, callback: Callable[[Optional[ForwardRef('FileChooser')]], None]) ‑&gt; None\n\nRegister a callback function.\n\nreset(self, path: Optional[str] = None, filename: Optional[str] = None) ‑&gt; None\n\nReset the form to the default path and filename."
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/ipyfilechooser/index.html",
    "href": "API_md/geodata_harvester/widgets/ipyfilechooser/index.html",
    "title": "Module geodata_harvester.widgets.ipyfilechooser",
    "section": "",
    "text": "geodata_harvester.widgets.ipyfilechooser.errors\ngeodata_harvester.widgets.ipyfilechooser.filechooser\ngeodata_harvester.widgets.ipyfilechooser.utils"
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/ipyfilechooser/index.html#sub-modules",
    "href": "API_md/geodata_harvester/widgets/ipyfilechooser/index.html#sub-modules",
    "title": "Module geodata_harvester.widgets.ipyfilechooser",
    "section": "",
    "text": "geodata_harvester.widgets.ipyfilechooser.errors\ngeodata_harvester.widgets.ipyfilechooser.filechooser\ngeodata_harvester.widgets.ipyfilechooser.utils"
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/ipyfilechooser/errors.html",
    "href": "API_md/geodata_harvester/widgets/ipyfilechooser/errors.html",
    "title": "Module geodata_harvester.widgets.ipyfilechooser.errors",
    "section": "",
    "text": "Exception classes.\n\n\n\nInvalidFileNameError(filename: str, message: Optional[str] = None)\n\nInvalidFileNameError class.\n\n\nbuiltins.Exception\nbuiltins.BaseException\n\n\ninvalid_str :\n\nInvalidPathError(path: str, message: Optional[str] = None)\n\nInvalidPathError class.\n\n\nbuiltins.Exception\nbuiltins.BaseException\n\n\nParentPathError(path: str, parent_path: str, message: Optional[str] = None)\n\nParentPathError class.\n\n\nbuiltins.Exception\nbuiltins.BaseException"
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/ipyfilechooser/errors.html#classes",
    "href": "API_md/geodata_harvester/widgets/ipyfilechooser/errors.html#classes",
    "title": "Module geodata_harvester.widgets.ipyfilechooser.errors",
    "section": "",
    "text": "InvalidFileNameError(filename: str, message: Optional[str] = None)\n\nInvalidFileNameError class.\n\n\nbuiltins.Exception\nbuiltins.BaseException\n\n\ninvalid_str :\n\nInvalidPathError(path: str, message: Optional[str] = None)\n\nInvalidPathError class.\n\n\nbuiltins.Exception\nbuiltins.BaseException\n\n\nParentPathError(path: str, parent_path: str, message: Optional[str] = None)\n\nParentPathError class.\n\n\nbuiltins.Exception\nbuiltins.BaseException"
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/ipyfilechooser/utils.html",
    "href": "API_md/geodata_harvester/widgets/ipyfilechooser/utils.html",
    "title": "Module geodata_harvester.widgets.ipyfilechooser.utils",
    "section": "",
    "text": "Helper functions for ipyfilechooser.\n\n\n\nget_dir_contents(path: str, show_hidden: bool = False, show_only_dirs: bool = False, dir_icon: Optional[str] = None, dir_icon_append: bool = False, filter_pattern: Optional[Sequence[str]] = None, top_path: Optional[str] = None) ‑&gt; List[str]\n\nGet directory contents.\n\nget_drive_letters() ‑&gt; List[str]\n\nGet all drive letters minus the drive used in path.\n\nget_subpaths(path: str) ‑&gt; List[str]\n\nWalk a path and return a list of subpaths.\n\nhas_parent(path: str) ‑&gt; bool\n\nCheck if a path has a parent folder.\n\nhas_parent_path(path: str, parent_path: Optional[str]) ‑&gt; bool\n\nVerifies if path falls under parent_path.\n\nis_valid_filename(filename: str) ‑&gt; bool\n\nVerifies if a filename does not contain illegal character sequences\n\nmatch_item(item: str, filter_pattern: Sequence[str]) ‑&gt; bool\n\nCheck if a string matches one or more fnmatch patterns.\n\nnormalize_path(path: str) ‑&gt; str\n\nNormalize a path string.\n\nprepend_dir_icons(dir_list: Iterable[str], dir_icon: str, dir_icon_append: bool = False) ‑&gt; List[str]\n\nPrepend unicode folder icon to directory names.\n\nstrip_parent_path(path: str, parent_path: Optional[str]) ‑&gt; str\n\nRemove a parent path from a path."
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/ipyfilechooser/utils.html#functions",
    "href": "API_md/geodata_harvester/widgets/ipyfilechooser/utils.html#functions",
    "title": "Module geodata_harvester.widgets.ipyfilechooser.utils",
    "section": "",
    "text": "get_dir_contents(path: str, show_hidden: bool = False, show_only_dirs: bool = False, dir_icon: Optional[str] = None, dir_icon_append: bool = False, filter_pattern: Optional[Sequence[str]] = None, top_path: Optional[str] = None) ‑&gt; List[str]\n\nGet directory contents.\n\nget_drive_letters() ‑&gt; List[str]\n\nGet all drive letters minus the drive used in path.\n\nget_subpaths(path: str) ‑&gt; List[str]\n\nWalk a path and return a list of subpaths.\n\nhas_parent(path: str) ‑&gt; bool\n\nCheck if a path has a parent folder.\n\nhas_parent_path(path: str, parent_path: Optional[str]) ‑&gt; bool\n\nVerifies if path falls under parent_path.\n\nis_valid_filename(filename: str) ‑&gt; bool\n\nVerifies if a filename does not contain illegal character sequences\n\nmatch_item(item: str, filter_pattern: Sequence[str]) ‑&gt; bool\n\nCheck if a string matches one or more fnmatch patterns.\n\nnormalize_path(path: str) ‑&gt; str\n\nNormalize a path string.\n\nprepend_dir_icons(dir_list: Iterable[str], dir_icon: str, dir_icon_append: bool = False) ‑&gt; List[str]\n\nPrepend unicode folder icon to directory names.\n\nstrip_parent_path(path: str, parent_path: Optional[str]) ‑&gt; str\n\nRemove a parent path from a path."
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/harvesterwidgets.html",
    "href": "API_md/geodata_harvester/widgets/harvesterwidgets.html",
    "title": "Module geodata_harvester.widgets.harvesterwidgets",
    "section": "",
    "text": "This script generates interactive notebook widgets for selecting the settings.\nWidgets are defined using the package ipywidgets, for more details see:\nhttps://ipywidgets.readthedocs.io/en/stable/index.html\nand examples: https://coderzcolumn.com/tutorials/python/interactive-widgets-in-jupyter-notebook-using-ipywidgets\nThis package is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2023 Sydney Informatics Hub (SIH), The University of Sydney\nThis open-source software is released under the LGPL-3.0 License.\n\n\n\neval_widgets(w_settings, names)\n\nThis function is converting widget settings into dictionary.\nIf widget settings change, add settings here too.\nInput: w_settings: list of settings names: list of setting names\nOutput: dict_settings: dictionary of settings\n\ngen_accordion(panels, panel_titles)\n\nGenerate accordion of panels\nInput: panels: list of panels panel_titles: list of panel titles\nOutput: accordion_main: accordion of panels\n\ngen_loadwidget()\n\nGenerate widget for loading settings from yaml file\nInput: None\nOutput: w_load: widget for loading settings\n\ngen_maintab()\n\nGenerate New Settings Tab\nInput: None\nOutput: tab_nest: tab containing New Settings and Load Settings w_settings: widget for settings names_settings: list of names of settings w_load: widget for loading settings\n\ngen_panel_dea()\n\nGenerate panel for DEA settings\nInput: None\nOutput: panel_dea: panel for DEA settings w_dea: widget for DEA settings options_dea: list of DEA options\n\ngen_panel_dem()\n\nGenerate panel for DEM settings\nInput: None\nOutput: panel_dem: panel for DEM settings w_dem: widget for DEM settings options_dem: list of DEM options\n\ngen_panel_ee()\n\nGenerate panel for Google Earth Engine settings\nInput: None\nOutput: panel_ee: panel for Google Earth Engine settings w_ee: widget for Google Earth Engine settings names_ee: list of widget names\n\ngen_panel_io()\n\nGenerate panel for input and output settings\nInput: None\nOutput: panel_io: panel for input and output settings w_io: widget for input path w_names: list of names of widgets\n\ngen_panel_landscape()\n\nGenerate panel for landscape settings\nInput: None\nOutput: panel_ls: panel for landscape settings w_ls: widget for landscape settings options_ls: list of landscape options\n\ngen_panel_radiometric()\n\nGenerate panel for radiometric settings\nInput: None\nOutput: panel_rm: panel for radiometric settings w_rm: widget for radiometric settings options_rm: list of radiometric options\n\ngen_panel_silo()\n\nGenerate panel for SILO settings\nInput: None\nOutput: panel_silo: panel for SILO settings w_silo: widget for SILO settings options_silo: list of SILO options\n\ngen_panel_slga()\n\nGenerate panel for SLGA settings\nInput: None\nOutput: panel_slga: panel for SLGA settings w_slga: widget for SLGA settings options_slga: list of available SLGA layers\n\ngen_panel_st()\n\nGenerate panel for spatial-temporal settings\nInput: None\nOutput: panel_st: panel for spatial-temporal settings settings_st: list of settings settings_names: list of names of settings\n\ngen_panels()\n\nGenerate all settings panels\nInput: None\nOutput: panels: list of panels w_settings: list of widgets for all settings names_settings: list of widget names panel_titles: list of panel titles\n\ngen_savebutton()\n\nGenerate Save button\nInput: None\nOutput: w_savebutton: widget for saving settings\n\nload_settings(fname_settings)\n\nLoad settings from yaml file\nInput: fname_settings: path and filename to settings file\nOutput: settings: settings as namespace\n\nprint_settings(settings)\n\nprint settings\nInput: settings: settings object\nOutput: None\n\nsave_dict_settings(dict_settings, yaml_outfname)\n\nsave dictionary to yaml file\nInput: dict_settings: dictionary of settings yaml_outfname: path and filename to save settings\nOutput: None\n\nsavebutton_onclick(params)\n\nSave settings to yaml file\nInput: params: list of widgets, list of names of widgets, output filename\nOutput: None"
  },
  {
    "objectID": "API_md/geodata_harvester/widgets/harvesterwidgets.html#functions",
    "href": "API_md/geodata_harvester/widgets/harvesterwidgets.html#functions",
    "title": "Module geodata_harvester.widgets.harvesterwidgets",
    "section": "",
    "text": "eval_widgets(w_settings, names)\n\nThis function is converting widget settings into dictionary.\nIf widget settings change, add settings here too.\nInput: w_settings: list of settings names: list of setting names\nOutput: dict_settings: dictionary of settings\n\ngen_accordion(panels, panel_titles)\n\nGenerate accordion of panels\nInput: panels: list of panels panel_titles: list of panel titles\nOutput: accordion_main: accordion of panels\n\ngen_loadwidget()\n\nGenerate widget for loading settings from yaml file\nInput: None\nOutput: w_load: widget for loading settings\n\ngen_maintab()\n\nGenerate New Settings Tab\nInput: None\nOutput: tab_nest: tab containing New Settings and Load Settings w_settings: widget for settings names_settings: list of names of settings w_load: widget for loading settings\n\ngen_panel_dea()\n\nGenerate panel for DEA settings\nInput: None\nOutput: panel_dea: panel for DEA settings w_dea: widget for DEA settings options_dea: list of DEA options\n\ngen_panel_dem()\n\nGenerate panel for DEM settings\nInput: None\nOutput: panel_dem: panel for DEM settings w_dem: widget for DEM settings options_dem: list of DEM options\n\ngen_panel_ee()\n\nGenerate panel for Google Earth Engine settings\nInput: None\nOutput: panel_ee: panel for Google Earth Engine settings w_ee: widget for Google Earth Engine settings names_ee: list of widget names\n\ngen_panel_io()\n\nGenerate panel for input and output settings\nInput: None\nOutput: panel_io: panel for input and output settings w_io: widget for input path w_names: list of names of widgets\n\ngen_panel_landscape()\n\nGenerate panel for landscape settings\nInput: None\nOutput: panel_ls: panel for landscape settings w_ls: widget for landscape settings options_ls: list of landscape options\n\ngen_panel_radiometric()\n\nGenerate panel for radiometric settings\nInput: None\nOutput: panel_rm: panel for radiometric settings w_rm: widget for radiometric settings options_rm: list of radiometric options\n\ngen_panel_silo()\n\nGenerate panel for SILO settings\nInput: None\nOutput: panel_silo: panel for SILO settings w_silo: widget for SILO settings options_silo: list of SILO options\n\ngen_panel_slga()\n\nGenerate panel for SLGA settings\nInput: None\nOutput: panel_slga: panel for SLGA settings w_slga: widget for SLGA settings options_slga: list of available SLGA layers\n\ngen_panel_st()\n\nGenerate panel for spatial-temporal settings\nInput: None\nOutput: panel_st: panel for spatial-temporal settings settings_st: list of settings settings_names: list of names of settings\n\ngen_panels()\n\nGenerate all settings panels\nInput: None\nOutput: panels: list of panels w_settings: list of widgets for all settings names_settings: list of widget names panel_titles: list of panel titles\n\ngen_savebutton()\n\nGenerate Save button\nInput: None\nOutput: w_savebutton: widget for saving settings\n\nload_settings(fname_settings)\n\nLoad settings from yaml file\nInput: fname_settings: path and filename to settings file\nOutput: settings: settings as namespace\n\nprint_settings(settings)\n\nprint settings\nInput: settings: settings object\nOutput: None\n\nsave_dict_settings(dict_settings, yaml_outfname)\n\nsave dictionary to yaml file\nInput: dict_settings: dictionary of settings yaml_outfname: path and filename to save settings\nOutput: None\n\nsavebutton_onclick(params)\n\nSave settings to yaml file\nInput: params: list of widgets, list of names of widgets, output filename\nOutput: None"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_radiometric.html",
    "href": "API_md/geodata_harvester/getdata_radiometric.html",
    "title": "Module geodata_harvester.getdata_radiometric",
    "section": "",
    "text": "Script to download Radiometric data from NCI’s GSKY Data Server (using WCS) for a given resolution, and bounding box. Final data is saved as geotiff or NetCDF.\nA full ist of datasets can be retrieved with get_radiometricdict() or get_capabilities() for a given url An overview of all datasets can be also found here: https://opus.nci.org.au/display/Help/Datasets\nFor more details of the NCI GSKY WCS, please see here: https://opus.nci.org.au/pages/viewpage.action?pageId=137199852\nLIMITATIONS: for some layers the server readout time can occasionally exceed 30s (longer readout time in request seems to be ignored) In case this happens please try later again when the NCI server is less loaded.\nThis package is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2022 Sydney Informatics Hub (SIH), The University of Sydney\nThis open-source software is released under the LGPL-3.0 License.\nAuthor: Sebastian Haan\n\n\n\nget_capabilities()\n\nGet capabilities from WCS layer.\n\nurl : str layer url\n\nkeys : list layer identifiers titles : list of str layer titles descriptions : list of str layer descriptions bboxs : list of floats layer bounding boxes\n\nget_radiometric_image(outfname, layername, bbox, url, resolution=1, crs='EPSG:4326', format_out='GeoTIFF')\n\nDownload radiometric data layer and save geotiff from WCS layer.\n\noutfname : str output file name layername : str layer identifier bbox : list layer bounding box resolution : int layer resolution in arcsec url : str url of wcs server crs: str crsm default ‘EPSG:4326’ format: str output format, either “GeoTIFF” or “NetCDF”\n\nExited ok: boolean\n\nget_radiometric_layers(outpath, layernames, bbox, resolution=1, crs='EPSG:4326', format_out='GeoTIFF')\n\nWrapper function for downloading radiometric data layers and save geotiffs from WCS layer.\n\noutpath: str output path layername : list of strings layer identifiers bbox : list layer bounding box resolution : int layer resolution in arcsec url : str url of wcs server crs: str crsm default ‘EPSG:4326’ format_out: str output format, either “GeoTIFF” or “NetCDF”\n\nlist of output filenames\n\nget_radiometricdict()\n\nReturns dictionary of keys and layer titles\nTo update manually please run get_capabilities() to retrieve all current layer details\n\nget_times(url, layername, year=None)\n\nReturn available dates for layer.\n\nurl: str, layer url layername: str, name of layer id year: int or str, year of interest (if None, times for all available years are returned)\n\nlist of dates\n\ngetdict_license()\n\nRetrieves the Geoscience Australia data license and NCI attribution information as dict\n\nplot_raster(infname)\n\nRead in raster tif with rasterio and visualise as map.\n\ninfname : str"
  },
  {
    "objectID": "API_md/geodata_harvester/getdata_radiometric.html#functions",
    "href": "API_md/geodata_harvester/getdata_radiometric.html#functions",
    "title": "Module geodata_harvester.getdata_radiometric",
    "section": "",
    "text": "get_capabilities()\n\nGet capabilities from WCS layer.\n\nurl : str layer url\n\nkeys : list layer identifiers titles : list of str layer titles descriptions : list of str layer descriptions bboxs : list of floats layer bounding boxes\n\nget_radiometric_image(outfname, layername, bbox, url, resolution=1, crs='EPSG:4326', format_out='GeoTIFF')\n\nDownload radiometric data layer and save geotiff from WCS layer.\n\noutfname : str output file name layername : str layer identifier bbox : list layer bounding box resolution : int layer resolution in arcsec url : str url of wcs server crs: str crsm default ‘EPSG:4326’ format: str output format, either “GeoTIFF” or “NetCDF”\n\nExited ok: boolean\n\nget_radiometric_layers(outpath, layernames, bbox, resolution=1, crs='EPSG:4326', format_out='GeoTIFF')\n\nWrapper function for downloading radiometric data layers and save geotiffs from WCS layer.\n\noutpath: str output path layername : list of strings layer identifiers bbox : list layer bounding box resolution : int layer resolution in arcsec url : str url of wcs server crs: str crsm default ‘EPSG:4326’ format_out: str output format, either “GeoTIFF” or “NetCDF”\n\nlist of output filenames\n\nget_radiometricdict()\n\nReturns dictionary of keys and layer titles\nTo update manually please run get_capabilities() to retrieve all current layer details\n\nget_times(url, layername, year=None)\n\nReturn available dates for layer.\n\nurl: str, layer url layername: str, name of layer id year: int or str, year of interest (if None, times for all available years are returned)\n\nlist of dates\n\ngetdict_license()\n\nRetrieves the Geoscience Australia data license and NCI attribution information as dict\n\nplot_raster(infname)\n\nRead in raster tif with rasterio and visualise as map.\n\ninfname : str"
  },
  {
    "objectID": "py_dataharvester.html",
    "href": "py_dataharvester.html",
    "title": "Python",
    "section": "",
    "text": "Github repository: https://github.com/Sydney-Informatics-Hub/geodata-harvester"
  },
  {
    "objectID": "py_dataharvester.html#pipeline-overview",
    "href": "py_dataharvester.html#pipeline-overview",
    "title": "Python",
    "section": "Pipeline Overview",
    "text": "Pipeline Overview"
  },
  {
    "objectID": "py_dataharvester.html#functionality",
    "href": "py_dataharvester.html#functionality",
    "title": "Python",
    "section": "Functionality",
    "text": "Functionality\nThe main goal of the Data Harvester is to enable researchers with reusable workflows for automatic data extraction and processing:\n\nRetrieve: given set of locations, automatically access and download multiple data sources (APIs) from a diverse range of geospatial and soil data sources\nProcess: Spatial and temporal processing, conversion to dataframes and custom raster-files\nOutput: Ready-made dataset for machine learning (training set and prediction mapping)\n\nGeodata-Harvester is designed as a modular and maintainable project in the form of a multi-stage pipeline by providing explicit boundaries among tasks. To encourage interaction and experimentation with the pipeline, multiple frontend notebooks and use case scenarios are provided."
  },
  {
    "objectID": "py_dataharvester.html#installation",
    "href": "py_dataharvester.html#installation",
    "title": "Python",
    "section": "Installation",
    "text": "Installation\nGeodata-Harvester can be run on cloud-servers (e.g., in JupyterHub environment) or on your local machine. Example notebooks for importing and using the package can be found in the folder notebooks. To install the package run one of the following:\n\nConda or Mamba\nThe package geodata-harvester is available via the conda-forge channel:\nconda install geodata-harvester -c conda-forge\nNote that the geodata-harvester is imported with underscore as\nimport geodata_harvester\n\n\nPip\nInstallation via pypi requires a pre-installation of gdal (see, e.g., pypi.org/project/GDAL/installation guide) in your environment. Once gdal is installed, you can install geodata-harvester via\npip install geodata-harvester\nThe geodata-harvester library can then be imported via\nimport geodata_harvester\n\n\nRequirements\nIf you like to develop Data Harvester locally, it is recommended to setup a virtual environment for the installation, e.g., via conda miniforge (see for dependencies environment.yaml).\nTo build the Geodata Harvester from scratch see the dependencies listed in the environment file.\nTo install the dependencies for the Geodata Harvester you may use the environment file directly in conda:\nwget https://raw.githubusercontent.com/Sydney-Informatics-Hub/geodata-harvester/main/environment.yaml\nconda env create -f environment.yaml -n gdh\nconda activate gdh"
  },
  {
    "objectID": "py_dataharvester.html#usage",
    "href": "py_dataharvester.html#usage",
    "title": "Python",
    "section": "Usage",
    "text": "Usage\nYou may now invoke the geodata-harvester directly from a python terminal with:\nimport geodata_harvester as gh\ngh.harvest.run()\nNote the subtle but important difference in use of an underscore _ to import the package and the use of a dash - to install it!\nTo get started, some example workflows are provided as Jupyter notebooks:\n\nOptions and user settings are defined by the user in the settings; see for settings documentation Settings_Overview\nRun the jupyter notebooks in the folder notebooks."
  },
  {
    "objectID": "py_dataharvester.html#api-reference",
    "href": "py_dataharvester.html#api-reference",
    "title": "Python",
    "section": "API reference",
    "text": "API reference\nA detailed API documentation is available here."
  },
  {
    "objectID": "py_dataharvester.html#new-data-source-modules",
    "href": "py_dataharvester.html#new-data-source-modules",
    "title": "Python",
    "section": "New data source modules",
    "text": "New data source modules\nThe Geodata-Harvester is designed to be extendable and new data source modules can be added as Python modules (for examples, see getdata_*.py modules). If you would like to add a new data source, please follow the adding new data source guidelines\nWe recommend to check the existing data source modules for inspiration. If you would like to contribute your data source module to the geodata-harvester package, please see the Contributing page"
  },
  {
    "objectID": "py_dataharvester.html#contribution",
    "href": "py_dataharvester.html#contribution",
    "title": "Python",
    "section": "Contribution",
    "text": "Contribution\nYour contributions can help improve the software and make it more useful for others. We are happy for any contribution to the geodata-harvester, whether feedbacks and bug reports via github Issues, adding use-case examples via notebook contributions, to improving source-code and adding new or updating existing data source modules.\nTo contribute to the development and to understand how the Geodata Harvester works, visit the the Contributing page"
  },
  {
    "objectID": "py_dataharvester.html#attribution-and-acknowledgments",
    "href": "py_dataharvester.html#attribution-and-acknowledgments",
    "title": "Python",
    "section": "Attribution and Acknowledgments",
    "text": "Attribution and Acknowledgments\nThis software was developed by the Sydney Informatics Hub, a core research facility of the University of Sydney, as part of the Data Harvesting project for the Agricultural Research Federation (AgReFed).\nAcknowledgments are an important way for us to demonstrate the value we bring to your research. Your research outcomes are vital for ongoing funding of the Sydney Informatics Hub.\nIf you make use of this software for your research project, please include the following acknowledgment:\n“This research was supported by the Sydney Informatics Hub, a Core Research Facility of the University of Sydney, and the Agricultural Research Federation (AgReFed).”\nAgReFed is supported by the Australian Research Data Commons (ARDC) and the Australian Government through the National Collaborative Research Infrastructure Strategy (NCRIS)."
  },
  {
    "objectID": "py_dataharvester.html#code-of-conduct",
    "href": "py_dataharvester.html#code-of-conduct",
    "title": "Python",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nPlease keep in mind that the geodata-harvester project follows the GitHub Community Code of Conduct, which requires respectful and professional behavior.\nWe appreciate your interest and contributions to the geodata-harvester project and look forward to working with you! If you have any questions or need help, don’t hesitate to reach out."
  },
  {
    "objectID": "events.html",
    "href": "events.html",
    "title": "Events",
    "section": "",
    "text": "Point of contact: Sebastian Haan\nPresenting the AgReFed Geodata-Harvester at the eResearch Australia Conference\n\n\n\nPoint of contact: Januar Harianto\nAgReFed Data-Harvester Workshop for R users. Registration and more information at: Eventbrite Workshop Registration"
  },
  {
    "objectID": "events.html#autumn-2022",
    "href": "events.html#autumn-2022",
    "title": "Events",
    "section": "",
    "text": "Point of contact: Sebastian Haan\nPresenting the AgReFed Geodata-Harvester at the eResearch Australia Conference\n\n\n\nPoint of contact: Januar Harianto\nAgReFed Data-Harvester Workshop for R users. Registration and more information at: Eventbrite Workshop Registration"
  },
  {
    "objectID": "R_dataharvester.html",
    "href": "R_dataharvester.html",
    "title": "R-Package",
    "section": "",
    "text": "This is a pre-release version of the R geodata-harvester which is undergoing active development:\nhttps://sydney-informatics-hub.github.io/dataharvester/"
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Contributing",
    "section": "",
    "text": "Thank you for investing your time in contributing to our project! We appreciate your interest in contributing to Geodata-Harvesterproject. Your contributions can help improve the software and make it more useful for others.\nIn this guideline, we’ll explain how you can contribute to the project. Contributions to the geodata-harvester can be made in many ways, such as:\n\nFeedback and bug reports via Github Issue\nUse-case examples via notebook contributions\nSource-code contributions\nData-source contributions\nUpdating existing data source modules\nImproving documentation\n\n\n\nTo report bugs or provide feedback, you can use the Github Issues feature. If you spot a problem or have a suggestion for improvement, search if an issue already exists. If a related issue doesn’t exist, please open a new issue. The issue should address what is the current problem, where it occurs, and, if possible, one suggestion how this problem can potentially be solved.\nIf this is a bug report, please provide a clear and concise description of the issue and any relevant information such as error messages including file name and code line, installation details, and all steps to reproduce the problem.\n\n\n\nScan through our existing issues to find one that interests you. As a general rule, we don’t assign issues to anyone. If you find an issue to work on, you are welcome to open a pull request with a fix.\n\n\n\nIf you have an interesting use-case for the geodata-harvester, we would love to hear about it! A great way to demonstrate use-cases is via Jupyter notebooks, which provide helpful workflows to the community. Currently we maintain a few example notebooks that demonstrate some use-cases of the GeoData-Harvester. If you make use of this package, you are welcome to contribute by improving existing notebooks or creating a Jupyter Notebook with your example and sharing it with us.\nTo contribute, please fork the geodata-harvester repo and add your notebook and settings file to the folder notebooks. For reproducible research we encourage the use of settings YAML files (see notebooks/settings). Please give the settings file a name that corresponds to the notebook name. Then commit your changes and create a pull request to share with us.\n\n\n\nFor small documentation changes and suggestion to improve existing documentation, please open a new Issue. If you would like to add/edit some more documentation, please fork the repo, edit the corresponding .md file, commit the change, and submit a pull request for a review.\n\n\n\nWe welcome contributions to improve the Python code and to keep the data-source handlers up-to-date. If you have experience with Python programming and would like to contribute to the source code, we suggest the following guidelines:\n\nFork the repository and clone it to your local machine.\nCreate a new branch for your changes.\nWrite clear, concise, and well-documented code.\nTest your changes thoroughly.\nSubmit a pull request with a description of your changes and any relevant information.\n\n\n\n\nIf you would like to add a new data source module or update an existing one, please visit the adding new data source guidelines. Please also check if there are any open Issue requests about the data source that you would like to add. To contribute a new data source module, follow these guidelines:\n\nCheck the existing data source modules for inspiration.\nWrite clear, concise, and well-documented code.\nTest your changes thoroughly (test scripts and example notebook demonstrating the new data source are welcome!)\nSubmit a pull request with a description of your changes and any relevant information.\n\n\n\n\nPlease keep in mind that the geodata-harvester project follows the GitHub Community Code of Conduct, which requires respectful and professional behavior.\nWe appreciate your contributions to the geodata-harvester project and look forward to working with you! If you have any questions or need help, don’t hesitate to reach out."
  },
  {
    "objectID": "contributing.html#feedback-and-bug-reports-create-a-new-issue",
    "href": "contributing.html#feedback-and-bug-reports-create-a-new-issue",
    "title": "Contributing",
    "section": "",
    "text": "To report bugs or provide feedback, you can use the Github Issues feature. If you spot a problem or have a suggestion for improvement, search if an issue already exists. If a related issue doesn’t exist, please open a new issue. The issue should address what is the current problem, where it occurs, and, if possible, one suggestion how this problem can potentially be solved.\nIf this is a bug report, please provide a clear and concise description of the issue and any relevant information such as error messages including file name and code line, installation details, and all steps to reproduce the problem."
  },
  {
    "objectID": "contributing.html#solve-an-open-issue",
    "href": "contributing.html#solve-an-open-issue",
    "title": "Contributing",
    "section": "",
    "text": "Scan through our existing issues to find one that interests you. As a general rule, we don’t assign issues to anyone. If you find an issue to work on, you are welcome to open a pull request with a fix."
  },
  {
    "objectID": "contributing.html#use-case-example-notebooks",
    "href": "contributing.html#use-case-example-notebooks",
    "title": "Contributing",
    "section": "",
    "text": "If you have an interesting use-case for the geodata-harvester, we would love to hear about it! A great way to demonstrate use-cases is via Jupyter notebooks, which provide helpful workflows to the community. Currently we maintain a few example notebooks that demonstrate some use-cases of the GeoData-Harvester. If you make use of this package, you are welcome to contribute by improving existing notebooks or creating a Jupyter Notebook with your example and sharing it with us.\nTo contribute, please fork the geodata-harvester repo and add your notebook and settings file to the folder notebooks. For reproducible research we encourage the use of settings YAML files (see notebooks/settings). Please give the settings file a name that corresponds to the notebook name. Then commit your changes and create a pull request to share with us."
  },
  {
    "objectID": "contributing.html#documentation-contributions",
    "href": "contributing.html#documentation-contributions",
    "title": "Contributing",
    "section": "",
    "text": "For small documentation changes and suggestion to improve existing documentation, please open a new Issue. If you would like to add/edit some more documentation, please fork the repo, edit the corresponding .md file, commit the change, and submit a pull request for a review."
  },
  {
    "objectID": "contributing.html#source-code-contributions",
    "href": "contributing.html#source-code-contributions",
    "title": "Contributing",
    "section": "",
    "text": "We welcome contributions to improve the Python code and to keep the data-source handlers up-to-date. If you have experience with Python programming and would like to contribute to the source code, we suggest the following guidelines:\n\nFork the repository and clone it to your local machine.\nCreate a new branch for your changes.\nWrite clear, concise, and well-documented code.\nTest your changes thoroughly.\nSubmit a pull request with a description of your changes and any relevant information."
  },
  {
    "objectID": "contributing.html#data-source-module-contributions",
    "href": "contributing.html#data-source-module-contributions",
    "title": "Contributing",
    "section": "",
    "text": "If you would like to add a new data source module or update an existing one, please visit the adding new data source guidelines. Please also check if there are any open Issue requests about the data source that you would like to add. To contribute a new data source module, follow these guidelines:\n\nCheck the existing data source modules for inspiration.\nWrite clear, concise, and well-documented code.\nTest your changes thoroughly (test scripts and example notebook demonstrating the new data source are welcome!)\nSubmit a pull request with a description of your changes and any relevant information."
  },
  {
    "objectID": "contributing.html#code-of-conduct",
    "href": "contributing.html#code-of-conduct",
    "title": "Contributing",
    "section": "",
    "text": "Please keep in mind that the geodata-harvester project follows the GitHub Community Code of Conduct, which requires respectful and professional behavior.\nWe appreciate your contributions to the geodata-harvester project and look forward to working with you! If you have any questions or need help, don’t hesitate to reach out."
  }
]